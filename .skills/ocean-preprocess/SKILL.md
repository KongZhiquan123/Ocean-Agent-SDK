---
name: ocean-preprocess
description: 海洋数据预处理技能 - 专用于超分辨率场景的NC到NPY数据格式转换
version: 3.0.1
author: kongzhiquan
contributors: leizheng
last_modified: 2026-02-04
---

<!--
Changelog:
  - 2026-02-04 kongzhiquan: v3.0.1
    - 明确说明 ocean_metrics 是独立工具，不包含在 ocean_preprocess_full 中
    - 更新报告生成流程，添加"第零步：计算质量指标"
    - 更新工具表格，强调 ocean_metrics 必须在预处理完成后手动调用
    - 更新流程图，显示 ocean_metrics 和 ocean_generate_report 是独立步骤
    - 推荐的完整工作流程：full → metrics → report → 填写分析
  - 2026-02-04 kongzhiquan: v3.0.0
    - 修正 ocean_preprocess_full 工具调用示例中的错误参数名
    - 补充报告生成流程中的分析步骤细节
  - 2026-02-04 leizheng: v2.9.0
    - 工具层面实现4阶段强制停止点
    - 阶段1: awaiting_variable_selection - 研究变量选择
    - 阶段2: awaiting_static_selection - 静态/掩码变量选择
    - 阶段3: awaiting_parameters - 处理参数确认（scale/method/split）
    - 阶段4: awaiting_execution - 执行前最终确认
    - 每个阶段工具都会强制返回，Agent 无法跳过
  - 2026-02-04 leizheng: v2.8.0
    - 强化变量选择流程，研究变量/静态变量/掩码变量必须由用户选择
    - Step 3: 用户未指定研究变量时，只能用 ocean_inspect_data 分析
    - Step 4: 改为强制停止点，必须等用户选择变量后才能继续
    - 禁止行为清单分类整理（变量选择/参数决策/流程控制/错误处理）
  - 2026-02-04 leizheng: v2.7.0
    - 新增"错误处理原则"章节，明确禁止自动重试
    - 更新禁止行为清单，增加自动重试、自动更换路径、跳过执行前确认等禁止项
    - 强化 Step 6 执行前确认要求，明确"确认执行"判断标准
    - 修复 Agent 自动决策导致的问题
  - 2026-02-04 leizheng: v2.6.0
    - 支持粗网格模式（数值模型方式）
    - 新增 lr_nc_folder/lr_static_file/lr_dyn_file_pattern 参数
    - 新增 Step C2: 粗网格数据转换到 lr/ 目录
    - 粗网格模式下自动跳过下采样
    - **支持从动态文件中提取静态变量**（当没有单独静态文件时）
  - 2026-02-03 leizheng: v2.5.0
    - ocean_preprocess_full 集成下采样和可视化
    - 完整流程变为 A→B→C→D→E 五步
    - scale 参数变为必须
  - 2026-02-03 leizheng: v2.4.0
    - 新增裁剪功能（h_slice/w_slice/scale 参数）
    - 新增下采样工具 ocean_downsample
    - 新增可视化工具 ocean_visualize
    - 新增指标检测工具 ocean_metrics
    - 更新完整流程文档
  - 2026-02-03 leizheng: v2.3.0
    - 支持 nc_files 参数明确指定文件列表
    - 支持单个文件路径自动转换为目录模式
    - 逐文件检测时间维度，识别静态文件混入
    - 更新禁止行为清单
  - 2026-02-03 leizheng: v2.2.1
    - 添加强制确认机制（必须同时提供 mask_vars 和 stat_vars）
  - 2026-02-03 leizheng: v2.2.0
    - 添加禁止自动决策原则
    - 添加禁止行为清单
    - 移除硬编码默认值要求
  - 2026-02-02 leizheng: v2.1.0
    - 添加警告优先原则
    - 添加警告处理指南
  - 2026-02-02 leizheng: v2.0.0
    - 完整重写 SKILL.md
    - 添加工具调用流程
    - 添加错误解释指南
    - 添加参数速查表
-->

# 海洋数据预处理技能

## 核心原则

1. **数据预处理定义**：不破坏原有数据结构的任何信息，不做标准化，只做格式转换

2. **⚠️ 警告优先原则（重要）**：
   - 在分析过程中如果有**任何不确定或异常**的地方，**必须先询问用户**再继续执行
   - **绝不能**在有严重警告的情况下直接执行处理
   - 即使工具返回 `pass` 状态，如果 `warnings` 中有内容，也要向用户展示并确认

3. **⚠️ 禁止自动决策原则（v2.2 新增）**：
   - **不得代替用户做任何数据处理决策**
   - 以下事项必须由用户明确确认：
     - NaN/Inf 值如何处理（是否允许、如何填充）
     - 掩码变量选择（哪些是掩码、哪个是主掩码）
     - 静态变量选择（哪些需要保存）
     - 坐标范围验证（是否需要、范围是多少）
   - 禁止使用硬编码默认值（如 "lon_rho", "mask_rho"）
   - 所有变量名必须从数据中检测到或由用户明确指定

4. **⚠️ 路径灵活处理原则（v2.3 新增）**：
   - nc_folder 可以是目录路径，也可以是单个文件路径
   - 如果提供单个文件路径，自动转换为目录 + 文件列表模式
   - 支持 nc_files 参数明确指定要处理的文件
   - **检测静态文件混入**：自动识别目录中没有时间维度的文件

5. **需要暂停并询问用户的情况**：
   - 形状不匹配（动态数据与静态数据维度不同）
   - 缺少掩码变量
   - NaN/Inf 值存在（即使 allow_nan=true）
   - 掩码非二值
   - 坐标范围异常
   - 任何 warnings 数组中的内容
   - 用户未明确指定 mask_vars 或 stat_vars 时
   - **检测到静态文件混入动态数据目录时**

---

## 可用工具

| 工具名 | 用途 | 什么时候用 |
|--------|------|-----------|
| `ocean_preprocess_full` | 一键执行完整流程 A→B→C→D→E（含下采样+可视化） | **推荐**，信息完整时直接用这个 |
| `ocean_metrics` | 质量指标检测 | **预处理完成后必须调用**，计算 SSIM、Relative L2 等指标 |
| `ocean_generate_report` | 生成预处理报告（含占位符） | 指标计算完成后生成报告，**必须由 Agent 填写分析** |
| `ocean_downsample` | HR→LR 下采样 | 单独执行下采样（full 已集成） |
| `ocean_visualize` | HR vs LR 可视化对比 | 单独生成可视化（full 已集成） |
| `ocean_inspect_data` | 只查看数据，不处理 | 用户只想看看有什么变量时 |
| `ocean_validate_tensor` | 只验证张量形状 | 一般不单独用 |
| `ocean_convert_npy` | 只执行转换 | 一般不单独用 |

---

## 工具调用流程（重要）

### 核心原则

1. **先收集，再分析，再确认，最后执行**
2. **用户说了什么就记下什么**，不要遗漏用户已提供的信息
3. **需要看数据才知道的信息** → 先分析数据再让用户选择
4. **用户可以直接决定的信息** → 直接追问
5. **执行前再 check 一遍** → 确保用户确认所有参数

### 信息分类

| 信息类型 | 示例 | 处理方式 |
|---------|------|---------|
| 用户可直接提供 | 数据目录、输出目录 | 直接追问 |
| 需要分析数据 | 有什么变量、数据形状、维度信息 | 先分析再让用户选择 |
| 用户决策 | 研究变量选哪些、掩码用哪个 | 展示选项让用户选择 |
| 处理参数 | 下采样倍数、插值方法、划分比例 | 直接追问，执行前再确认 |

---

### 完整流程（v2.9.0 工具强制 4 阶段）

**重要**：`ocean_preprocess_full` 工具会在每个阶段强制返回，Agent 无法跳过任何确认步骤。

```
调用工具（无 dyn_vars）
    ↓
⛔ 阶段1: awaiting_variable_selection  ← 工具强制返回
    │   展示动态变量候选，要求用户选择研究变量
    ↓
用户选择研究变量后，再次调用（带 dyn_vars）
    ↓
⛔ 阶段2: awaiting_static_selection   ← 工具强制返回
    │   展示静态/掩码变量候选，要求用户选择
    ↓
用户选择静态/掩码变量后，再次调用（带 stat_vars, mask_vars）
    ↓
⛔ 阶段3: awaiting_parameters         ← 工具强制返回
    │   要求用户确认：scale、method、split比例、裁剪参数
    ↓
用户确认参数后，再次调用（带所有参数）
    ↓
⛔ 阶段4: awaiting_execution          ← 工具强制返回
    │   展示完整参数汇总，等待用户说"确认执行"
    ↓
用户确认执行后，再次调用（带 user_confirmed=true）
    ↓
✅ 执行完整处理流程 (A→B→C→D→E)
```

**每个阶段的返回状态**：

| 阶段 | 返回状态 | 需要用户确认 | Agent 必须询问 |
|------|---------|------------|--------------|
| 1 | `awaiting_variable_selection` | 研究变量 | "您要研究哪些变量？" |
| 2 | `awaiting_static_selection` | 静态/掩码变量 | "需要保存哪些静态变量？使用哪些掩码？" |
| 3 | `awaiting_parameters` | 处理参数 | "下采样倍数？插值方法？划分比例？裁剪尺寸？" |
| 4 | `awaiting_execution` | 最终确认 | "请确认以上参数，回复'确认执行'" |

---

### Step 1-2: 收集基本信息

从用户的 prompt 中提取已有信息，追问缺失的：

| 信息 | 必需 | 如果缺失 |
|------|------|---------|
| 数据目录 | ✅ | 追问 |
| 输出目录 | ✅ | 追问 |
| 研究变量 | ⚠️ | 可以先分析数据再选 |
| 下采样倍数 | ⚠️ | Step 5 追问 |
| 插值方法 | ⚠️ | Step 5 追问 |
| 划分比例 | ⚠️ | Step 5 追问 |

**注意**：如果用户已经说了下采样倍数、方法等，先记下来，后面 Step 6 再确认。

---

### Step 3: 分析数据

**⚠️ 重要**：如果用户**没有明确指定研究变量**，必须先用 `ocean_inspect_data` 分析数据，让用户选择后再继续。**禁止猜测研究变量！**

| 用户是否指定了研究变量 | 调用工具 |
|----------------------|---------|
| ❌ 未指定 | `ocean_inspect_data`（仅分析，不处理） |
| ✅ 已指定 | `ocean_preprocess_full`（分析+等待确认） |

**用户未指定研究变量时**，调用 `ocean_inspect_data`：

```json
{
  "nc_folder": "/用户提供的数据目录"
}
```

**用户已明确指定研究变量时**，调用 `ocean_preprocess_full`：

```json
{
  "nc_folder": "/用户提供的数据目录",
  "output_base": "/用户提供的输出目录",
  "dyn_vars": ["用户明确指定的变量"]
}
```

向用户展示分析结果：

```
数据分析完成，以下是您的数据信息：

【文件信息】
- 数据目录: /data/ocean
- 文件数量: 365 个
- 数据形状: (365, 680, 1440) [时间, 高度, 宽度]

【动态变量候选】（有时间维度，可作为研究目标）
- chl: 形状 (365, 680, 1440), float32
- no3: 形状 (365, 680, 1440), float32
- temp: 形状 (365, 50, 680, 1440), float32 [有深度维度]

【疑似掩码变量】
- mask: 形状 (680, 1440), int8

【疑似静态变量】
- lon: 形状 (680, 1440)
- lat: 形状 (680, 1440)
- h: 形状 (680, 1440)
```

---

### Step 4: 用户选择（强制停止点）

**⛔ 这是强制停止点！** Agent 必须在此处停下来，等待用户明确选择以下内容：

根据分析结果，让用户选择：

```
请根据以上信息确认：

1. 您要研究哪些变量？【必须由用户选择，Agent 禁止猜测】
   可选: chl, no3, temp（temp 有深度维度，会输出 4D 数据）

2. 掩码变量使用 mask 吗？（如果数据没有掩码，可以设为空）

3. 需要保存哪些静态变量？
   可选: lon, lat, h, mask

4. 数据中是否允许 NaN 值存在？
```

**Agent 禁止行为**：
- ❌ 根据变量名"推测"用户想研究什么（如看到 uo/vo 就假设用户要研究流速）
- ❌ 看到只有几个动态变量就自动全选
- ❌ 跳过询问直接使用检测到的变量

**Agent 必须做的**：
- ✅ 展示所有动态变量候选，明确询问"您要研究哪些变量？"
- ✅ 等待用户回复后才能继续

---

### Step 5: 追问处理参数

如果用户之前没有提供处理参数，现在追问：

```
接下来需要确认处理参数：

1. **超分数据来源方式**：
   - 下采样：从高分辨率数据下采样生成低分辨率数据
   - 数值模型：使用粗网格直接运行数值模型（LR 数据已有，只需转换 HR）

   请问您使用哪种方式？

2. **下采样参数**（如果选择下采样）：
   - 下采样倍数（scale）：如 4 表示尺寸缩小为 1/4
   - 插值方法：
     • area（推荐）：区域平均，最接近真实低分辨率
     • cubic：三次插值，较平滑
     • linear：双线性插值
     • nearest：最近邻插值，保留原始值
     • lanczos：Lanczos 插值，高质量
     • lanczos：Lanczos 插值

3. **数据集划分比例**：
   - train/valid/test 比例？（如 0.7/0.15/0.15）

4. **数据裁剪**（可选）：
   - 当前数据形状: (680, 1440)
   - 是否需要裁剪以确保尺寸能被 scale 整除？
```

#### 两种超分方式的处理区别

| 方式 | 说明 | 工具参数设置 |
|------|------|-------------|
| **下采样** | HR 数据下采样生成 LR | `scale` + `downsample_method` 必须指定 |
| **粗网格（数值模型）** | LR 数据由粗网格模型直接生成 | `lr_nc_folder` 必须指定（可选 `lr_static_file`, `lr_dyn_file_pattern`） |

**下采样方式**：
- 输入：HR 数据（高分辨率）
- 输出：HR + LR（LR 由工具自动下采样生成）
- 流程：NC→NPY 转换 → 下采样 → 可视化
- 参数：需要 `scale` 和 `downsample_method`

**粗网格方式（v2.6 新增）**：
- 输入：HR 数据 + LR 数据（两套独立的 NC 文件）
- 输出：HR + LR（分别转换到 hr/ 和 lr/ 目录）
- 流程：HR 转换 → LR 转换 → 可视化（自动跳过下采样）
- 参数：需要 `lr_nc_folder`，可选 `lr_static_file`, `lr_dyn_file_pattern`
- **优势**：一次调用工具即可完成 HR 和 LR 的转换

---

### Step 6: 执行前 Check（关键步骤）

**在真正执行之前**，必须展示所有参数让用户确认：

#### 下采样方式的确认示例：

```
所有参数已收集完毕，执行前请确认：

================== 处理参数确认 ==================

【输入输出】
- 数据目录: /data/ocean
- 输出目录: /output/dataset
- 文件数量: 365 个

【研究变量】
- 动态变量: chl, no3
- 掩码变量: mask
- 静态变量: lon, lat, h, mask

【数据处理】
- 超分方式: 下采样
- NaN 处理: 不允许 NaN
- 数据裁剪: 无

【下采样参数】
- 下采样倍数: 4
- 插值方法: area

【数据集划分】
- 训练集: 70%
- 验证集: 15%
- 测试集: 15%

================================================

确认以上参数无误后，我将执行以下步骤：
1. NC → NPY 转换（含划分）
2. HR → LR 下采样
3. 生成可视化对比图

请回复"确认执行"开始处理，或告诉我需要修改哪些参数。
```

#### 数值模型方式的确认示例：

```
所有参数已收集完毕，执行前请确认：

================== 处理参数确认 ==================

【输入输出】
- HR 数据目录: /data/ocean_hr
- LR 数据目录: /data/ocean_lr
- 输出目录: /output/dataset

【研究变量】
- 动态变量: chl, no3
- 掩码变量: mask
- 静态变量: lon, lat, h, mask

【数据处理】
- 超分方式: 数值模型（HR/LR 分别转换）
- NaN 处理: 不允许 NaN

【数据集划分】
- 训练集: 70%
- 验证集: 15%
- 测试集: 15%

================================================

确认以上参数无误后，我将分别处理 HR 和 LR 数据：
1. 处理 HR 数据 → output/train/hr/, valid/hr/, test/hr/
2. 处理 LR 数据 → output/train/lr/, valid/lr/, test/lr/
3. 生成可视化对比图

请回复"确认执行"开始处理，或告诉我需要修改哪些参数。
```

**⚠️ 必须等用户明确确认后才能执行！**

**判断用户是否确认的标准**：
- ✅ 用户明确说："确认执行"、"确认"、"开始"、"执行"、"好的，开始吧"
- ❌ 用户只是回答了某个问题，但没说"确认执行"
- ❌ 用户提供了参数值，但没说"确认执行"

**如果用户没有说"确认执行"**：
- 继续等待，或者再次询问"参数确认完毕，是否开始执行？"

---

### Step 7: 执行

**只有**在用户明确确认后，才能调用 `ocean_preprocess_full` 执行完整流程：

```json
{
  "nc_folder": "/data/ocean",
  "output_base": "/output/dataset",
  "dyn_vars": ["chl", "no3"],
  "user_confirmed": true,
  "mask_vars": ["mask"],
  "stat_vars": ["lon", "lat", "h", "mask"],
  "train_ratio": 0.7,
  "valid_ratio": 0.15,
  "test_ratio": 0.15,
  "scale": 4,
  "downsample_method": "area",
  "allow_nan": false
}
```

---

### 对话示例

**示例 1：用户提供完整信息**

```
用户: 数据在 /data/cmems，变量是 chl 和 no3，输出到 /output，4 倍下采样用 area 方法，划分 0.7/0.15/0.15

Agent: 收到，我先分析一下您的数据...

[分析数据]

数据分析完成：
- 文件数量: 365 个
- chl 形状: (365, 680, 1440)
- no3 形状: (365, 680, 1440)
- 检测到掩码: mask
- 检测到静态变量: lon, lat

请确认：
1. 掩码变量使用 mask 吗？
2. 需要保存哪些静态变量？

用户: mask 用 mask，静态变量保存 lon lat

Agent: 好的，执行前请确认所有参数：

【处理参数确认】
- 数据目录: /data/cmems
- 研究变量: chl, no3
- 掩码: mask
- 静态变量: lon, lat
- 下采样: 4x, area 方法
- 划分: 70%/15%/15%

确认无误后我将开始处理。

用户: 确认执行

Agent: [开始执行...]
```

**示例 2：用户不清楚有什么变量**

```
用户: 我的数据在 /data/ocean，输出到 /output，帮我做超分预处理

Agent: 好的，我先分析一下您的数据，看看有哪些变量可用...

[分析数据]

数据分析完成，以下是您的数据信息：

【动态变量候选】
- uo: 东向流速, 形状 (365, 680, 1440)
- vo: 北向流速, 形状 (365, 680, 1440)
- temp: 温度, 形状 (365, 50, 680, 1440)

【静态变量】
- lon_rho, lat_rho, h, mask_rho

请问您想研究哪些变量？

用户: 研究 uo 和 vo

Agent: 好的。接下来需要确认处理参数：
1. 下采样倍数是多少？
2. 使用什么插值方法？（推荐 area）
3. 数据集划分比例？

用户: 4 倍，area，0.8/0.1/0.1

Agent: 收到。最后确认一下：
- 掩码使用 mask_rho 吗？
- 静态变量保存哪些？

用户:是的，静态变量保存 lon_rho lat_rho mask_rho

Agent: 好的，执行前请确认所有参数：
[展示完整参数列表]

用户: 确认

Agent: [开始执行...]
```

**示例 3：使用粗网格模式（HR/LR 数据来自不同精度模型）**

```
用户:s 我有两套数据，HR 在 /data/hr，LR 在 /data/lr，都是 ROMS 模型输出，帮我转成超分训练格式

Agent: 好的，您使用的是粗网格模式（HR/LR 数据由模型分别生成）。我先分析一下您的 HR 数据...

[分析 HR 数据]

HR 数据分析完成：
- 文件数量: 365 个
- 数据形状: (365, 680, 1440)
- 动态变量: temp, salt, uo, vo
- 静态变量: lon_rho, lat_rho, h, mask_rho

请问：
1. 您想研究哪些变量？
2. 输出目录是哪里？

用户: 研究 temp 和 salt，输出到 /output/dataset

Agent: 好的。还需要确认：
1. 掩码使用 mask_rho 吗？
2. 需要保存哪些静态变量？
3. 数据集划分比例？

用户: mask_rho，静态变量保存 lon_rho lat_rho，划分 0.7/0.15/0.15

Agent: 好的，执行前请确认所有参数：

【处理参数确认】
- 超分方式: 粗网格模式（HR/LR 分别转换）
- HR 数据目录: /data/hr
- LR 数据目录: /data/lr
- 输出目录: /output/dataset
- 研究变量: temp, salt
- 掩码: mask_rho
- 静态变量: lon_rho, lat_rho
- 划分: 70%/15%/15%

执行流程：
1. Step A-B: 数据检查和张量验证
2. Step C: HR 数据转换 → train/hr/, valid/hr/, test/hr/
3. Step C2: LR 数据转换 → train/lr/, valid/lr/, test/lr/
4. Step E: 生成可视化对比图

确认执行？

用户: 确认

Agent: [开始执行完整流程...]
```

**粗网格模式调用参数示例**：
```json
{
  "nc_folder": "/data/hr",
  "output_base": "/output/dataset",
  "dyn_vars": ["temp", "salt"],
  "user_confirmed": true,
  "mask_vars": ["mask_rho"],
  "stat_vars": ["lon_rho", "lat_rho"],
  "train_ratio": 0.7,
  "valid_ratio": 0.15,
  "test_ratio": 0.15,
  "lr_nc_folder": "/data/lr",
  "lr_static_file": "/data/lr/grid.nc"
}
```

#### 情况 A：返回 `overall_status: "awaiting_confirmation"`

**含义**：工具检测到了疑似掩码变量或坐标变量，需要用户确认。

**返回结构**：
```json
{
  "overall_status": "awaiting_confirmation",
  "message": "数据分析完成，请用户确认变量分类...",
  "step_a": {
    "suspected_masks": ["mask_rho", "mask_u", "mask_v"],
    "suspected_coordinates": ["lon_rho", "lat_rho", "h", "angle"],
    "dynamic_vars_candidates": ["uo", "vo", "temp", "salt"]
  }
}
```

**你必须做的事**：

1. 向用户展示检测到的变量分类：
```
我已分析数据，检测到以下变量：

【动态变量候选】（可作为研究目标）
- uo, vo, temp, salt

【疑似掩码变量】
- mask_rho, mask_u, mask_v

【疑似坐标/静态变量】
- lon_rho, lat_rho, h, angle

请逐一确认：
1. 您指定的研究变量 uo, vo 是否正确？
2. 掩码变量应该使用哪些？（检测到: mask_rho, mask_u, mask_v）
3. 需要保存哪些静态变量？（检测到: lon_rho, lat_rho, h, angle）
4. NaN/Inf 值如何处理？
   - 数据中是否可能有 NaN？
   - 如果有，是否允许保留？
```

2. **必须等待用户逐一确认每个问题**，不得自动决定

3. **用户确认后，再次调用 ocean_preprocess_full，必须同时提供所有参数**：

```json
{
  "nc_folder": "/data/ocean",
  "output_base": "/output/processed",
  "dyn_vars": ["uo", "vo"],
  "static_file": "/data/ocean/grid.nc",
  "mask_vars": ["mask_rho", "mask_u", "mask_v"],
  "stat_vars": ["lon_rho", "lat_rho", "h", "angle", "mask_rho"],
  "lon_var": "lon_rho",
  "lat_var": "lat_rho",
  "allow_nan": false
}
```

**重要**：
- 必须**同时**提供 `mask_vars` 和 `stat_vars`，否则工具会返回错误
- `lon_var` 和 `lat_var` 必须是用户确认的或从数据中检测到的
- **禁止使用硬编码默认值**

---

#### 情况 B：返回 `overall_status: "pass"`

**含义**：处理成功完成。

**⚠️ 重要：检查 warnings**

即使状态是 `pass`，你也必须检查返回结果中的 `warnings` 数组。如果有警告，**必须向用户展示并确认是否接受**：

```json
{
  "overall_status": "pass",
  "step_c": {
    "warnings": ["形状不匹配: 动态数据 (2041, 4320) 与静态数据 (100, 200)"],
    "errors": []
  }
}
```

**有警告时你必须做的**：

1. **不要**直接说"处理完成"
2. **必须**向用户展示所有警告
3. **必须**询问用户是否接受这些警告继续
4. 等用户确认后才能报告处理完成

示例回复：
```
处理已完成，但检测到以下警告：

⚠️ 警告信息：
1. 形状不匹配: 动态数据 (2041×4320) 与静态数据 (100×200) 形状不同
2. 缺少掩码: 未找到 mask_u 掩码变量

这些警告可能影响后续使用。请确认：
- 形状不匹配是否是预期的？（动态和静态数据来自不同分辨率？）
- 缺少 mask_u 是否会影响您的分析？

请回复"确认接受"继续，或告诉我需要如何处理。
```

**无警告时**：
```
预处理完成！

输出目录结构：
/output/processed/
├── target_variables/
│   ├── uo.npy
│   └── vo.npy
└── static_variables/
    ├── 00_lon_rho.npy
    ├── 10_lat_rho.npy
    └── 90_mask_rho.npy

所有验证检查已通过，无警告。
```

---

#### 情况 C：返回 `overall_status: "error"`

**含义**：处理过程中出错。

**返回结构**：
```json
{
  "overall_status": "error",
  "message": "Step C 失败",
  "step_c": {
    "errors": ["动态变量 'uo' 含有非法值: NaN=1234, Inf=0"],
    "warnings": [...]
  }
}
```

**你必须做的**：从 `errors` 数组中提取错误信息，向用户清晰解释。

---


---

## 报告生成流程（重要）

### 何时生成报告

在完整预处理流程（A→B→C→D→E）完成后，**必须**生成报告并填写分析。

### 报告生成步骤

#### 第零步：计算质量指标（必须）

**⚠️ 强制要求**：`ocean_preprocess_full` 不会自动计算质量指标（SSIM、Relative L2等）。**必须**在生成报告前调用 `ocean_metrics` 工具。

```json
{
  "dataset_root": "/output/dataset",
  "scale": 4
}
```

**为什么必须执行这一步**：
- 质量指标是评估下采样质量的**核心数据**，没有指标就无法进行专业分析
- 报告的"分析和建议"部分**必须**基于这些指标进行分析
- 如果跳过此步骤，报告将缺少关键信息，无法完成分析任务

**输出**：
- 指定的路径，若未指定则默认为 `dataset_root/metrics_result.json` - 包含所有变量的 SSIM、Relative L2、MSE、RMSE 指标

**⚠️ Agent 禁止行为**：
- ❌ 跳过质量指标计算直接生成报告
- ❌ 在报告中说"质量指标未计算"或"建议手动计算指标"
- ❌ 使用模板化的分析内容而不基于实际指标数据

#### 第一步：调用报告生成工具

```json
{
  "dataset_root": "/output/dataset"
}
```

工具会自动查找以下文件：
- `ocean_preprocess_temp/inspect_result.json` - Step A 数据检查结果
- `ocean_preprocess_temp/validate_result.json` - Step B 张量验证结果
- `ocean_preprocess_temp/convert_result.json` - Step C 完整转换结果（包含后置验证、warnings、errors）
- `preprocess_manifest.json` - 输入配置清单（dyn_vars, stat_vars等）
- `metrics_result.json` - 质量指标结果（如果执行了第零步）
- `visualisation_data_process/*.png` - 可视化对比图

#### 第二步：读取生成的报告

报告会保存在 `dataset_root/preprocessing_report.md`。

**重要**：报告的第 6 节"分析和建议"包含一个占位符注释：
```markdown
## 6. 分析和建议

<!-- AGENT_ANALYSIS_PLACEHOLDER
...
-->
```

#### 第三步：Agent 必须填写分析

**你必须做的事**：

1. **仔细阅读报告中的所有数据**：
   - 数据集概览（文件数、变量分类）
   - 验证结果（是否通过、有无警告）
   - 质量指标（SSIM、Relative L2 等）
   - 可视化图片（如果可以查看）

2. **分析数据质量**，包括但不限于：
   - **SSIM 指标分析**: 哪些变量的结构相似性好/差？为什么？
   - **Relative L2 误差分析**: 误差分布是否合理？是否有异常值？
   - **数据量评估**: 数据量是否充足？训练集/验证集/测试集划分是否合理？
   - **变量选择建议**: 是否所有变量都需要？是否有冗余？
   - **验证结果解读**: 所有验证规则是否通过？如果有警告，如何处理？
   - **下采样质量评估**: 下采样方法是否合适？是否需要调整？
   - **潜在问题识别**: 数据中是否存在异常、缺失值、不一致等问题？
   - **改进建议**: 如何提升数据质量？如何优化预处理流程？

3. **编写专业的分析**：
   - 使用清晰、专业的语言
   - 提供具体的数值和例子
   - 避免模板化的内容
   - 给出可操作的建议

4. **替换占位符**：
   - 读取报告文件
   - 找到占位符注释
   - 用你的分析替换整个注释块
   - 保存报告

#### 第四步：向用户展示报告

告知用户报告已生成，并简要总结关键发现。

### 分析示例

**好的分析**：
```markdown
## 6. 分析和建议

### 6.1 数据质量评估

本次预处理的数据质量整体良好，所有验证规则均通过。以下是详细分析：

**SSIM 指标分析**：
- `uo` 和 `vo` 变量的 SSIM 值分别为 0.9234 和 0.9187，表明下采样后保持了良好的结构相似性
- `temp` 变量的 SSIM 最高（0.9512），说明温度场的空间结构在下采样过程中保留得最好
- 所有变量的 SSIM 均 > 0.91，符合超分辨率训练的质量要求

**Relative L2 误差分析**：
- 所有变量的相对误差均 < 5%，其中 `temp` 最低（2.34%）
- `vo` 变量的误差略高（4.89%），可能是因为 v 方向流速的空间变化更剧烈
- 建议在训练时对 `vo` 变量给予更多关注

### 6.2 数据集划分评估

- 训练集 255 个时间步（70%），验证集 55 个（15%），测试集 55 个（15%）
- 数据量充足，足以支持深度学习模型训练
- 按时间顺序划分，符合时间序列数据的最佳实践

### 6.3 改进建议

1. **下采样方法优化**: 当前使用 `area` 方法，如需进一步提升质量，可尝试 `bicubic` 方法
2. **变量权重**: 建议在训练时对 `vo` 变量使用更高的损失权重
3. **数据增强**: 可考虑添加旋转、翻转等数据增强策略
```

**不好的分析**（避免）：
```markdown
## 6. 分析和建议

数据质量良好，所有指标正常，可以用于训练。
```

### ⚠️ 禁止行为

- ❌ 不读取报告就直接说"报告已生成"
- ❌ 不分析数据就使用模板化的内容
- ❌ 只说"数据质量良好"而不提供具体分析
- ❌ 忽略占位符，不填写分析部分
- ❌ 复制粘贴示例分析而不根据实际数据调整

## 错误解释指南

当工具返回错误时，按以下方式向用户解释：

### 路径/文件错误（最常见）

| 错误关键词 | 向用户解释 |
|-----------|-----------|
| `没有找到任何动态变量` | "您提供的数据文件中没有找到带时间维度的变量。**这很可能是因为您把静态文件路径填到了动态数据目录**。动态数据文件应该包含如 uo, vo, temp 等随时间变化的变量。" |
| `研究变量不在动态变量候选列表中` | "您指定的研究变量在数据文件的动态变量中不存在。请检查变量名是否拼写正确，或者查看工具返回的可用动态变量列表。" |
| `未找到匹配的动态数据文件` | "在指定目录下没有找到 NC 文件。请检查：1) 目录路径是否正确；2) 文件匹配模式是否匹配您的文件名。" |

### 数据质量错误

| 错误关键词 | 向用户解释 |
|-----------|-----------|
| `含有非法值: NaN=xxx` | "检测到变量中存在 NaN（缺失值），共 xxx 个。这可能是数据源问题。如果这是预期的（如陆地区域填充），可以设置 allow_nan=true 跳过检查。" |
| `含有非法值: Inf=xxx` | "检测到变量中存在 Inf（无穷大），共 xxx 个。这通常是数值计算溢出导致，请检查数据源。" |
| `坐标变量 'xxx' 包含 NaN` | "坐标变量中存在 NaN，这是严重错误。坐标不允许有缺失值，请检查静态文件是否损坏。" |

### 维度错误

| 错误关键词 | 向用户解释 |
|-----------|-----------|
| `有零长度维度` | "变量的某个维度长度为 0，数据是空的。请检查文件是否完整，或文件匹配模式是否正确。" |
| `维度数量错误: 实际 2D` | "该变量是 2D，但动态变量应该是 3D [时间,高度,宽度] 或 4D [时间,深度,高度,宽度]。请确认这是否是动态变量。" |
| `维度数量错误: 实际 5D` | "该变量是 5D，超出支持范围（最多 4D）。可能需要先降维处理。" |

### 静态文件错误

| 错误关键词 | 向用户解释 |
|-----------|-----------|
| `静态文件不存在` | "指定的静态文件路径不存在，请检查路径是否正确。" |
| `掩码形状不匹配` | "掩码变量的形状与动态数据的空间维度不一致，无法正确应用掩码。请检查静态文件是否与动态数据匹配。" |

---

## ⚠️ 警告处理指南（必读）

**核心原则**：有警告时必须暂停并询问用户，不能直接继续。

### 需要暂停并询问的警告类型

| 警告类型 | 警告关键词 | 必须询问用户 |
|----------|-----------|-------------|
| 形状不匹配 | `形状不匹配`、`shape mismatch` | ✅ 是 |
| 缺少掩码 | `未找到掩码`、`缺少 mask` | ✅ 是 |
| NaN 值存在 | `含有 NaN`、`NaN=` | ✅ 是（即使 allow_nan=true） |
| 掩码非二值 | `掩码不是二值`、`not binary` | ✅ 是 |
| 坐标范围异常 | `超出范围`、`out of range` | ✅ 是 |
| 时间不单调 | `时间不单调`、`not monotonic` | ✅ 是 |
| 启发式验证失败 | `陆地零值比例`、`海洋零值比例` | ✅ 是 |

### 如何向用户展示警告

```
⚠️ 处理过程中发现以下警告：

1. **形状不匹配**: 动态数据 (2041×4320) 与静态数据 (100×200) 形状不同
   - 这意味着动态数据和静态数据来自不同分辨率的网格
   - 可能导致掩码无法正确对应到数据点

2. **缺少掩码**: 未找到 mask_u 掩码变量
   - u 方向的流速数据将没有陆地掩码保护
   - 可能影响后续的超分辨率训练

这些警告需要您确认是否继续：
- 如果这是预期的情况，请回复"确认继续"
- 如果需要更正，请告诉我正确的文件路径或配置
```

### 用户可能的回复及处理

| 用户回复 | 你应该做的 |
|----------|-----------|
| "确认继续"/"没关系"/"可以" | 记录用户已确认，报告最终结果 |
| "不对，应该是..."/"重新处理" | 根据用户新提供的信息重新调用工具 |
| "这是什么意思？" | 详细解释该警告的含义和可能影响 |

---

## 单独使用 ocean_inspect_data

当用户只想查看数据有什么变量时：

```json
{
  "nc_folder": "/data/ocean",
  "static_file": "/data/ocean/grid.nc"
}
```

**返回**：
```json
{
  "status": "success",
  "file_count": 365,
  "dynamic_vars_candidates": ["uo", "vo", "temp", "salt"],
  "suspected_masks": ["mask_rho", "mask_u"],
  "suspected_coordinates": ["lon_rho", "lat_rho", "h"]
}
```

**你应该做的**：向用户展示变量列表和分类建议。

---

## 常见用户问法处理

| 用户说 | Agent 应该做什么 |
|--------|-----------------|
| "帮我预处理海洋数据" | 追问数据目录、输出目录，然后分析数据 |
| "数据在 /data/ocean，输出到 /out" | 先分析数据，展示变量让用户选择 |
| "数据在 /data，变量是 chl no3，输出到 /out" | 分析数据，追问处理参数（下采样倍数等） |
| "...4倍下采样，area方法，0.7/0.15/0.15" | 记下参数，分析数据，执行前 check 确认 |
| "看看 /data 有什么变量" | 调用 ocean_inspect_data，只展示不处理 |

**核心原则**：
1. 用户说了什么就记下什么，不要遗漏
2. 需要分析数据才知道的 → 先分析再让用户选
3. 用户可以决定的 → 直接追问
4. 执行前必须让用户确认所有参数

---

## 参数速查表

### ocean_preprocess_full

| 参数 | 类型 | 必需 | 默认值 | 说明 |
|------|------|------|--------|------|
| nc_folder | string | ✅ | - | NC 文件目录（也可以是单个文件路径，会自动转换） |
| nc_files | string[] | 否 | - | 明确指定要处理的文件列表（支持通配符如 `ocean_*.nc`） |
| output_base | string | ✅ | - | 输出目录 |
| dyn_vars | string[] | ✅ | - | 研究变量 |
| static_file | string | 否 | - | 静态文件路径 |
| dyn_file_pattern | string | 否 | "*.nc" | 文件匹配模式（当 nc_files 未指定时使用） |
| mask_vars | string[] | ⚠️ 推荐 | 从数据检测 | 掩码变量（必须用户确认） |
| stat_vars | string[] | ⚠️ 推荐 | 从数据检测 | 静态变量（必须用户确认） |
| lon_var | string | ⚠️ 推荐 | 从数据检测 | 经度变量名（禁止硬编码默认值） |
| lat_var | string | ⚠️ 推荐 | 从数据检测 | 纬度变量名（禁止硬编码默认值） |
| allow_nan | boolean | 否 | false | 允许 NaN/Inf（必须用户确认） |
| lon_range | [min,max] | 否 | - | 经度范围验证 |
| lat_range | [min,max] | 否 | - | 纬度范围验证 |
| train_ratio | number | ✅ | - | 训练集比例（必须由用户指定） |
| valid_ratio | number | ✅ | - | 验证集比例（必须由用户指定） |
| test_ratio | number | ✅ | - | 测试集比例（必须由用户指定） |
| scale | number | ⚠️ 条件 | - | 下采样倍数（下采样模式必须指定） |
| downsample_method | string | ⚠️ 条件 | - | 下采样方法（下采样模式必须指定） |
| skip_downsample | boolean | 否 | false | 跳过下采样步骤 |
| skip_visualize | boolean | 否 | false | 跳过可视化步骤 |
| **lr_nc_folder** | string | ⚠️ 条件 | - | **粗网格模式：LR 数据目录（提供此参数启用粗网格模式）** |
| **lr_static_file** | string | 否 | - | **粗网格模式：LR 静态文件路径** |
| **lr_dyn_file_pattern** | string | 否 | 同 dyn_file_pattern | **粗网格模式：LR 文件匹配模式** |

**⚠️ 条件参数说明**：
- **下采样模式**：必须提供 `scale` 和 `downsample_method`
- **粗网格模式**：必须提供 `lr_nc_folder`，此时不需要 `scale` 和 `downsample_method`

**⚠️ 注意**：标注为"推荐"的参数，如果未从数据中检测到，必须由用户明确提供。禁止使用硬编码默认值！

### nc_files 参数使用示例

```json
// 处理目录中所有 NC 文件
{ "nc_folder": "/data/ocean" }

// 只处理特定文件
{ "nc_folder": "/data/ocean", "nc_files": ["ocean_avg_001.nc", "ocean_avg_002.nc"] }

// 使用通配符
{ "nc_folder": "/data/ocean", "nc_files": ["ocean_avg_*.nc"] }

// 排除静态文件（只处理动态文件）
{ "nc_folder": "/data/ocean", "nc_files": ["ocean_avg_*.nc"], "static_file": "/data/ocean/grid.nc" }
```

### ocean_inspect_data

| 参数 | 类型 | 必需 | 默认值 | 说明 |
|------|------|------|--------|------|
| nc_folder | string | ✅ | - | NC 文件目录 |
| nc_files | string[] | 否 | - | 明确指定要处理的文件列表（支持通配符） |
| static_file | string | 否 | - | 静态文件路径 |
| dyn_file_pattern | string | 否 | "*.nc" | 文件匹配模式（当 nc_files 未指定时使用） |
| mask_vars | string[] | 否 | - | 明确指定掩码变量列表，用于变量分类 |
| static_vars | string[] | 否 | - | 明确指定静态变量列表，用于变量分类 |

---

## 检查清单

执行预处理前确认：
- [ ] 用户提供了数据**目录**路径（不是文件路径！）
- [ ] 用户明确指定了研究变量（不要猜测）
- [ ] 用户提供了输出目录路径
- [ ] 如果有静态文件，已获取路径

收到 awaiting_confirmation 后确认：
- [ ] 已向用户展示疑似变量
- [ ] 用户已确认掩码变量和静态变量
- [ ] 用户已确认 NaN 处理方式
- [ ] 第二次调用时**同时**提供了所有必要参数

---

## ⛔ 禁止行为清单（v2.8 更新）

以下行为是**严格禁止**的：

### 变量选择（必须由用户决定）

| 禁止行为 | 原因 | 正确做法 |
|----------|------|----------|
| **⚠️ 自动决定研究变量（dyn_vars）** | Agent 不知道用户的研究目的 | 展示动态变量候选，询问"您要研究哪些变量？" |
| **⚠️ 自动决定静态变量（stat_vars）** | 用户可能不需要全部保存 | 展示检测到的坐标变量，询问"需要保存哪些？" |
| **⚠️ 自动决定掩码变量（mask_vars）** | 不同场景需要不同掩码 | 展示检测到的掩码，询问"使用哪个掩码？" |
| 自动选择主掩码变量 | 不同场景需要不同掩码 | 让用户确认或告知选择 |
| 自动推导 mask_u/mask_v | 推导方式可能不适合所有情况 | 让用户明确指定 |

### 参数决策（必须由用户决定）

| 禁止行为 | 原因 | 正确做法 |
|----------|------|----------|
| 使用硬编码变量名（如 lon_rho, mask_rho） | 不同数据集变量名不同 | 从数据检测或让用户指定 |
| 自动决定 NaN 处理方式 | 用户对数据质量有不同要求 | 询问用户是否允许 NaN |
| **⚠️ 自动决定数据集划分比例** | 用户有不同的训练需求 | 询问 train/valid/test 比例 |
| **⚠️ 自动决定下采样参数** | 不同任务的超分倍数不同 | 询问 scale 和插值方法 |

### 流程控制（禁止跳过）

| 禁止行为 | 原因 | 正确做法 |
|----------|------|----------|
| **收到 awaiting_confirmation 后直接继续处理** | 用户尚未确认变量配置 | **必须等待用户逐一确认** |
| **第一次调用就提供 mask_vars/stat_vars** | 跳过了用户确认流程 | 第一次不提供，等用户确认后第二次再提供 |
| **检测到静态文件混入时不告知用户** | 可能导致处理错误 | 展示混入的文件列表，询问如何处理 |
| **⚠️ 跳过 Step 6 执行前确认** | 用户可能想修改参数 | 必须完整展示所有参数，等用户说"确认执行" |
| **⚠️ 预处理完成后跳过质量指标计算** | 报告分析必须基于指标数据 | **必须调用 ocean_metrics 工具** |
| **⚠️ 未计算指标就生成报告** | 报告将缺少核心数据 | 先调用 ocean_metrics，再调用 ocean_generate_report |
| 在有警告时继续处理 | 可能产生错误结果 | 展示警告并等待确认 |

### 错误处理（禁止自动重试）

| 禁止行为 | 原因 | 正确做法 |
|----------|------|----------|
| **⚠️ 遇到错误后自动重试** | 用户不知道发生了什么 | 展示错误，询问用户如何处理 |
| **⚠️ 自动更换输出路径** | 用户可能有特定的路径要求 | 告知权限问题，让用户指定新路径 |
| **⚠️ 自动调整并行参数** | 不同环境的最优值不同 | 告知内存问题，建议值让用户确认 |

---

## ⛔ 错误处理原则（v2.7 新增）

当工具返回错误时，Agent **必须**：

1. **向用户清晰展示错误信息**，包括：
   - 错误类型（权限、内存、数据格式等）
   - 具体错误内容
   - 可能的原因

2. **绝不自动尝试修复**，以下行为是**禁止**的：
   - ❌ 自动更换输出路径
   - ❌ 自动减少并行线程数
   - ❌ 自动去掉某些变量
   - ❌ 自动调整参数后重试

3. **询问用户如何处理**，示例：
   ```
   遇到以下错误：

   ❌ 权限错误: 无法写入 /data/tmp/output

   可能的原因：
   - 目录所有者是其他用户
   - 当前用户没有写权限

   请选择处理方式：
   1. 指定一个新的输出目录（您有写权限的路径）
   2. 联系管理员获取目录写权限

   请告诉我您的选择。
   ```

4. **等待用户确认后再重试**
   - 必须等到用户明确回复后才能继续
   - 用户可能需要修改参数或放弃操作

### 常见错误处理示例

| 错误类型 | 正确处理方式 |
|----------|-------------|
| 权限错误 | 告知用户，让用户指定新路径 |
| 内存不足/段错误 | 告知用户，建议减少并行度（如 workers=4），让用户确认 |
| 1D 坐标不支持 | 解释原因，询问是否要跳过这些坐标变量 |
| 文件格式错误 | 展示错误详情，让用户检查数据文件 |
| NaN 值检测 | 即使用户之前说了 allow_nan=true，也要展示 NaN 统计信息并再次确认 |

---

## ⚠️ 强制确认机制（v2.2.1 新增）

**工具行为**：
- 如果调用 `ocean_preprocess_full` 时**没有同时提供** `mask_vars` 和 `stat_vars`
- 工具会**强制返回** `awaiting_confirmation` 状态
- 即使数据分析完全成功，也不会继续处理

**Agent 必须做的事**：
1. 第一次调用只提供 `nc_folder`, `output_base`, `dyn_vars`
2. 收到 `awaiting_confirmation` 后，向用户展示：
   - 检测到的动态变量候选
   - 检测到的疑似掩码变量
   - 检测到的疑似坐标变量
3. **逐一询问用户**：
   - "您要研究的变量是 xxx 吗？"
   - "掩码变量使用 xxx 吗？"
   - "需要保存哪些静态变量？"
   - "是否允许数据中有 NaN 值？"
   - "数据集划分比例是多少？（train/valid/test）"
   - "需要裁剪数据吗？如果需要，请指定 h_slice 和 w_slice"
4. **等待用户逐一确认**
5. 用户确认后，第二次调用时提供所有确认的参数

---

## 完整超分预处理流程（v2.6 更新）

### 流程概览

`ocean_preprocess_full` 执行 A→B→C→D→E 五个步骤，支持两种模式：

**下采样模式**：
```
NC 文件 → [Step A: 数据检查]
              ↓
         [Step B: 张量验证]
              ↓
         [Step C: 转换+裁剪+划分] → HR 数据
              ↓
         [Step D: 下采样] → LR 数据
              ↓
         [Step E: 可视化检查] → 对比图
              ↓
         [独立步骤] ocean_metrics → 质量指标
              ↓
         [独立步骤] ocean_generate_report → 预处理报告
```

**粗网格模式（v2.6 新增）**：
```
HR NC 文件 → [Step A: 数据检查]
                ↓
            [Step B: 张量验证]
                ↓
            [Step C: HR 转换+裁剪+划分] → HR 数据
                ↓
LR NC 文件 → [Step C2: LR 转换+裁剪+划分] → LR 数据
                ↓
            [Step E: 可视化检查] → 对比图
                ↓
            [独立步骤] ocean_metrics → 质量指标
                ↓
            [独立步骤] ocean_generate_report → 预处理报告
```

**重要说明**：
- `ocean_preprocess_full` 只执行 A→B→C→(C2)→D→E 步骤
- **质量指标计算**和**报告生成**是独立工具，必须手动调用
- **强制工作流程**（不可跳过任何步骤）：
  1. `ocean_preprocess_full` - 数据预处理
  2. `ocean_metrics` - 计算质量指标（**必须执行**）
  3. `ocean_generate_report` - 生成报告
  4. Agent 读取报告并填写专业分析
            [Step E: 可视化检查] → 对比图
```

### 一键执行完整流程

使用 `ocean_preprocess_full` 工具，提供必要参数后自动完成所有步骤：

**下采样模式示例**：
```json
{
  "nc_folder": "/data/ocean",
  "output_base": "/output/dataset",
  "dyn_vars": ["chl", "no3"],
  "user_confirmed": true,
  "train_ratio": 0.7,
  "valid_ratio": 0.15,
  "test_ratio": 0.15,
  "h_slice": "0:680",
  "w_slice": "0:1440",
  "scale": 4,
  "downsample_method": "area"
}
```

**粗网格模式示例（v2.6 新增）**：
```json
{
  "nc_folder": "/data/ocean_hr",
  "output_base": "/output/dataset",
  "dyn_vars": ["chl", "no3"],
  "user_confirmed": true,
  "train_ratio": 0.7,
  "valid_ratio": 0.15,
  "test_ratio": 0.15,
  "lr_nc_folder": "/data/ocean_lr",
  "lr_static_file": "/data/ocean_lr/grid.nc"
}
```

**输出目录结构**：
```
/output/dataset/
├── train/
│   ├── hr/
│   │   ├── chl.npy
│   │   └── no3.npy
│   └── lr/
│       ├── chl.npy
│       └── no3.npy
├── valid/
│   ├── hr/
│   └── lr/
├── test/
│   ├── hr/
│   └── lr/
├── static_variables/
└── visualisation_data_process/
    ├── train/*.png
    ├── valid/*.png
    └── test/*.png
```

### 新增参数

| 参数 | 类型 | 必需 | 默认值 | 说明 |
|------|------|------|--------|------|
| scale | number | ✅ 是 | - | 下采样倍数（必须由用户指定） |
| downsample_method | string | ✅ 是 | - | 下采样插值方法：area/cubic/linear/nearest/lanczos |
| skip_downsample | boolean | 否 | false | 跳过下采样步骤 |
| skip_visualize | boolean | 否 | false | 跳过可视化步骤 |

**插值方法说明**：
- `area`（推荐）：区域平均，最接近真实低分辨率采样
- `cubic`：三次插值，较平滑
- `linear`：双线性插值
- `nearest`：最近邻插值，保留原始值
- `lanczos`：Lanczos 插值，高质量但计算较慢

### 单独执行各步骤（可选）

如果需要单独控制某个步骤，可以使用独立工具：

#### Step 1: NC → NPY 转换（含裁剪和划分）

使用 `ocean_downsample` 工具：

```json
{
  "dataset_root": "/output/dataset",
  "scale": 4,
  "method": "area"
}
```

**参数说明**：
- `scale`: 下采样倍数（如 4 表示尺寸缩小为 1/4）
- `method`: 插值方法
  - `area`（推荐）：区域平均，最接近真实低分辨率
  - `cubic`：三次插值，较平滑
  - `linear`：双线性插值
  - `nearest`：最近邻插值，保留原始值
  - `lanczos`：Lanczos 插值，高质量
  - `lanczos`：Lanczos 插值

**输出**：
```
/output/dataset/
├── train/
│   ├── hr/  (已有)
│   └── lr/  ← 新生成
│       ├── chl.npy
│       └── no3.npy
├── valid/
│   ├── hr/
│   └── lr/  ← 新生成
└── test/
    ├── hr/
    └── lr/  ← 新生成
```

### Step 3: 可视化检查

使用 `ocean_visualize` 工具：

```json
{
  "dataset_root": "/output/dataset"
}
```

**输出**：
```
/output/dataset/
└── visualisation_data_process/
    ├── train/
    │   ├── chl.png
    │   └── no3.png
    ├── valid/
    └── test/
```

### Step 4: 质量指标检测

使用 `ocean_metrics` 工具：

```json
{
  "dataset_root": "/output/dataset",
  "scale": 4
}
```

**输出**：
```
/output/dataset/
└── metrics_result.json
```

**指标说明**：
- `SSIM`: 结构相似性 (0~1, 越接近 1 越好)
- `Relative L2`: 相对 L2 误差 (越小越好, HR 作为分母)
- `MSE`: 均方误差
- `RMSE`: 均方根误差

---

## 静态变量处理（v2.6 新增）

### 场景：动态文件中包含静态变量

有些数据集的动态文件中同时包含了静态变量（如 `lon_rho`, `lat_rho`, `mask_rho`），没有单独的静态文件。

**Agent 的处理能力**：

1. **自动检测**：`inspect_data` 会分析每个变量是否有时间维度：
   - 有时间维度 → 归类为"动态变量候选"
   - 无时间维度 + 名称包含 mask/land → 归类为"疑似掩码变量"
   - 无时间维度 + 名称包含 lon/lat/h 等 → 归类为"疑似静态变量"

2. **自动提取**：`convert_npy` 现在支持从动态文件中提取静态变量：
   - 如果提供了 `static_file`，从静态文件提取
   - 如果没有 `static_file`，自动从动态文件中提取

### 使用示例

**场景：数据只有动态文件，没有单独的静态文件**

```
用户: 我的数据在 /data/ocean，都是动态文件，里面有 chl、no3，还有 lon、lat、mask

Agent: 好的，我先分析数据...

[分析结果]
动态变量候选: chl, no3
疑似静态变量: lon, lat, h
疑似掩码变量: mask

请确认：
1. 研究变量是 chl, no3 吗？
2. 静态变量保存 lon, lat 吗？
3. 掩码变量使用 mask 吗？

用户: 是的

Agent: 好的，执行预处理...
（即使没有 static_file，也会自动从动态文件中提取 lon, lat, mask 保存到 static_variables/ 目录）
```

**工具调用参数**：
```json
{
  "nc_folder": "/data/ocean",
  "output_base": "/output/dataset",
  "dyn_vars": ["chl", "no3"],
  "stat_vars": ["lon", "lat", "mask"],
  "mask_vars": ["mask"],
  // 注意：不需要 static_file 参数
  ...
}
```

**输出结构**：
```
/output/dataset/
├── train/hr/
│   ├── chl.npy
│   └── no3.npy
├── static_variables/
│   ├── 00_lon.npy       ← 从动态文件中提取
│   ├── 10_lat.npy       ← 从动态文件中提取
│   └── 90_mask.npy      ← 从动态文件中提取
└── ...
```

---

## 新工具参数速查表

### ocean_downsample

| 参数 | 类型 | 必需 | 默认值 | 说明 |
|------|------|------|--------|------|
| dataset_root | string | ✅ | - | 数据集根目录 |
| scale | number | ✅ | - | 下采样倍数 |
| method | string | 否 | "area" | 插值方法 |
| splits | string[] | 否 | ["train","valid","test"] | 要处理的划分 |
| include_static | boolean | 否 | false | 是否处理静态变量 |

### ocean_visualize

| 参数 | 类型 | 必需 | 默认值 | 说明 |
|------|------|------|--------|------|
| dataset_root | string | ✅ | - | 数据集根目录 |
| splits | string[] | 否 | ["train","valid","test"] | 要检查的划分 |
| out_dir | string | 否 | dataset_root/visualisation_data_process | 输出目录 |

### ocean_metrics

| 参数 | 类型 | 必需 | 默认值 | 说明 |
|------|------|------|--------|------|
| dataset_root | string | ✅ | - | 数据集根目录 |
| scale | number | ✅ | - | 下采样倍数 |
| splits | string[] | 否 | ["train","valid","test"] | 要检查的划分 |
| output | string | 否 | dataset_root/metrics_result.json | 输出文件路径 |

---

## 裁剪参数说明（v2.4 新增）

### 为什么需要裁剪？

超分辨率训练要求 HR 尺寸能被 scale 整除：
```
HR: (680, 1440)  ← 能被 4 整除
LR: (170, 360)   ← 680÷4=170, 1440÷4=360

❌ HR: (681, 1440)  ← 681 不能被 4 整除
```

### 裁剪参数格式

| 格式 | 含义 | 示例 |
|------|------|------|
| `"0:680"` | 取 [0, 680) | `data[..., 0:680, :]` |
| `":680"` | 取 [0, 680) | 同上 |
| `"1:"` | 从 1 开始到末尾 | `data[..., 1:, :]` |
| `"1:-1"` | 去掉首尾各 1 行 | `data[..., 1:-1, :]` |

### 裁剪验证

如果提供了 `scale` 参数，工具会自动验证裁剪后的尺寸能否被整除：
- 能整除 → 继续处理
- 不能整除 → 报错并提示建议值

