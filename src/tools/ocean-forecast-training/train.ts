/**
 * @file train.ts
 * @description Ocean forecast training tool - 4-stage confirmation workflow
 * @author Leizheng
 * @date 2026-02-26
 * @version 1.1.0
 *
 * @changelog
 *   - 2026-02-26 Leizheng: v1.1.0 fix PASS phase reads device_ids from mergedParams instead of raw args
 *   - 2026-02-26 Leizheng: v1.0.0 initial version for ocean forecast training
 */

import { defineTool } from '@shareai-lab/kode-sdk'
import { findPythonWithModule, findFirstPythonPath } from '@/utils/python-manager'
import { trainingProcessManager } from '@/utils/training-process-manager'
import { saveOrAppendNotebook, generateForecastTrainCells } from './notebook'
import type { ForecastTrainNotebookParams } from './notebook'
import path from 'node:path'
import net from 'node:net'
import {
  ForecastTrainingWorkflow,
  ForecastTrainingState,
  type ForecastWorkflowParams,
  type ForecastDatasetInfo,
  type GpuInfo,
  type ModelInfo,
} from './workflow-state'

/** è®­ç»ƒä¼šè¯å‚æ•°ç¼“å­˜æ–‡ä»¶åï¼Œç”¨äºè·¨æ— çŠ¶æ€è°ƒç”¨ä¿ç•™ç”¨æˆ·ç¡®è®¤è¿‡çš„å‚æ•° */
const SESSION_FILENAME = '.ocean_forecast_session.json'

/** ä» log_dir è¯»å–ä¿å­˜çš„è®­ç»ƒä¼šè¯å‚æ•°ï¼ˆä¸å­˜åœ¨æˆ–è§£æå¤±è´¥æ—¶è¿”å› nullï¼‰ */
async function loadSessionParams(
  logDir: string,
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  ctx: any,
): Promise<ForecastWorkflowParams | null> {
  try {
    const sessionPath = path.join(logDir, SESSION_FILENAME)
    const content = await ctx.sandbox.fs.read(sessionPath)
    const parsed = JSON.parse(content)
    return (parsed?.params as ForecastWorkflowParams) ?? null
  } catch {
    return null
  }
}

/** å°†å½“å‰å…¨é‡å‚æ•°å†™å…¥ log_dir çš„ä¼šè¯ç¼“å­˜æ–‡ä»¶ */
async function saveSessionParams(
  logDir: string,
  params: ForecastWorkflowParams,
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  ctx: any,
): Promise<void> {
  try {
    const sessionPath = path.join(logDir, SESSION_FILENAME)
    await ctx.sandbox.fs.write(sessionPath, JSON.stringify({ savedAt: Date.now(), params }))
  } catch {
    // å†™å…¥å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
  }
}

/**
 * å°† JSON å­—ç¬¦ä¸²è½¬ä¹‰ä¸ºå¯ä»¥å®‰å…¨åµŒå…¥ shell å•å¼•å·çš„å½¢å¼
 * ç­–ç•¥ï¼šæ›¿æ¢å•å¼•å·ä¸º '\'' (ç»“æŸå•å¼•å· + è½¬ä¹‰å•å¼•å· + å¼€å§‹å•å¼•å·)
 * æ³¨ï¼šåœ¨ shell å•å¼•å·å†…ï¼Œåæ–œæ ç­‰å…¶ä»–å­—ç¬¦å‡ä¸ºå­—é¢é‡ï¼Œæ— éœ€é¢å¤–è½¬ä¹‰
 */
function shellSafeJson(json: string): string {
  return json.replace(/'/g, "'\\''")
}

/**
 * è½¬ä¹‰å­—ç¬¦ä¸²ä½¿å…¶å¯ä»¥å®‰å…¨åµŒå…¥ shell åŒå¼•å·
 * åœ¨åŒå¼•å·å†…æœ‰ç‰¹æ®Šå«ä¹‰çš„å­—ç¬¦ï¼š\ " $ ` !
 */
function shellEscapeDouble(str: string): string {
  return str.replace(/[\\"$`!]/g, '\\$&')
}

async function isPortFree(port: number): Promise<boolean> {
  return new Promise((resolve) => {
    const server = net.createServer()
    server.unref()
    server.once('error', () => resolve(false))
    server.listen(port, () => {
      server.close(() => resolve(true))
    })
  })
}

async function findFreePort(start = 29500, end = 29600): Promise<number | null> {
  for (let port = start; port <= end; port += 1) {
    // eslint-disable-next-line no-await-in-loop
    if (await isPortFree(port)) return port
  }
  return null
}

function extractTaggedJson(output: string, tag: string): Record<string, unknown> | null {
  const pattern = new RegExp(`__${tag}__([\\s\\S]*?)__${tag}__`)
  const match = output.match(pattern)
  if (!match) return null
  try {
    return JSON.parse(match[1])
  } catch {
    return null
  }
}

async function validateDataset(
  datasetRoot: string,
  pythonPath: string,
  trainingDir: string,
  ctx: { sandbox: { exec: (cmd: string, options?: { timeoutMs?: number }) => Promise<{ code: number; stdout: string; stderr: string }> } },
): Promise<ForecastDatasetInfo> {
  const validateScript = path.join(trainingDir, 'validate_dataset.py')
  const validateResult = await ctx.sandbox.exec(
    `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(validateScript)}" --dataset_root "${shellEscapeDouble(datasetRoot)}"`,
    { timeoutMs: 60000 }
  )
  if (validateResult.code === 0) {
    return JSON.parse(validateResult.stdout)
  }

  return {
    status: 'error',
    dataset_root: datasetRoot,
    dyn_vars: [],
    spatial_shape: null,
    splits: {},
    total_timesteps: 0,
    time_range: null,
    has_static: false,
    static_vars: [],
    warnings: [],
    errors: [`éªŒè¯è„šæœ¬æ‰§è¡Œå¤±è´¥: ${validateResult.stderr}`]
  }
}

/**
 * è°ƒç”¨ recommend_hyperparams.py è·å–è¶…å‚æ•°æ¨èã€‚
 * å¤±è´¥æ—¶è¿”å› nullï¼Œä¸æŠ›å‡ºå¼‚å¸¸ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰ã€‚
 */
async function runHyperparamRecommendation(
  args: {
    dataset_root?: string
    model_name?: string
    dyn_vars?: string[]
    in_t?: number
    out_t?: number
    device_ids?: number[]
  },
  pythonPath: string,
  trainingDir: string,
  ctx: { sandbox: { exec: (cmd: string, options?: { timeoutMs?: number }) => Promise<{ code: number; stdout: string; stderr: string }> } },
): Promise<Record<string, unknown> | null> {
  if (!args.dataset_root || !args.model_name || !args.dyn_vars?.length) {
    return null
  }
  try {
    const recommendScript = path.join(trainingDir, 'recommend_hyperparams.py')
    const deviceId = Number(args.device_ids?.[0] ?? 0)
    const inT = args.in_t ?? 7
    const outT = args.out_t ?? 1
    const cmd = [
      `cd "${shellEscapeDouble(trainingDir)}"`,
      `&&`,
      `CUDA_VISIBLE_DEVICES=${deviceId}`,
      `"${shellEscapeDouble(pythonPath)}"`,
      `"${shellEscapeDouble(recommendScript)}"`,
      `--dataset_root "${shellEscapeDouble(args.dataset_root)}"`,
      `--model_name "${shellEscapeDouble(args.model_name)}"`,
      `--dyn_vars "${shellEscapeDouble(args.dyn_vars.join(','))}"`,
      `--in_t ${inT}`,
      `--out_t ${outT}`,
      `--device 0`,
    ].join(' ')
    const result = await ctx.sandbox.exec(cmd, { timeoutMs: 180000 })
    if (result.code !== 0) return null
    return extractTaggedJson(result.stdout, 'recommend')
  } catch {
    return null
  }
}

/**
 * å°†è¶…å‚æ•°æ¨èç»“æœæ ¼å¼åŒ–ä¸ºç”¨æˆ·å¯è¯»çš„æ¶ˆæ¯æ®µè½ã€‚
 */
function formatRecommendationMessage(rec: Record<string, unknown>): string {
  const recommendations = rec.recommendations as Record<string, unknown> | undefined
  const reasoning = rec.reasoning as Record<string, unknown> | undefined
  const datasetInfo = rec.dataset_info as Record<string, unknown> | undefined
  const gpuInfo = rec.gpu_info as Record<string, unknown> | undefined
  const spectral = rec.spectral_analysis as Record<string, unknown> | undefined
  const modelNotes = rec.model_notes as Record<string, unknown> | undefined

  if (!recommendations) return ''

  const lines: string[] = [
    '================================================================================',
    '                    ğŸ’¡ è¶…å‚æ•°æ¨èï¼ˆåŸºäºå®æµ‹æ˜¾å­˜ + æ•°æ®åˆ†æï¼‰',
    '================================================================================',
  ]

  // æ•°æ®é›† & GPU åŸºæœ¬ä¿¡æ¯
  if (datasetInfo || gpuInfo) {
    lines.push('\nã€åˆ†æåŸºç¡€ã€‘')
    if (datasetInfo) {
      lines.push(`- è®­ç»ƒé›†ï¼š${datasetInfo.n_train} ä¸ªæ ·æœ¬ï¼Œç©ºé—´åˆ†è¾¨ç‡ ${(datasetInfo.spatial_shape as number[])?.join(' Ã— ') ?? '?'}ï¼Œ${datasetInfo.n_vars} ä¸ªå˜é‡`)
    }
    if (gpuInfo && gpuInfo.name) {
      lines.push(`- GPUï¼š${gpuInfo.name}ï¼ˆ${gpuInfo.total_gb ?? '?'} GBï¼‰`)
    }
  }

  // æ¨èå‚æ•°
  lines.push('\nã€æ¨èå‚æ•°ã€‘')
  if (recommendations.batch_size !== undefined)
    lines.push(`- batch_size:        ${recommendations.batch_size}`)
  if (recommendations.eval_batch_size !== undefined)
    lines.push(`- eval_batch_size:   ${recommendations.eval_batch_size}`)
  if (recommendations.epochs !== undefined)
    lines.push(`- epochs:            ${recommendations.epochs}`)
  if (recommendations.lr !== undefined)
    lines.push(`- lr:                ${(recommendations.lr as number).toExponential(2)}`)
  if (recommendations.gradient_checkpointing !== undefined)
    lines.push(`- gradient_checkpointing: ${recommendations.gradient_checkpointing}`)

  // æ¨èç†ç”±
  if (reasoning && Object.keys(reasoning).length > 0) {
    lines.push('\nã€æ¨èç†ç”±ã€‘')
    for (const [key, val] of Object.entries(reasoning)) {
      lines.push(`- ${key}: ${val}`)
    }
  }

  // é¢‘è°±åˆ†æ
  if (spectral) {
    lines.push('\nã€æ•°æ®é¢‘è°±åˆ†æï¼ˆä»…ä¾›å‚è€ƒï¼Œä¸è‡ªåŠ¨ä¿®æ”¹æ¨¡å‹ç»“æ„ï¼‰ã€‘')
    lines.push(`- é¢‘ç‡ç‰¹å¾ï¼š${spectral.freq_desc}ï¼ˆk90 â‰ˆ ${spectral.k90_mean}ï¼Œmax_k = ${spectral.max_k}ï¼‰`)
  }

  // æ¨¡å‹ç‰¹å®šæç¤º
  if (modelNotes) {
    lines.push('\nã€æ¨¡å‹ç»“æ„å‚æ•°å‚è€ƒã€‘')
    for (const [, note] of Object.entries(modelNotes)) {
      lines.push(`- ${note}`)
    }
  }

  lines.push('\nâš ï¸ Agent æ³¨æ„ï¼šä»¥ä¸Šä¸ºç³»ç»Ÿæ¨èå€¼ï¼Œè¯·å‘ŠçŸ¥ç”¨æˆ·å¹¶è¯¢é—®æ˜¯å¦é‡‡ç”¨æˆ–è°ƒæ•´ï¼Œå†ç»§ç»­æ‰§è¡Œç¡®è®¤ã€‚')
  lines.push('================================================================================')

  return lines.join('\n')
}

export const oceanForecastTrainTool = defineTool({
  name: 'ocean_forecast_train_start',
  description: `æ‰§è¡Œæµ·æ´‹æ—¶åºé¢„æµ‹æ¨¡å‹è®­ç»ƒæˆ–æµ‹è¯•ã€‚

**åˆ†é˜¶æ®µç¡®è®¤æµç¨‹**ï¼ˆæ¯é˜¶æ®µå¿…é¡»ç­‰å¾…ç”¨æˆ·ç¡®è®¤ï¼‰ï¼š
1. ç¡®è®¤æ•°æ®ç›®å½•å’Œè¾“å‡ºç›®å½•ï¼ˆè‡ªåŠ¨æ£€æµ‹å˜é‡å’Œæ—¶åºä¿¡æ¯ï¼‰
2. é€‰æ‹©è®­ç»ƒæ¨¡å‹
3. ç¡®è®¤è®­ç»ƒå‚æ•°ï¼ˆåŒ…æ‹¬ GPU é€‰æ‹©ï¼‰
4. æœ€ç»ˆç¡®è®¤æ‰§è¡Œ

**é¦–æ¬¡è°ƒç”¨**ï¼šåªä¼  dataset_root å’Œ log_dirï¼Œå·¥å…·ä¼šè‡ªåŠ¨æ£€æµ‹æ•°æ®å¹¶å±•ç¤ºä¿¡æ¯
**é€æ­¥è¡¥å……å‚æ•°**ï¼šæ¯æ¬¡è°ƒç”¨è¡¥å……è¯¥é˜¶æ®µéœ€è¦çš„å‚æ•°ï¼Œç›´åˆ°æ‰€æœ‰é˜¶æ®µé€šè¿‡
**æœ€ç»ˆæ‰§è¡Œ**ï¼šä¼ å…¥ user_confirmed=true å’Œ confirmation_token åå¯åŠ¨åå°è®­ç»ƒ

**åå°æ‰§è¡Œæ¨¡å¼**ï¼š
- è®­ç»ƒå¯åŠ¨åç«‹å³è¿”å› process_idï¼Œä¸ä¼šé˜»å¡ç­‰å¾…è®­ç»ƒå®Œæˆ
- ä½¿ç”¨ ocean_forecast_train_status å·¥å…·æŸ¥è¯¢è®­ç»ƒçŠ¶æ€å’Œå®æ—¶æ—¥å¿—
- æœåŠ¡å™¨å…³é—­æ—¶ä¼šè‡ªåŠ¨ç»ˆæ­¢è®­ç»ƒè¿›ç¨‹

**è®­ç»ƒæ¨¡å¼ (mode=train)**ï¼šæ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹ï¼ŒåŒ…å«éªŒè¯å’Œæ—©åœ
**æµ‹è¯•æ¨¡å¼ (mode=test)**ï¼šåŠ è½½æœ€ä½³æ¨¡å‹ï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
**é¢„æµ‹æ¨¡å¼ (mode=predict)**ï¼šåŠ è½½æ¨¡å‹å¯¹æµ‹è¯•é›†æ‰§è¡Œå…¨é‡é¢„æµ‹ï¼Œè¾“å‡º NPY æ–‡ä»¶ï¼ˆè·³è¿‡è®­ç»ƒå·¥ä½œæµï¼‰

**GPU æ¨¡å¼**ï¼š
- å•å¡ï¼šdevice_ids é•¿åº¦ä¸º 1
- å¤šå¡ DPï¼šdistribute=true, distribute_mode="DP"
- å¤šå¡ DDPï¼ˆæ¨èï¼‰ï¼šdistribute=true, distribute_mode="DDP"`,

  params: {
    dataset_root: {
      type: 'string',
      description: 'é¢„å¤„ç†æ•°æ®æ ¹ç›®å½•ï¼ˆocean-forecast-data-preprocess è¾“å‡ºç›®å½•ï¼‰',
      required: false
    },
    log_dir: {
      type: 'string',
      description: 'è®­ç»ƒæ—¥å¿—è¾“å‡ºç›®å½•',
      required: false
    },
    model_name: {
      type: 'string',
      description: 'æ¨¡å‹åç§°ï¼ˆå¦‚ FNO2d, UNet2d, SwinTransformerV2 ç­‰ï¼‰',
      required: false
    },
    dyn_vars: {
      type: 'array',
      items: { type: 'string' },
      description: 'åŠ¨æ€å˜é‡åˆ—è¡¨ï¼ˆå¦‚ ["uo", "vo"]ï¼‰ã€‚å¦‚ä¸æä¾›ï¼Œå°†ä»æ•°æ®ç›®å½•è‡ªåŠ¨æ£€æµ‹å¹¶è¦æ±‚ç¡®è®¤ã€‚',
      required: false
    },
    in_t: {
      type: 'number',
      description: 'è¾“å…¥æ—¶é—´æ­¥æ•°ï¼ˆç”¨äºæ„å»ºæ—¶åºçª—å£ï¼‰',
      required: false
    },
    out_t: {
      type: 'number',
      description: 'è¾“å‡ºæ—¶é—´æ­¥æ•°ï¼ˆé¢„æµ‹æœªæ¥æ­¥æ•°ï¼‰',
      required: false
    },
    stride: {
      type: 'number',
      description: 'æ—¶é—´çª—å£æ»‘åŠ¨æ­¥é•¿',
      required: false
    },
    mode: {
      type: 'string',
      description: 'è¿è¡Œæ¨¡å¼: "train", "test" æˆ– "predict"ï¼ˆpredict è·³è¿‡è®­ç»ƒå·¥ä½œæµï¼Œç›´æ¥æ¨ç†ï¼‰',
      required: false,
      default: 'train'
    },
    epochs: {
      type: 'number',
      description: 'è®­ç»ƒè½®æ•°',
      required: false,
      default: 500
    },
    lr: {
      type: 'number',
      description: 'å­¦ä¹ ç‡',
      required: false,
      default: 0.001
    },
    batch_size: {
      type: 'number',
      description: 'è®­ç»ƒ batch size',
      required: false,
      default: 4
    },
    eval_batch_size: {
      type: 'number',
      description: 'è¯„ä¼° batch size',
      required: false,
      default: 4
    },
    device_ids: {
      type: 'array',
      items: { type: 'number' },
      description: 'ä½¿ç”¨çš„ GPU åˆ—è¡¨ï¼ˆå¦‚ [0, 1, 2, 3]ï¼‰ã€‚å¿…é¡»ç”±ç”¨æˆ·ç¡®è®¤ã€‚è‹¥å¯ç”¨å¤šå¡è®­ç»ƒï¼Œè‡³å°‘éœ€è¦ä¸¤ä¸ª GPUã€‚',
      required: false
    },
    distribute: {
      type: 'boolean',
      description: 'æ˜¯å¦å¯ç”¨å¤šå¡è®­ç»ƒ',
      required: false,
      default: false
    },
    distribute_mode: {
      type: 'string',
      description: 'å¤šå¡æ¨¡å¼: "DP" æˆ– "DDP"',
      required: false,
      default: 'DDP'
    },
    master_port: {
      type: 'number',
      description: 'DDP ä¸»ç«¯å£ï¼ˆå¯é€‰ï¼Œç«¯å£å†²çªæ—¶å¯æŒ‡å®šï¼‰',
      required: false
    },
    use_amp: {
      type: 'boolean',
      description: 'æ˜¯å¦å¯ç”¨ AMP æ··åˆç²¾åº¦è®­ç»ƒï¼ˆå‡å°‘çº¦ 40-50% æ˜¾å­˜ï¼‰',
      required: false
    },
    gradient_checkpointing: {
      type: 'boolean',
      description: 'æ˜¯å¦å¯ç”¨ Gradient Checkpointingï¼ˆå‡å°‘çº¦ 60% æ¿€æ´»æ˜¾å­˜ï¼Œå¢åŠ çº¦ 30% è®¡ç®—æ—¶é—´ï¼Œé»˜è®¤å¼€å¯ï¼‰',
      required: false,
      default: true
    },
    normalize: {
      type: 'boolean',
      description: 'æ˜¯å¦å½’ä¸€åŒ–',
      required: false,
      default: true
    },
    normalizer_type: {
      type: 'string',
      description: 'å½’ä¸€åŒ–ç±»å‹: "PGN" æˆ– "GN"',
      required: false,
      default: 'PGN'
    },
    optimizer: {
      type: 'string',
      description: 'ä¼˜åŒ–å™¨: "AdamW", "Adam", "SGD"',
      required: false,
      default: 'AdamW'
    },
    weight_decay: {
      type: 'number',
      description: 'æƒé‡è¡°å‡',
      required: false,
      default: 0.001
    },
    scheduler: {
      type: 'string',
      description: 'å­¦ä¹ ç‡è°ƒåº¦å™¨: "StepLR", "MultiStepLR", "OneCycleLR"',
      required: false,
      default: 'StepLR'
    },
    patience: {
      type: 'number',
      description: 'æ—©åœè€å¿ƒå€¼',
      required: false,
      default: 10
    },
    eval_freq: {
      type: 'number',
      description: 'è¯„ä¼°é¢‘ç‡ï¼ˆæ¯ N ä¸ª epochï¼‰',
      required: false,
      default: 5
    },
    seed: {
      type: 'number',
      description: 'éšæœºç§å­',
      required: false,
      default: 42
    },
    ckpt_path: {
      type: 'string',
      description: 'æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„',
      required: false
    },
    user_confirmed: {
      type: 'boolean',
      description: 'ã€å¿…é¡»ã€‘ç”¨æˆ·ç¡®è®¤æ ‡å¿—ã€‚å¿…é¡»åœ¨å±•ç¤ºå‚æ•°æ±‡æ€»å¹¶è·å¾—ç”¨æˆ·æ˜ç¡®ç¡®è®¤åï¼Œæ‰èƒ½è®¾ç½®ä¸º trueã€‚ç¦æ­¢è‡ªåŠ¨è®¾ç½®ï¼',
      required: false,
      default: false
    },
    confirmation_token: {
      type: 'string',
      description: 'æ‰§è¡Œç¡®è®¤ Tokenã€‚å¿…é¡»ä» awaiting_execution é˜¶æ®µçš„è¿”å›å€¼ä¸­è·å–ã€‚',
      required: false
    }
  },

  async exec(args, ctx) {
    // è®­ç»ƒå·¥å…·éœ€è¦ torchï¼Œä¼˜å…ˆæŸ¥æ‰¾å®‰è£…äº† torch çš„ Python
    const pythonPath = findPythonWithModule('torch') || findFirstPythonPath()
    if (!pythonPath) {
      throw new Error('æœªæ‰¾åˆ°å¯ç”¨çš„ Python è§£é‡Šå™¨ï¼ˆéœ€è¦å®‰è£… torchï¼‰')
    }

    const trainingDir = path.resolve(process.cwd(), 'scripts/ocean-forecast-training')

    // ===== 1. æ„å»ºå·¥ä½œæµå‚æ•°ï¼ˆåˆå¹¶ session ç¼“å­˜ï¼Œé˜²æ­¢å¯é€‰å‚æ•°è·¨è°ƒç”¨ä¸¢å¤±ï¼‰ =====
    const workflowArgs = { ...args }
    const sessionParams = args.log_dir ? await loadSessionParams(args.log_dir, ctx) : null
    const workflow = new ForecastTrainingWorkflow(workflowArgs, sessionParams ?? undefined)
    const stateCheck = workflow.determineCurrentState()

    // ===== 2. å¦‚æœæœªåˆ° PASS é˜¶æ®µï¼Œæ”¶é›†ä¸Šä¸‹æ–‡ä¿¡æ¯å¹¶è¿”å›æç¤º =====
    if (stateCheck.currentState !== ForecastTrainingState.PASS) {
      const context: {
        datasetInfo?: ForecastDatasetInfo
        gpuInfo?: GpuInfo
        modelList?: ModelInfo[]
      } = {}

      // å¦‚æœæœ‰ dataset_rootï¼ŒéªŒè¯æ•°æ®ç›®å½•
      if (args.dataset_root) {
        context.datasetInfo = await validateDataset(args.dataset_root, pythonPath, trainingDir, ctx)
      }

      // é˜¶æ®µ2+éœ€è¦æ¨¡å‹åˆ—è¡¨
      if (stateCheck.currentState === ForecastTrainingState.AWAITING_MODEL_SELECTION) {
        const listScript = path.join(trainingDir, 'list_models.py')
        const listResult = await ctx.sandbox.exec(
          `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(listScript)}"`,
          { timeoutMs: 30000 }
        )
        if (listResult.code === 0) {
          const parsed = JSON.parse(listResult.stdout)
          context.modelList = parsed.models
        }
      }

      // é˜¶æ®µ3+éœ€è¦ GPU ä¿¡æ¯
      if (
        stateCheck.currentState === ForecastTrainingState.AWAITING_PARAMETERS ||
        stateCheck.currentState === ForecastTrainingState.AWAITING_EXECUTION ||
        stateCheck.currentState === ForecastTrainingState.TOKEN_INVALID
      ) {
        const gpuScript = path.join(trainingDir, 'check_gpu.py')
        const gpuResult = await ctx.sandbox.exec(
          `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(gpuScript)}"`,
          { timeoutMs: 30000 }
        )
        if (gpuResult.code === 0) {
          context.gpuInfo = JSON.parse(gpuResult.stdout)
        }
      }

      const prompt = workflow.getStagePrompt(context)

      // AWAITING_EXECUTION æ—¶æŒä¹…åŒ–å…¨é‡å‚æ•°ï¼Œä¾›åç»­æ‰§è¡Œè°ƒç”¨æ¢å¤å¯é€‰å‚æ•°ï¼ˆå¦‚ normalizer_typeï¼‰
      if (stateCheck.currentState === ForecastTrainingState.AWAITING_EXECUTION && args.log_dir) {
        await saveSessionParams(args.log_dir, workflow.getParams(), ctx)
      }
      // AWAITING_EXECUTION æ—¶è¿è¡Œè¶…å‚æ•°æ¨èï¼ˆå®æµ‹æ˜¾å­˜ + æ•°æ®é›†åˆ†æï¼‰
      if (stateCheck.currentState === ForecastTrainingState.AWAITING_EXECUTION) {
        const recResult = await runHyperparamRecommendation(args, pythonPath, trainingDir, ctx)
        if (recResult?.status === 'success') {
          const recMsg = formatRecommendationMessage(recResult)
          if (recMsg) {
            prompt.message = `${prompt.message}\n\n${recMsg}`
          }
          prompt.data = {
            ...(prompt.data ?? {}),
            hyperparameter_recommendations: recResult,
          }
        }
      }
      return {
        status: prompt.status,
        message: prompt.message,
        canExecute: prompt.canExecute,
        ...prompt.data
      }
    }

    // ===== 3. PASS é˜¶æ®µï¼šæ‰§è¡Œè®­ç»ƒ =====
    // Read from merged workflow params (session-confirmed values) to ensure
    // user-confirmed device_ids etc. are not overwritten by raw args defaults.
    const mergedForExec = workflow.getParams()
    const dataset_root = mergedForExec.dataset_root ?? args.dataset_root
    const log_dir = mergedForExec.log_dir ?? args.log_dir
    const model_name = mergedForExec.model_name ?? args.model_name
    const dyn_vars = mergedForExec.dyn_vars ?? args.dyn_vars
    const mode = mergedForExec.mode ?? args.mode ?? 'train'
    const device_ids = mergedForExec.device_ids ?? args.device_ids ?? [0]
    const distribute = mergedForExec.distribute ?? args.distribute ?? false
    const distribute_mode = mergedForExec.distribute_mode ?? args.distribute_mode ?? 'DDP'
    const ckpt_path = mergedForExec.ckpt_path ?? args.ckpt_path

    if (!log_dir) {
      return {
        status: 'error',
        error: 'æœªæŒ‡å®šè®­ç»ƒæ—¥å¿—è¾“å‡ºç›®å½• (log_dir)',
        suggestion: 'è¯·åœ¨å‚æ•°ä¸­æä¾› log_dir'
      }
    }

    // ===== predict å¿«é€Ÿé€šé“ï¼šè·³è¿‡è®­ç»ƒä¸“å±æ­¥éª¤ï¼ˆOOM ç­‰ï¼‰ï¼Œç›´æ¥å‡†å¤‡ + å¯åŠ¨ =====
    if (mode === 'predict') {
      if (!dataset_root) {
        return { status: 'error', error: 'éœ€è¦ dataset_root', suggestion: 'è¯·æä¾›é¢„å¤„ç†æ•°æ®æ ¹ç›®å½•' }
      }
      if (!model_name) {
        return { status: 'error', error: 'éœ€è¦ model_name', suggestion: 'è¯·æä¾›æ¨¡å‹åç§°' }
      }

      const normalizedDeviceIds = Array.isArray(device_ids) && device_ids.length > 0 ? device_ids : [0]

      // å‡†å¤‡å·¥ä½œç©ºé—´
      const workspaceDir = path.resolve(log_dir, '_ocean_forecast_code')
      const prepareScript = path.join(trainingDir, 'prepare_workspace.py')
      const prepareResult = await ctx.sandbox.exec(
        `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(prepareScript)}" --source_dir "${shellEscapeDouble(trainingDir)}" --target_dir "${shellEscapeDouble(workspaceDir)}" --model_name "${shellEscapeDouble(model_name)}" --data_name ocean_forecast_npy`,
        { timeoutMs: 60000 }
      )
      if (prepareResult.code !== 0) {
        return {
          status: 'error',
          error: `å·¥ä½œç©ºé—´å‡†å¤‡å¤±è´¥: ${prepareResult.stderr}`,
          suggestion: `è¯·æ£€æŸ¥è¾“å‡ºç›®å½• ${log_dir} æ˜¯å¦å­˜åœ¨ä¸”æœ‰å†™å…¥æƒé™`
        }
      }
      const prepareInfo = JSON.parse(prepareResult.stdout)

      // ç”Ÿæˆé…ç½®ï¼ˆpredict æœ€å°å‚æ•°é›†ï¼‰
      const predictMergedParams = workflow.getParams()
      const generateScript = path.join(workspaceDir, 'generate_config.py')
      const configParams: Record<string, unknown> = {
        model_name, dataset_root, dyn_vars, log_dir,
        in_t: predictMergedParams.in_t ?? 7,
        out_t: predictMergedParams.out_t ?? 1,
        stride: predictMergedParams.stride ?? 1,
        device: normalizedDeviceIds[0], device_ids: normalizedDeviceIds,
        distribute: false, distribute_mode: 'single',
        ckpt_path: ckpt_path || path.join(log_dir, 'best_model.pth'),
        epochs: 1, batch_size: 1, eval_batch_size: 1,
        use_amp: predictMergedParams.use_amp ?? true,
        gradient_checkpointing: false,
        normalize: predictMergedParams.normalize, normalizer_type: predictMergedParams.normalizer_type,
      }
      const configPath = path.join(workspaceDir, `${model_name}_config.yaml`)
      const paramsJson = JSON.stringify(configParams)
      const genResult = await ctx.sandbox.exec(
        `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(generateScript)}" --params '${shellSafeJson(paramsJson)}' --output "${shellEscapeDouble(configPath)}"`,
        { timeoutMs: 60000 }
      )
      if (genResult.code !== 0) {
        return {
          status: 'error',
          error: `é…ç½®ç”Ÿæˆå¤±è´¥: ${genResult.stderr}`,
          suggestion: 'è¯·æ£€æŸ¥ dataset_root è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠ model_name æ˜¯å¦åœ¨æ”¯æŒåˆ—è¡¨ä¸­'
        }
      }
      const genInfo = JSON.parse(genResult.stdout)

      // æ„å»ºå‘½ä»¤ï¼ˆpredict å§‹ç»ˆå•å¡ï¼‰
      const cudaDevice = String(normalizedDeviceIds[0])
      const mainPy = path.join(workspaceDir, 'main.py')
      const cmdPath = pythonPath
      const cmdArgs = [mainPy, '--mode', 'predict', '--config', configPath]
      const cmdEnv = { CUDA_VISIBLE_DEVICES: cudaDevice }

      // å¯åŠ¨åå°è¿›ç¨‹
      const processInfo = trainingProcessManager.startProcess({
        cmd: cmdPath,
        args: cmdArgs,
        cwd: workspaceDir,
        logDir: log_dir,
        env: cmdEnv,
        metadata: {
          modelName: model_name,
          datasetRoot: dataset_root,
          logDir: log_dir,
          configPath: genInfo.config_path,
          workspaceDir: workspaceDir,
          deviceIds: normalizedDeviceIds,
          mode: 'predict',
        },
      })

      // ç­‰å¾… predict_start äº‹ä»¶
      const STARTUP_TIMEOUT_MS = 300000
      const startupResult = await trainingProcessManager.waitForEvent(
        processInfo.id, 'predict_start', STARTUP_TIMEOUT_MS
      )

      if (startupResult.processStatus === 'failed' || startupResult.processStatus === 'killed') {
        const failedInfo = trainingProcessManager.getProcess(processInfo.id)
        return {
          status: 'error',
          error: 'é¢„æµ‹æ¨ç†åœ¨å¯åŠ¨é˜¶æ®µå´©æºƒï¼ˆæ•°æ®åŠ è½½/æ¨¡å‹åŠ è½½å¤±è´¥ï¼‰',
          process_id: processInfo.id,
          error_summary: failedInfo?.errorSummary ?? null,
          error_log_tail: trainingProcessManager.readLogs(processInfo.id, { tail: 50 })?.content,
          suggestions: failedInfo?.errorSummary?.suggestions ?? [],
        }
      }

      const predictionsDir = path.join(log_dir, 'predictions')
      if (startupResult.found) {
        return {
          status: 'started',
          message: 'é¢„æµ‹æ¨ç†å·²å¯åŠ¨ã€‚ä½¿ç”¨ ocean_forecast_train_status ç›‘æ§è¿›åº¦ã€‚',
          process_id: processInfo.id,
          pid: processInfo.pid,
          mode: 'predict',
          model: model_name,
          config_path: genInfo.config_path,
          log_dir,
          log_file: processInfo.logFile,
          predictions_dir: predictionsDir,
          workspace_dir: workspaceDir,
          workspace_info: prepareInfo,
          next_steps: [
            `è°ƒç”¨ ocean_forecast_train_status({ action: "wait", process_id: "${processInfo.id}", timeout: 300 }) ç­‰å¾…æ¨ç†å®Œæˆ`,
            `è°ƒç”¨ ocean_forecast_train_status({ process_id: "${processInfo.id}" }) æŸ¥çœ‹æ¨ç†çŠ¶æ€`,
            `è°ƒç”¨ ocean_forecast_train_status({ action: "logs", process_id: "${processInfo.id}", tail: 50 }) æŸ¥çœ‹æœ€æ–°æ—¥å¿—`,
            `æ¨ç†å®Œæˆåè°ƒç”¨ ocean_forecast_train_visualize({ log_dir: "${log_dir}", mode: "predict" }) ç”Ÿæˆå¯è§†åŒ–`,
          ],
        }
      }

      return {
        status: 'started',
        message: 'é¢„æµ‹è¿›ç¨‹å·²å¯åŠ¨ï¼Œä»åœ¨åˆå§‹åŒ–ä¸­ï¼ˆå¯èƒ½æ•°æ®é‡è¾ƒå¤§ï¼‰ã€‚ä½¿ç”¨ ocean_forecast_train_status ç›‘æ§ã€‚',
        process_id: processInfo.id,
        pid: processInfo.pid,
        mode: 'predict',
        model: model_name,
        config_path: genInfo.config_path,
        log_dir,
        log_file: processInfo.logFile,
        predictions_dir: predictionsDir,
        workspace_dir: workspaceDir,
        workspace_info: prepareInfo,
        next_steps: [
          `è°ƒç”¨ ocean_forecast_train_status({ action: "wait", process_id: "${processInfo.id}", timeout: 300 }) ç­‰å¾…æ¨ç†å®Œæˆ`,
          `è°ƒç”¨ ocean_forecast_train_status({ process_id: "${processInfo.id}" }) æŸ¥çœ‹æ¨ç†çŠ¶æ€`,
        ],
      }
    }

    // ===== 3.0 æ¨¡å‹æ”¯æŒæ€§æ£€æŸ¥ï¼ˆè‹¥æ¨¡å‹æœªæ¥å…¥ï¼Œæå‰é˜»æ–­ï¼‰ =====
    let modelSupportInfo: ModelInfo | undefined
    const listScript = path.join(trainingDir, 'list_models.py')
    const listResult = await ctx.sandbox.exec(
      `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(listScript)}"`,
      { timeoutMs: 30000 }
    )
    if (listResult.code === 0) {
      try {
        const parsed = JSON.parse(listResult.stdout)
        if (Array.isArray(parsed.models)) {
          modelSupportInfo = parsed.models.find((m: ModelInfo) => m.name === model_name)
        }
      } catch {
        modelSupportInfo = undefined
      }
    }
    if (modelSupportInfo && modelSupportInfo.supported === false) {
      return {
        status: 'error',
        error: 'æ¨¡å‹ ' + model_name + ' æœªæ¥å…¥è®­ç»ƒæµç¨‹',
        reason: modelSupportInfo.notes ?? modelSupportInfo.description,
        suggestion: 'è¯·æ”¹ç”¨å·²æ¥å…¥çš„æ¨¡å‹ï¼Œæˆ–è¡¥é½æ¨¡å‹æ³¨å†Œ / trainer / é…ç½®æ¨¡æ¿åå†è¯•'
      }
    }
    if (listResult.code === 0 && !modelSupportInfo) {
      return {
        status: 'error',
        error: 'æœªçŸ¥æ¨¡å‹: ' + model_name,
        suggestion: 'è¯·ä»æ¨¡å‹åˆ—è¡¨ä¸­é€‰æ‹©ï¼Œæˆ–ç¡®è®¤æ¨¡å‹åç§°æ˜¯å¦æ‹¼å†™æ­£ç¡®'
      }
    }

    const normalizedDeviceIds = Array.isArray(device_ids) && device_ids.length > 0 ? device_ids : [0]
    const effectiveDistribute = distribute && normalizedDeviceIds.length > 1
    const effectiveDistributeMode = effectiveDistribute ? distribute_mode : 'single'

    const execWarnings: string[] = []

    let masterPort: number | null = null
    if (effectiveDistribute && distribute_mode === 'DDP') {
      const requestedPort = typeof args.master_port === 'number' ? Math.trunc(args.master_port) : null
      if (requestedPort && requestedPort > 0 && requestedPort <= 65535) {
        if (await isPortFree(requestedPort)) {
          masterPort = requestedPort
        } else {
          const fallbackPort = await findFreePort(29500, 29600)
          masterPort = fallbackPort ?? requestedPort
          execWarnings.push(`DDP master_port ${requestedPort} å·²è¢«å ç”¨ï¼Œå·²åˆ‡æ¢ä¸º ${masterPort}ã€‚`)
        }
      } else {
        const fallbackPort = await findFreePort(29500, 29600)
        masterPort = fallbackPort ?? 29500
        if (masterPort !== 29500) {
          execWarnings.push(`DDP master_port è‡ªåŠ¨é€‰æ‹©ä¸º ${masterPort}ã€‚`)
        }
      }
    }

    if (distribute && normalizedDeviceIds.length <= 1) {
      execWarnings.push(
        'å·²è¯·æ±‚å¤šå¡/DP/DDP ä½† device_ids åªæœ‰ 1 å¼  GPUï¼Œå·²è‡ªåŠ¨é™çº§ä¸ºå•å¡è®­ç»ƒä»¥é¿å… DDP åˆå§‹åŒ–å¤±è´¥ã€‚'
      )
    }

    // ===== 3a. å‡†å¤‡è®­ç»ƒå·¥ä½œç©ºé—´ï¼ˆåªå¤åˆ¶æ‰€é€‰æ¨¡å‹ç›¸å…³ä»£ç ï¼‰ =====
    const workspaceDir = path.resolve(log_dir, '_ocean_forecast_code')
    const prepareScript = path.join(trainingDir, 'prepare_workspace.py')
    const prepareResult = await ctx.sandbox.exec(
      `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(prepareScript)}" --source_dir "${shellEscapeDouble(trainingDir)}" --target_dir "${shellEscapeDouble(workspaceDir)}" --model_name "${shellEscapeDouble(model_name)}" --data_name ocean_forecast_npy`,
      { timeoutMs: 60000 }
    )
    if (prepareResult.code !== 0) {
      return {
        status: 'error',
        error: `å·¥ä½œç©ºé—´å‡†å¤‡å¤±è´¥: ${prepareResult.stderr}`,
        reason: 'æ— æ³•å°†è®­ç»ƒä»£ç å¤åˆ¶åˆ°è¾“å‡ºç›®å½•',
        suggestion: `è¯·æ£€æŸ¥è¾“å‡ºç›®å½• ${log_dir} æ˜¯å¦å­˜åœ¨ä¸”æœ‰å†™å…¥æƒé™`
      }
    }
    const prepareInfo = JSON.parse(prepareResult.stdout)

    const generateScript = path.join(workspaceDir, 'generate_config.py')

    // ===== 3b. ç”Ÿæˆé…ç½®æ–‡ä»¶ =====
    const mergedParams = workflow.getParams()
    const effectiveUseAmp = mergedParams.use_amp ?? true
    const configParams: Record<string, unknown> = {
      model_name,
      dataset_root,
      dyn_vars,
      in_t: mergedParams.in_t ?? 7,
      out_t: mergedParams.out_t ?? 1,
      stride: mergedParams.stride ?? 1,
      log_dir,
      device: normalizedDeviceIds[0],
      device_ids: normalizedDeviceIds,
      distribute: effectiveDistribute,
      distribute_mode: effectiveDistributeMode,
      master_port: masterPort ?? undefined,
      ckpt_path,
      epochs: mergedParams.epochs,
      lr: mergedParams.lr,
      batch_size: mergedParams.batch_size,
      eval_batch_size: mergedParams.eval_batch_size,
      patience: mergedParams.patience,
      eval_freq: mergedParams.eval_freq,
      normalize: mergedParams.normalize,
      normalizer_type: mergedParams.normalizer_type,
      optimizer: mergedParams.optimizer,
      weight_decay: mergedParams.weight_decay,
      scheduler: mergedParams.scheduler,
      scheduler_step_size: mergedParams.scheduler_step_size,
      scheduler_gamma: mergedParams.scheduler_gamma,
      seed: mergedParams.seed,
      wandb: mergedParams.wandb,
      use_amp: effectiveUseAmp,
      gradient_checkpointing: mergedParams.gradient_checkpointing,
    }

    const configPath = path.join(workspaceDir, `${model_name}_config.yaml`)

    const paramsJson = JSON.stringify(configParams)
    const genResult = await ctx.sandbox.exec(
      `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(generateScript)}" --params '${shellSafeJson(paramsJson)}' --output "${shellEscapeDouble(configPath)}"`,
      { timeoutMs: 60000 }
    )

    if (genResult.code !== 0) {
      return {
        status: 'error',
        error: `é…ç½®ç”Ÿæˆå¤±è´¥: ${genResult.stderr}`,
        reason: 'å‚æ•°å¯èƒ½ä¸å…¼å®¹æ‰€é€‰æ¨¡å‹ï¼Œæˆ–æ•°æ®ç›®å½•ä¸å¯è®¿é—®',
        suggestion: 'è¯·æ£€æŸ¥ dataset_root è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠ model_name æ˜¯å¦åœ¨æ”¯æŒåˆ—è¡¨ä¸­'
      }
    }

    const genInfo = JSON.parse(genResult.stdout)

    // ===== 3c. OOM è‡ªåŠ¨é˜²æŠ¤ï¼šè‡ªåŠ¨é™ä½ batch_sizeï¼ˆä¸å¯è·³è¿‡ï¼‰ =====
    if (mode === 'train') {
      const estimateScript = path.join(workspaceDir, 'estimate_memory.py')
      const cudaDevice = normalizedDeviceIds[0]
      let currentBatchSize = (configParams.batch_size as number) ?? 4
      let currentAmp = (configParams.use_amp as boolean) ?? true
      const MAX_ATTEMPTS = 5

      for (let attempt = 0; attempt < MAX_ATTEMPTS; attempt++) {
        // æ¯æ¬¡è°ƒå‚åé‡æ–°ç”Ÿæˆé…ç½®
        if (attempt > 0) {
          configParams.batch_size = currentBatchSize
          configParams.use_amp = currentAmp
          const regenJson = JSON.stringify(configParams)
          // eslint-disable-next-line no-await-in-loop
          const regenResult = await ctx.sandbox.exec(
            `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(generateScript)}" --params '${shellSafeJson(regenJson)}' --output "${shellEscapeDouble(configPath)}"`,
            { timeoutMs: 60000 }
          )
          if (regenResult.code !== 0) {
            execWarnings.push(`æ˜¾å­˜é¢„ä¼°å‰é‡å»ºé…ç½®å¤±è´¥ï¼Œå·²è·³è¿‡è‡ªåŠ¨è°ƒå‚ï¼š${regenResult.stderr || regenResult.stdout}`)
            break
          }
        }

        // eslint-disable-next-line no-await-in-loop
        const estimateResult = await ctx.sandbox.exec(
          `cd "${shellEscapeDouble(workspaceDir)}" && CUDA_VISIBLE_DEVICES=${Number(cudaDevice) || 0} "${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(estimateScript)}" --config "${shellEscapeDouble(configPath)}" --device 0`,
          { timeoutMs: 120000 }
        )
        if (estimateResult.code !== 0) {
          execWarnings.push(`æ˜¾å­˜é¢„ä¼°å¤±è´¥ï¼Œå·²è·³è¿‡è‡ªåŠ¨è°ƒå‚å¹¶ç»§ç»­è®­ç»ƒï¼š${estimateResult.stderr || estimateResult.stdout}`)
          break
        }

        try {
          const mem = JSON.parse(estimateResult.stdout)
          if (mem.status === 'success' && mem.utilization_pct <= 85) {
            // é€šè¿‡ â†’ è·³å‡ºå¾ªç¯
            break
          }

          // OOM æˆ– >85%ï¼šä»…é™ä½ batch_sizeï¼ˆforecast æ²¡æœ‰ patch_size å¯ç¼©å‡ï¼‰
          if (!currentAmp) {
            // å…ˆå°è¯•å¼€å¯ AMP
            currentAmp = true
          } else if (currentBatchSize > 1) {
            currentBatchSize = Math.max(1, Math.floor(currentBatchSize / 2))
          } else {
            // æ‰€æœ‰æ‰‹æ®µè€—å°½
            return {
              status: 'error',
              error: 'GPU æ˜¾å­˜ä¸è¶³ï¼Œå·²å°è¯•æ‰€æœ‰è‡ªåŠ¨ä¼˜åŒ–æ‰‹æ®µä»æ— æ³•é€‚é…',
              memory_estimate: mem,
              applied_optimizations: { use_amp: currentAmp, batch_size: currentBatchSize },
              recommendations: mem.recommendations,
              suggestion: 'è¯·ä½¿ç”¨æ›´å¤§æ˜¾å­˜çš„ GPUï¼Œæˆ–å‡å°‘ in_t / out_t / dyn_vars æ•°é‡'
            }
          }
        } catch {
          // è§£æå¤±è´¥ä¸é˜»æ­¢è®­ç»ƒ
          execWarnings.push('æ˜¾å­˜é¢„ä¼°è¾“å‡ºè§£æå¤±è´¥ï¼Œå·²è·³è¿‡è‡ªåŠ¨è°ƒå‚å¹¶ç»§ç»­è®­ç»ƒ')
          break
        }
      }
    }

    // ===== 3d. æ„å»ºè¿è¡Œå‘½ä»¤ =====
    let cmdPath: string
    let cmdArgs: string[]
    let cmdEnv: Record<string, string> = {}

    if (effectiveDistribute && distribute_mode === 'DDP') {
      const nproc = normalizedDeviceIds.length
      const cudaDevices = normalizedDeviceIds.join(',')
      const mainDdp = path.join(workspaceDir, 'main_ddp.py')
      cmdPath = pythonPath
      cmdArgs = ['-m', 'torch.distributed.run', `--nproc_per_node=${nproc}`, `--master_port=${masterPort ?? 29500}`, mainDdp, '--mode', mode, '--config', configPath]
      cmdEnv = { CUDA_VISIBLE_DEVICES: cudaDevices, MASTER_PORT: String(masterPort ?? 29500) }
    } else if (effectiveDistribute && distribute_mode === 'DP') {
      const mainPy = path.join(workspaceDir, 'main.py')
      cmdPath = pythonPath
      cmdArgs = [mainPy, '--mode', mode, '--config', configPath]
      // DP ç›´æ¥ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ç‰©ç† GPU ç¼–å·ï¼Œé¿å…è¢«å•å¡ CUDA_VISIBLE_DEVICES é™åˆ¶
      cmdEnv = {}
    } else {
      const cudaDevice = String(normalizedDeviceIds[0])
      const mainPy = path.join(workspaceDir, 'main.py')
      cmdPath = pythonPath
      cmdArgs = [mainPy, '--mode', mode, '--config', configPath]
      cmdEnv = { CUDA_VISIBLE_DEVICES: cudaDevice }
    }

    // ===== 3e. å¯åŠ¨åå°è®­ç»ƒè¿›ç¨‹ =====
    const processInfo = trainingProcessManager.startProcess({
      cmd: cmdPath,
      args: cmdArgs,
      cwd: workspaceDir,
      logDir: log_dir,
      env: cmdEnv,
      metadata: {
        modelName: model_name,
        datasetRoot: dataset_root,
        logDir: log_dir,
        configPath: genInfo.config_path,
        workspaceDir: workspaceDir,
        deviceIds: normalizedDeviceIds,
      },
    })

    // ===== 3f. ç­‰å¾…è®­ç»ƒå¯åŠ¨æˆåŠŸï¼ˆäº‹ä»¶é©±åŠ¨ï¼‰ =====
    const STARTUP_TIMEOUT_MS = 300000  // 5 åˆ†é’Ÿï¼ˆæ•°æ®åŠ è½½å¯èƒ½å¾ˆä¹…ï¼‰
    const startupResult = await trainingProcessManager.waitForEvent(
      processInfo.id, 'training_start', STARTUP_TIMEOUT_MS
    )

    if (startupResult.processStatus === 'failed' || startupResult.processStatus === 'killed') {
      // å¯åŠ¨é˜¶æ®µå´©æºƒ â†’ ç›´æ¥è¿”å›é”™è¯¯
      const failedInfo = trainingProcessManager.getProcess(processInfo.id)
      return {
        status: 'error',
        error: 'è®­ç»ƒåœ¨å¯åŠ¨é˜¶æ®µå´©æºƒï¼ˆæ•°æ®åŠ è½½/æ¨¡å‹æ„å»ºå¤±è´¥ï¼‰',
        process_id: processInfo.id,
        error_summary: failedInfo?.errorSummary ?? null,
        error_log_tail: trainingProcessManager.readLogs(processInfo.id, { tail: 50 })?.content,
        suggestions: failedInfo?.errorSummary?.suggestions ?? [],
      }
    }

    // ===== 3g. ç”Ÿæˆ Jupyter Notebookï¼ˆè®­ç»ƒæˆåŠŸå¯åŠ¨åï¼‰ =====
    // eslint-disable-next-line @typescript-eslint/no-explicit-any
    const metadataNotebookPath = (ctx.agent as any)?.config?.metadata?.notebookPath as string | undefined
    const notebookPath = metadataNotebookPath
      ? path.resolve(metadataNotebookPath)
      : path.resolve(ctx.sandbox.workDir, `${path.basename(ctx.sandbox.workDir)}.ipynb`)
    try {
      const nbParams: ForecastTrainNotebookParams = {
        logDir: log_dir,
        datasetRoot: dataset_root ?? '',
        modelName: model_name ?? '',
        configPath: genInfo.config_path ?? configPath,
        workspaceDir,
        pythonPath,
        deviceIds: normalizedDeviceIds,
        distribute: effectiveDistribute,
        distributeMode: effectiveDistributeMode,
        masterPort: masterPort ?? undefined,
        mode,
        inT: mergedParams.in_t,
        outT: mergedParams.out_t,
        stride: mergedParams.stride,
        dynVars: mergedParams.dyn_vars,
        epochs: mergedParams.epochs,
        lr: mergedParams.lr,
        batchSize: mergedParams.batch_size,
        evalBatchSize: mergedParams.eval_batch_size,
        patience: mergedParams.patience,
        evalFreq: mergedParams.eval_freq,
        normalize: mergedParams.normalize,
        normalizerType: mergedParams.normalizer_type,
        optimizer: mergedParams.optimizer,
        weightDecay: mergedParams.weight_decay,
        scheduler: mergedParams.scheduler,
        schedulerStepSize: mergedParams.scheduler_step_size,
        schedulerGamma: mergedParams.scheduler_gamma,
        seed: mergedParams.seed,
        useAmp: effectiveUseAmp,
        gradientCheckpointing: mergedParams.gradient_checkpointing,
        ckptPath: ckpt_path,
        wandb: mergedParams.wandb,
      }
      const cells = generateForecastTrainCells(nbParams)
      await saveOrAppendNotebook(ctx, notebookPath, cells)
    } catch (e) {
      console.warn('Notebook ç”Ÿæˆå¤±è´¥:', e)
    }

    // å…¬å…±åŸºç¡€å“åº”
    const baseResponse = {
      status: 'started',
      process_id: processInfo.id,
      pid: processInfo.pid,
      mode,
      model: model_name,
      config_path: genInfo.config_path,
      log_dir,
      log_file: processInfo.logFile,
      notebook_path: notebookPath,
      distribute: effectiveDistribute,
      distribute_mode: effectiveDistributeMode,
      device_ids: normalizedDeviceIds,
      master_port: masterPort ?? undefined,
      workspace_dir: workspaceDir,
      workspace_info: prepareInfo,
      warnings: execWarnings.length > 0 ? execWarnings : undefined,
    }

    if (startupResult.found) {
      return {
        ...baseResponse,
        message: 'è®­ç»ƒå·²å¯åŠ¨å¹¶æ­£å¸¸è¿è¡Œä¸­ã€‚ä½¿ç”¨ ocean_forecast_train_status å·¥å…·ç›‘æ§è¿›åº¦ã€‚',
        next_steps: [
          `è°ƒç”¨ ocean_forecast_train_status({ action: "wait", process_id: "${processInfo.id}", timeout: 120 }) ç­‰å¾…è®­ç»ƒçŠ¶æ€å˜åŒ–`,
          `è°ƒç”¨ ocean_forecast_train_status({ action: "watch", process_id: "${processInfo.id}", timeout: 300 }) ç­‰å¾…å…³é”®æ¨é€äº‹ä»¶`,
          `è°ƒç”¨ ocean_forecast_train_status({ process_id: "${processInfo.id}" }) æŸ¥çœ‹è®­ç»ƒçŠ¶æ€`,
          `è°ƒç”¨ ocean_forecast_train_status({ action: "logs", process_id: "${processInfo.id}", tail: 50 }) æŸ¥çœ‹æœ€æ–°æ—¥å¿—`,
          `è°ƒç”¨ ocean_forecast_train_status({ action: "kill", process_id: "${processInfo.id}" }) ç»ˆæ­¢è®­ç»ƒ`,
        ],
      }
    }

    return {
      ...baseResponse,
      message: 'è®­ç»ƒè¿›ç¨‹å·²å¯åŠ¨ï¼Œä»åœ¨åˆå§‹åŒ–ä¸­ï¼ˆå¯èƒ½æ•°æ®é‡è¾ƒå¤§ï¼‰ã€‚ä½¿ç”¨ ocean_forecast_train_status ç›‘æ§ã€‚',
      next_steps: [
        `è°ƒç”¨ ocean_forecast_train_status({ action: "wait", process_id: "${processInfo.id}", timeout: 120 }) ç­‰å¾…è®­ç»ƒçŠ¶æ€å˜åŒ–`,
        `è°ƒç”¨ ocean_forecast_train_status({ action: "watch", process_id: "${processInfo.id}", timeout: 300 }) ç­‰å¾…å…³é”®æ¨é€äº‹ä»¶`,
        `è°ƒç”¨ ocean_forecast_train_status({ process_id: "${processInfo.id}" }) æŸ¥çœ‹è®­ç»ƒçŠ¶æ€`,
        `è°ƒç”¨ ocean_forecast_train_status({ action: "logs", process_id: "${processInfo.id}", tail: 50 }) æŸ¥çœ‹æœ€æ–°æ—¥å¿—`,
      ],
    }
  }
})
