/**
 * @file train.ts
 *
 * @description æµ·æ´‹è¶…åˆ†è¾¨ç‡æ¨¡å‹è®­ç»ƒå·¥å…·
 *              é›†æˆçŠ¶æ€æœºå®ç°åˆ†é˜¶æ®µç¡®è®¤æµç¨‹
 *              æ”¯æŒåå°æ‰§è¡Œå’Œå®æ—¶æ—¥å¿—æµ
 * @author Leizheng
 * @contributors kongzhiquan, Leizheng
 * @date 2026-02-09
 * @version 4.8.1
 *
 * @changelog
 *   - 2026-02-26 kongzhiquan: v4.8.1 Notebook è·¯å¾„æ”¹ç”¨åç«¯ä¼ å…¥çš„ notebookPathï¼ˆä» agent metadata è¯»å–ï¼‰
 *   - 2026-02-25 kongzhiquan: v4.8.0 è®­ç»ƒæˆåŠŸå¯åŠ¨åç”Ÿæˆå¯å¤ç° Jupyter Notebook
 *     - åœ¨ PASS é˜¶æ®µ status=started æ—¶è°ƒç”¨ generateTrainCells + saveOrAppendNotebook
 *     - Notebook ä¿å­˜è‡³ {log_dir}/{basename}.ipynb
 *     - åŒ…å«è¯„ä¼°ã€æ¨ç†ã€å®Œæ•´è®­ç»ƒå‘½ä»¤ç­‰ cells
 *   - 2026-02-25 Leizheng: v4.7.0 AWAITING_EXECUTION é˜¶æ®µé›†æˆè¶…å‚æ•°æ¨è
 *     - è°ƒç”¨ recommend_hyperparams.py å®æµ‹æ˜¾å­˜ + æ•°æ®é›†æ‰«æ
 *     - æ¨è batch_size / epochs / lrï¼Œå¹¶é™„æ•°æ®é¢‘è°±åˆ†æè¯´æ˜
 *     - å¤±è´¥æ—¶é™é»˜è·³è¿‡ï¼Œä¸å½±å“ç°æœ‰è®­ç»ƒæµç¨‹
 *   - 2026-02-25 Leizheng: v4.6.0 session æ–‡ä»¶æŒä¹…åŒ–ç”¨æˆ·ç¡®è®¤å‚æ•°
 *     - AWAITING_EXECUTION æ—¶å°†å…¨é‡å‚æ•°ä¿å­˜åˆ° {log_dir}/.ocean_sr_session.json
 *     - PASS æ‰§è¡Œæ—¶è¯»å– session æ–‡ä»¶ä½œä¸º sessionOverrides ä¼ å…¥ TrainingWorkflow
 *     - å½»åº•è§£å†³å¯é€‰å‚æ•°ï¼ˆnormalizer_type ç­‰ï¼‰åœ¨æ— çŠ¶æ€å¤šè½®è°ƒç”¨ä¸­ä¸¢å¤±çš„é—®é¢˜
 *     - use_amp è‡ªåŠ¨è®¾ç½®ä¸çº³å…¥ definedArgsï¼Œä¿ç•™ç”¨æˆ·é€šè¿‡ session æŒ‡å®šçš„å€¼
 *   - 2026-02-24 Leizheng: v4.5.0 configParams æ”¹ç”¨ workflow.getParams()
 *     - è§£å†³æ— çŠ¶æ€å·¥ä½œæµä¸­ç”¨æˆ·ç¡®è®¤å‚æ•°ï¼ˆå¦‚ normalizer_typeï¼‰åœ¨æ‰§è¡Œè°ƒç”¨æ—¶ä¸¢å¤±çš„é—®é¢˜
 *     - æ‰§è¡Œé˜¶æ®µä» workflow åˆå¹¶å‚æ•°å–å€¼ï¼Œä¸å†ä¾èµ–åŸå§‹ argsï¼ˆå¯èƒ½ç¼ºå¤±å­—æ®µï¼‰
 *   - 2026-02-11 Leizheng: v4.4.0 predict å¿«é€Ÿé€šé“
 *     - mode å‚æ•°æ”¯æŒ "predict"ï¼Œè·³è¿‡è®­ç»ƒå·¥ä½œæµï¼ˆOOM/shape/FFT æ£€æŸ¥ï¼‰
 *     - predict åˆ†æ”¯ç›´æ¥å‡†å¤‡å·¥ä½œç©ºé—´ â†’ ç”Ÿæˆé…ç½® â†’ å¯åŠ¨ â†’ ç­‰å¾… predict_start
 *     - å¯åŠ¨äº‹ä»¶æ ¹æ® mode é€‰æ‹© predict_start æˆ– training_start
 *   - 2026-02-11 Leizheng: v4.3.0 ResShift divisor ä¿®æ­£ + TOKEN_INVALID GPU ä¿¡æ¯
 *     - ResShift divisor 8â†’64ï¼ˆSwin window_size=8ï¼‰
 *     - TOKEN_INVALID çŠ¶æ€ä¸‹ä¹Ÿè·å– GPU ä¿¡æ¯ä¾›é‡æ–°ç¡®è®¤
 *   - 2026-02-09 Leizheng: v4.2.7 FFT æ¨¡å‹ AMP é»˜è®¤ç­–ç•¥ä¿®å¤ + æ¨¡å‹æ”¯æŒæ€§é¢„æ£€
 *   - 2026-02-09 Leizheng: v4.2.6 é»˜è®¤ batch_size ä¸‹è°ƒä¸º 4 + é»˜è®¤å¼€å¯ gradient_checkpointing
 *   - 2026-02-09 Leizheng: v4.2.5 è®­ç»ƒå‰è¾“å‡ºå°ºå¯¸é¢„æ£€ + é»˜è®¤ batch_size ä¸‹è°ƒ
 *     - è®­ç»ƒå¯åŠ¨å‰æ£€æŸ¥æ¨¡å‹è¾“å‡ºå°ºå¯¸æ˜¯å¦ä¸ HR åŒ¹é…
 *     - batch_size/eval_batch_size é»˜è®¤é™ä¸º 16
 *   - 2026-02-09 Leizheng: v4.2.4 FFT + AMP æ¨è patch_size æç¤º
 *   - 2026-02-09 Leizheng: v4.2.3 FFT æ¨¡å‹ AMP é»˜è®¤ç­–ç•¥
 *     - FFT æ¨¡å‹é»˜è®¤å…³é—­ AMPï¼ˆç”¨æˆ·æ˜¾å¼å¼€å¯åˆ™å°Šé‡å¹¶æç¤ºé£é™©ï¼‰
 *   - 2026-02-09 Leizheng: v4.2.2 FFT æç¤ºç­–ç•¥è°ƒæ•´ + æ˜¾å­˜é¢„è­¦
 *     - FFT é¢„æ£€æ‰©å±•åˆ°æ‰€æœ‰æ¨¡å‹ï¼Œæ”¹ä¸ºæç¤ºä¸æ‹¦æˆª
 *     - æ–°å¢ GPU ä½ç©ºé—²æ˜¾å­˜æç¤ºï¼ˆä¸æ‹¦æˆªï¼‰
 *   - 2026-02-09 Leizheng: v4.2.1 FFT + AMP å…¼å®¹æ€§é¢„æ£€æ‰©å±•
 *     - é€‚é… HiNOTE ç­‰ FFT æ¨¡å‹ï¼Œç»Ÿä¸€å‰ç½®æ‹¦æˆª
 *     - æç¤ºä¸é”™è¯¯ä¿¡æ¯ç»Ÿä¸€ä¸º FFT ç»´åº¦è¦æ±‚
 *   - 2026-02-09 Leizheng: v4.2.0 FNO + AMP å…¼å®¹æ€§é¢„æ£€
 *     - è®­ç»ƒå‰æ£€æµ‹ FFT è¾“å…¥å°ºå¯¸æ˜¯å¦ä¸º 2 çš„å¹‚
 *     - åœ¨é˜¶æ®µæç¤ºä¸­è¿½åŠ æ˜ç¡®å‘Šè­¦ï¼Œé¿å…è¿è¡Œæ—¶ cuFFT å´©æºƒ
 *   - 2026-02-08 Leizheng: v4.1.0 ä¿®å¤å‚æ•°ä¼ é€’ + æ˜¾å¼ç™½åå•
 *     - configParams æ”¹ç”¨æ˜¾å¼ç™½åå•ï¼Œé¿å… restParams æ³„æ¼çŠ¶æ€æœºå†…éƒ¨å­—æ®µ
 *     - æ˜¾å¼ä¼ é€’ ckpt_pathï¼ˆä¹‹å‰è¢«è§£æ„åä» restParams ä¸­ä¸¢å¤±ï¼‰
 *   - 2026-02-07 kongzhiquan: v4.0.0 OOM è‡ªåŠ¨é˜²æŠ¤ + äº‹ä»¶é©±åŠ¨å¯åŠ¨ç›‘æ§
 *     - æ˜¾å­˜é¢„ä¼°æ”¹ä¸ºè‡ªåŠ¨å¾ªç¯è°ƒå‚ï¼ˆAMPâ†’å‡batch_sizeâ†’æŠ¥é”™ï¼‰ï¼Œä¸å¯è·³è¿‡
 *     - ç§»é™¤ skip_memory_check å‚æ•°ï¼Œuse_amp é»˜è®¤æ”¹ä¸º true
 *     - å¯åŠ¨åç­‰å¾… training_start äº‹ä»¶ï¼ˆæœ€é•¿ 5 åˆ†é’Ÿï¼‰ï¼Œæ•è·æ—©æœŸå´©æºƒ
 *     - å¯åŠ¨é˜¶æ®µå´©æºƒæ—¶ç›´æ¥è¿”å› error_summary + suggestions
 *   - 2026-02-07 kongzhiquan: v3.0.0 åå°æ‰§è¡Œæ¨¡å¼
 *     - ä½¿ç”¨ TrainingProcessManager å¯åŠ¨åå°è®­ç»ƒè¿›ç¨‹
 *     - è®­ç»ƒå¯åŠ¨åç«‹å³è¿”å› process_idï¼Œä¸å†é˜»å¡ç­‰å¾…
 *     - æ”¯æŒå®æ—¶æ—¥å¿—æµï¼ˆé€šè¿‡ ocean_sr_train_status å·¥å…·æŸ¥è¯¢ï¼‰
 *     - æœåŠ¡å™¨å…³é—­æ—¶è‡ªåŠ¨æ¸…ç†è®­ç»ƒè¿›ç¨‹
 *   - 2026-02-07 Leizheng: v3.0.0 OOM é˜²æŠ¤ä¸‰ä»¶å¥—
 *     - æ–°å¢ use_amp / gradient_checkpointing / patch_size å‚æ•°
 *     - è®­ç»ƒå‰è‡ªåŠ¨è¿è¡Œæ˜¾å­˜é¢„ä¼°ï¼ŒOOM æå‰æ‹¦æˆªå¹¶ç»™å‡ºå»ºè®®
 *     - æ–°å‚æ•°é€šè¿‡ generate_config.py å†™å…¥ YAML é…ç½®
 *   - 2026-02-07 Leizheng: v2.3.0 æŒ‰æ¨¡å‹é€‰æ‹©æ€§å¤åˆ¶ä»£ç åˆ°ç”¨æˆ·è¾“å‡ºç›®å½•æ‰§è¡Œï¼Œä¿æŒ SDK æºç ä¸è¢«ä¿®æ”¹
 *   - 2026-02-07 Leizheng: v2.2.0 ä½¿ç”¨ findPythonWithModule('torch') è‡ªåŠ¨æŸ¥æ‰¾å¸¦ PyTorch çš„ Python
 *   - 2026-02-06 Leizheng: v2.1.0 æŒ‡å‘ masked ç‰ˆæœ¬è®­ç»ƒæ¡†æ¶
 *     - trainingDir æ”¹ä¸º scripts/ocean_SR_training_masked
 *   - 2026-02-06 Leizheng: v2.0.0 é›†æˆè®­ç»ƒå·¥ä½œæµçŠ¶æ€æœº
 *     - 4 é˜¶æ®µç¡®è®¤: æ•°æ® â†’ æ¨¡å‹ â†’ å‚æ•°(GPU) â†’ æ‰§è¡Œ
 *     - è‡ªåŠ¨æ£€æµ‹ dyn_vars / scale / shape
 *     - GPU ä¿¡æ¯é›†æˆåˆ°å‚æ•°ç¡®è®¤é˜¶æ®µ
 *     - Token é˜²è·³æ­¥æœºåˆ¶
 *   - 2026-02-06 Leizheng: v1.0.0 åˆå§‹ç‰ˆæœ¬
 *     - æ”¯æŒå•å¡/å¤šå¡(DP/DDP)è®­ç»ƒ
 *     - è‡ªåŠ¨ç”Ÿæˆ YAML é…ç½®æ–‡ä»¶
 *     - æ”¯æŒ train/test ä¸¤ç§æ¨¡å¼
 */

import { defineTool } from '@shareai-lab/kode-sdk'
import { findPythonWithModule, findFirstPythonPath } from '@/utils/python-manager'
import { trainingProcessManager } from '@/utils/training-process-manager'
import path from 'node:path'
import net from 'node:net'
import {
  TrainingWorkflow,
  TrainingState,
  type TrainingWorkflowParams,
  type DatasetValidationInfo,
  type GpuInfo,
  type ModelInfo,
} from './workflow-state'
import { generateTrainCells, saveOrAppendNotebook } from './notebook'

/** è®­ç»ƒä¼šè¯å‚æ•°ç¼“å­˜æ–‡ä»¶åï¼Œç”¨äºè·¨æ— çŠ¶æ€è°ƒç”¨ä¿ç•™ç”¨æˆ·ç¡®è®¤è¿‡çš„å‚æ•° */
const SESSION_FILENAME = '.ocean_sr_session.json'

/** ä» log_dir è¯»å–ä¿å­˜çš„è®­ç»ƒä¼šè¯å‚æ•°ï¼ˆä¸å­˜åœ¨æˆ–è§£æå¤±è´¥æ—¶è¿”å› nullï¼‰ */
async function loadSessionParams(
  logDir: string,
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  ctx: any,
): Promise<TrainingWorkflowParams | null> {
  try {
    const sessionPath = path.join(logDir, SESSION_FILENAME)
    const content = await ctx.sandbox.fs.read(sessionPath)
    const parsed = JSON.parse(content)
    return (parsed?.params as TrainingWorkflowParams) ?? null
  } catch {
    return null
  }
}

/** å°†å½“å‰å…¨é‡å‚æ•°å†™å…¥ log_dir çš„ä¼šè¯ç¼“å­˜æ–‡ä»¶ */
async function saveSessionParams(
  logDir: string,
  params: TrainingWorkflowParams,
  // eslint-disable-next-line @typescript-eslint/no-explicit-any
  ctx: any,
): Promise<void> {
  try {
    const sessionPath = path.join(logDir, SESSION_FILENAME)
    await ctx.sandbox.fs.write(sessionPath, JSON.stringify({ savedAt: Date.now(), params }))
  } catch {
    // å†™å…¥å¤±è´¥ä¸å½±å“ä¸»æµç¨‹
  }
}

/**
 * å°† JSON å­—ç¬¦ä¸²è½¬ä¹‰ä¸ºå¯ä»¥å®‰å…¨åµŒå…¥ shell å•å¼•å·çš„å½¢å¼
 * ç­–ç•¥ï¼šæ›¿æ¢å•å¼•å·ä¸º '\'' (ç»“æŸå•å¼•å· + è½¬ä¹‰å•å¼•å· + å¼€å§‹å•å¼•å·)
 * æ³¨ï¼šåœ¨ shell å•å¼•å·å†…ï¼Œåæ–œæ ç­‰å…¶ä»–å­—ç¬¦å‡ä¸ºå­—é¢é‡ï¼Œæ— éœ€é¢å¤–è½¬ä¹‰
 */
function shellSafeJson(json: string): string {
  return json.replace(/'/g, "'\\''")
}

/**
 * è½¬ä¹‰å­—ç¬¦ä¸²ä½¿å…¶å¯ä»¥å®‰å…¨åµŒå…¥ shell åŒå¼•å·
 * åœ¨åŒå¼•å·å†…æœ‰ç‰¹æ®Šå«ä¹‰çš„å­—ç¬¦ï¼š\ " $ ` !
 */
function shellEscapeDouble(str: string): string {
  return str.replace(/[\\"$`!]/g, '\\$&')
}

async function isPortFree(port: number): Promise<boolean> {
  return new Promise((resolve) => {
    const server = net.createServer()
    server.unref()
    server.once('error', () => resolve(false))
    server.listen(port, () => {
      server.close(() => resolve(true))
    })
  })
}

async function findFreePort(start = 29500, end = 29600): Promise<number | null> {
  for (let port = start; port <= end; port += 1) {
    // eslint-disable-next-line no-await-in-loop
    if (await isPortFree(port)) return port
  }
  return null
}

function extractTaggedJson(output: string, tag: string): Record<string, unknown> | null {
  const pattern = new RegExp(`__${tag}__([\\s\\S]*?)__${tag}__`)
  const match = output.match(pattern)
  if (!match) return null
  try {
    return JSON.parse(match[1])
  } catch {
    return null
  }
}

// FFT/é¢‘åŸŸ/å¤æ•°å˜æ¢ç›¸å…³æ¨¡å‹ï¼šé»˜è®¤å…³é—­ AMPï¼Œå…è®¸ç”¨æˆ·æ˜¾å¼ overrideï¼ˆå¼ºæç¤ºï¼‰
const FFT_AMP_SENSITIVE_MODELS = new Set([
  'FNO2d',
  'HiNOTE',
  'MWT2d',
  'M2NO2d',
  'MG-DDPM',
])
const AMP_DEFAULT_OFF_MODELS = new Set([...FFT_AMP_SENSITIVE_MODELS, 'SRNO'])
const DIFFUSION_MODELS = new Set(['DDPM', 'SR3', 'MG-DDPM', 'ReMiG', 'ResShift', 'Resshift'])

function isFftSensitiveModel(modelName?: string): boolean {
  return Boolean(modelName && FFT_AMP_SENSITIVE_MODELS.has(modelName))
}

function isAmpDefaultOffModel(modelName?: string): boolean {
  return Boolean(modelName && AMP_DEFAULT_OFF_MODELS.has(modelName))
}

function isPowerOfTwo(value: number): boolean {
  return Number.isInteger(value) && value > 0 && (value & (value - 1)) === 0
}

function countPowerOfTwoFactor(value: number): number {
  let v = Math.abs(Math.trunc(value))
  let count = 0
  while (v > 0 && v % 2 === 0) {
    v = v / 2
    count += 1
  }
  return count
}

function getModelDivisor(modelName?: string): number {
  if (!modelName) return 1
  // ResShift: downsample 2^3=8, Swin window_size=8, divisor=8*8=64
  if (modelName === 'Resshift' || modelName === 'ResShift') return 64
  if (DIFFUSION_MODELS.has(modelName)) return 32
  if (modelName === 'UNet2d') return 16
  return 1
}

function getMaxHrDim(datasetInfo?: DatasetValidationInfo): number | null {
  const hrDims = getSpatialDims(datasetInfo?.hr_shape)
  if (!hrDims) return null
  return Math.min(hrDims[0], hrDims[1])
}

function buildFftPatchRecommendations(params: {
  model_name?: string
  scale?: number
  patch_size?: number | null
  datasetInfo?: DatasetValidationInfo
}): {
  patch_sizes: number[]
  lr_sizes: number[]
  divisor: number
  max_dim?: number
  reason?: string
} {
  const scale = params.scale ?? params.datasetInfo?.scale ?? null
  const divisor = getModelDivisor(params.model_name)
  if (!scale || !Number.isFinite(scale) || scale <= 0) {
    return {
      patch_sizes: [],
      lr_sizes: [],
      divisor,
      reason: 'ç¼ºå°‘æœ‰æ•ˆçš„ scale',
    }
  }

  const maxDim = getMaxHrDim(params.datasetInfo)
  if (maxDim !== null && maxDim < scale) {
    return {
      patch_sizes: [],
      lr_sizes: [],
      divisor,
      max_dim: maxDim,
      reason: `HR å°ºå¯¸è¿‡å°ï¼ˆ${maxDim} < scale ${scale}ï¼‰`,
    }
  }

  let minK = 0
  if (divisor > 1 && isPowerOfTwo(divisor)) {
    const divisorPow = Math.log2(divisor)
    const scalePow = countPowerOfTwoFactor(scale)
    minK = Math.max(0, Math.ceil(divisorPow - scalePow))
  }

  let maxK = minK + 8
  if (maxDim !== null) {
    const ratio = maxDim / scale
    if (ratio >= 1) {
      maxK = Math.floor(Math.log2(ratio))
    } else {
      maxK = minK - 1
    }
  }

  if (maxK < minK) {
    return {
      patch_sizes: [],
      lr_sizes: [],
      divisor,
      max_dim: maxDim ?? undefined,
      reason: 'HR å°ºå¯¸ä¸è¶³ä»¥æ»¡è¶³ 2 çš„å¹‚ä¸æ•´é™¤è¦æ±‚',
    }
  }

  const candidates: number[] = []
  for (let k = minK; k <= maxK; k += 1) {
    const lrSize = Math.pow(2, k)
    const patchSize = scale * lrSize
    if (!Number.isFinite(patchSize)) continue
    if (divisor > 1 && patchSize % divisor !== 0) continue
    if (maxDim !== null && patchSize > maxDim) break
    candidates.push(patchSize)
  }

  if (candidates.length === 0) {
    return {
      patch_sizes: [],
      lr_sizes: [],
      divisor,
      max_dim: maxDim ?? undefined,
      reason: 'æœªæ‰¾åˆ°æ»¡è¶³çº¦æŸçš„ patch_size',
    }
  }

  const target = params.patch_size ?? (maxDim ? Math.min(Math.floor(maxDim / 2), 256) : candidates[0])
  const sorted = candidates
    .slice()
    .sort((a, b) => {
      const da = Math.abs(a - target)
      const db = Math.abs(b - target)
      if (da !== db) return da - db
      return a - b
    })
    .slice(0, 3)

  return {
    patch_sizes: sorted,
    lr_sizes: sorted.map(size => size / scale),
    divisor,
    max_dim: maxDim ?? undefined,
  }
}

function getSpatialDims(shape?: number[] | null): [number, number] | null {
  if (!shape || shape.length < 2) return null
  const height = shape[shape.length - 2]
  const width = shape[shape.length - 1]
  if (!Number.isFinite(height) || !Number.isFinite(width)) return null
  return [height, width]
}

function resolveFftInputDims(params: {
  datasetInfo?: DatasetValidationInfo
  scale?: number
  patch_size?: number | null
}): { height: number; width: number; source: string } | null {
  const { datasetInfo, scale, patch_size } = params
  const resolvedScale = scale ?? datasetInfo?.scale ?? null

  if (patch_size !== undefined && patch_size !== null && resolvedScale && resolvedScale > 0) {
    const lrSize = patch_size / resolvedScale
    if (Number.isInteger(lrSize)) {
      return {
        height: lrSize,
        width: lrSize,
        source: `patch_size(${patch_size})/scale(${resolvedScale})`,
      }
    }
  }

  const lrDims = getSpatialDims(datasetInfo?.lr_shape)
  if (lrDims) {
    return {
      height: lrDims[0],
      width: lrDims[1],
      source: 'lr_shape',
    }
  }

  const hrDims = getSpatialDims(datasetInfo?.hr_shape)
  if (hrDims && resolvedScale && resolvedScale > 0) {
    const hrHeight = hrDims[0]
    const hrWidth = hrDims[1]
    if (hrHeight % resolvedScale === 0 && hrWidth % resolvedScale === 0) {
      return {
        height: hrHeight / resolvedScale,
        width: hrWidth / resolvedScale,
        source: `hr_shape/scale(${resolvedScale})`,
      }
    }
  }

  return null
}

function buildFftAmpIncompatibility(params: {
  model_name?: string
  use_amp?: boolean
  datasetInfo?: DatasetValidationInfo
  scale?: number
  patch_size?: number | null
}): {
  message: string
  details: {
    lr_height: number
    lr_width: number
    source: string
    divisor?: number
    max_dim?: number
    recommended_patch_sizes?: number[]
    recommended_lr_sizes?: number[]
  }
} | null {
  const { model_name, use_amp, datasetInfo, scale, patch_size } = params
  if (!isFftSensitiveModel(model_name)) return null
  if (use_amp !== true) return null
  if (!datasetInfo || datasetInfo.status !== 'ok') return null

  const dims = resolveFftInputDims({ datasetInfo, scale, patch_size })
  if (!dims) return null

  const { height, width, source } = dims
  if (isPowerOfTwo(height) && isPowerOfTwo(width)) return null

  const recommendations = buildFftPatchRecommendations({
    model_name,
    scale,
    patch_size,
    datasetInfo,
  })
  const recPatchSizes = recommendations.patch_sizes
  const recLrSizes = recommendations.lr_sizes
  const recDetail =
    recPatchSizes.length > 0
      ? `\nâœ… æ¨è patch_sizeï¼ˆæ»¡è¶³ LR=2^k${recommendations.divisor > 1 ? `ï¼Œä¸”å¯è¢« ${recommendations.divisor} æ•´é™¤` : ''}${recommendations.max_dim ? `ï¼Œä¸” â‰¤ ${recommendations.max_dim}` : ''}ï¼‰ï¼š${recPatchSizes.join(', ')}\n   å¯¹åº” LR å°ºå¯¸ï¼š${recLrSizes.join(', ')}`
      : recommendations.reason
        ? `\nâš ï¸ æ— æ³•ç»™å‡ºæ¨è patch_sizeï¼š${recommendations.reason}`
        : ''

  const message = `================================================================================
âš ï¸ FFT + AMP å…¼å®¹æ€§æé†’ï¼ˆé¿å… cuFFT å´©æºƒï¼‰
================================================================================

æ£€æµ‹åˆ°æ¨¡å‹ä¸º **${model_name}** ä¸” **use_amp=true**ã€‚
cuFFT åœ¨åŠç²¾åº¦ä¸‹è¦æ±‚ FFT è¾“å…¥å°ºå¯¸ä¸º **2 çš„å¹‚**ã€‚

å½“å‰ LR å°ºå¯¸ï¼š${height} Ã— ${width}ï¼ˆæ¥æºï¼š${source}ï¼‰

âœ… è§£å†³æ–¹æ¡ˆï¼ˆéœ€ç”¨æˆ·ç¡®è®¤ï¼‰ï¼š
1) è®¾ç½® use_amp=falseï¼ˆæœ€ç®€å•ï¼ŒFNO/HiNOTE ç­‰ FFT æ¨¡å‹æ¨èï¼‰
2) é‡æ–°é¢„å¤„ç†ä¸º 2 çš„å¹‚å°ºå¯¸ï¼ˆå¦‚ 64/128ï¼‰
3) è®¾ç½® patch_sizeï¼Œä½¿ LR å°ºå¯¸ä¸º 2 çš„å¹‚ï¼ˆå¹¶æ»¡è¶³ scale/model_divisorï¼‰
${recDetail}

è¯·ä¿®æ”¹å‚æ•°åå†ç»§ç»­ç¡®è®¤æ‰§è¡Œã€‚
================================================================================`

  return {
    message,
    details: {
      lr_height: height,
      lr_width: width,
      source,
      divisor: recommendations.divisor,
      max_dim: recommendations.max_dim,
      recommended_patch_sizes: recPatchSizes.length > 0 ? recPatchSizes : undefined,
      recommended_lr_sizes: recLrSizes.length > 0 ? recLrSizes : undefined,
    },
  }
}

function buildOomPreWarning(params: {
  gpuInfo?: GpuInfo
  device_ids?: number[]
}): {
  message: string
  details: {
    low_gpus: Array<{
      id: number
      free_gb: number
      total_gb: number
      free_ratio: number
    }>
  }
} | null {
  const { gpuInfo, device_ids } = params
  if (!gpuInfo || !gpuInfo.cuda_available) return null
  if (!device_ids || device_ids.length === 0) return null

  const LOW_FREE_GB = 2
  const LOW_FREE_RATIO = 0.1

  const selected = gpuInfo.gpus.filter((gpu) => device_ids.includes(gpu.id))
  if (selected.length === 0) return null

  const lowGpus = selected.filter((gpu) => {
    const freeRatio = gpu.total_memory_gb > 0 ? gpu.free_memory_gb / gpu.total_memory_gb : 0
    return gpu.free_memory_gb < LOW_FREE_GB || freeRatio < LOW_FREE_RATIO
  })

  if (lowGpus.length === 0) return null

  const detailLines = lowGpus
    .map((gpu) => `- GPU ${gpu.id}: ${gpu.free_memory_gb}GB / ${gpu.total_memory_gb}GB ç©ºé—²`)
    .join('\n')

  return {
    message: `================================================================================
âš ï¸ æ˜¾å­˜é¢„è­¦ï¼ˆå¯èƒ½ OOMï¼‰
================================================================================

æ£€æµ‹åˆ°æ‰€é€‰ GPU ç©ºé—²æ˜¾å­˜åä½ï¼š
${detailLines}

å»ºè®®ï¼šå‡å° batch_sizeï¼Œè®¾ç½® patch_sizeï¼Œæˆ–æ›´æ¢ç©ºé—² GPUã€‚
================================================================================`,
    details: {
      low_gpus: lowGpus.map((gpu) => ({
        id: gpu.id,
        free_gb: gpu.free_memory_gb,
        total_gb: gpu.total_memory_gb,
        free_ratio: gpu.total_memory_gb > 0 ? gpu.free_memory_gb / gpu.total_memory_gb : 0,
      })),
    },
  }
}

async function validateDataset(
  datasetRoot: string,
  pythonPath: string,
  trainingDir: string,
  ctx: { sandbox: { exec: (cmd: string, options?: { timeoutMs?: number }) => Promise<{ code: number; stdout: string; stderr: string }> } },
): Promise<DatasetValidationInfo> {
  const validateScript = path.join(trainingDir, 'validate_dataset.py')
  const validateResult = await ctx.sandbox.exec(
    `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(validateScript)}" --dataset_root "${shellEscapeDouble(datasetRoot)}"`,
    { timeoutMs: 60000 }
  )
  if (validateResult.code === 0) {
    return JSON.parse(validateResult.stdout)
  }

  return {
    status: 'error',
    dataset_root: datasetRoot,
    dyn_vars: [],
    scale: null,
    hr_shape: null,
    lr_shape: null,
    splits: {},
    has_static: false,
    static_vars: [],
    total_samples: { hr: 0, lr: 0 },
    warnings: [],
    errors: [`éªŒè¯è„šæœ¬æ‰§è¡Œå¤±è´¥: ${validateResult.stderr}`]
  }
}

/**
 * è°ƒç”¨ recommend_hyperparams.py è·å–è¶…å‚æ•°æ¨èã€‚
 * å¤±è´¥æ—¶è¿”å› nullï¼Œä¸æŠ›å‡ºå¼‚å¸¸ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰ã€‚
 */
async function runHyperparamRecommendation(
  args: {
    dataset_root?: string
    model_name?: string
    scale?: number
    dyn_vars?: string[]
    device_ids?: number[]
  },
  pythonPath: string,
  trainingDir: string,
  ctx: { sandbox: { exec: (cmd: string, options?: { timeoutMs?: number }) => Promise<{ code: number; stdout: string; stderr: string }> } },
): Promise<Record<string, unknown> | null> {
  if (!args.dataset_root || !args.model_name || !args.scale || !args.dyn_vars?.length) {
    return null
  }
  try {
    const recommendScript = path.join(trainingDir, 'recommend_hyperparams.py')
    const deviceId = Number(args.device_ids?.[0] ?? 0)
    const cmd = [
      `cd "${shellEscapeDouble(trainingDir)}"`,
      `&&`,
      `CUDA_VISIBLE_DEVICES=${deviceId}`,
      `"${shellEscapeDouble(pythonPath)}"`,
      `"${shellEscapeDouble(recommendScript)}"`,
      `--dataset_root "${shellEscapeDouble(args.dataset_root)}"`,
      `--model_name "${shellEscapeDouble(args.model_name)}"`,
      `--scale ${args.scale}`,
      `--dyn_vars "${shellEscapeDouble(args.dyn_vars.join(','))}"`,
      `--device 0`,
    ].join(' ')
    const result = await ctx.sandbox.exec(cmd, { timeoutMs: 180000 })
    if (result.code !== 0) return null
    return extractTaggedJson(result.stdout, 'recommend')
  } catch {
    return null
  }
}

/**
 * å°†è¶…å‚æ•°æ¨èç»“æœæ ¼å¼åŒ–ä¸ºç”¨æˆ·å¯è¯»çš„æ¶ˆæ¯æ®µè½ã€‚
 */
function formatRecommendationMessage(rec: Record<string, unknown>): string {
  const recommendations = rec.recommendations as Record<string, unknown> | undefined
  const reasoning = rec.reasoning as Record<string, unknown> | undefined
  const datasetInfo = rec.dataset_info as Record<string, unknown> | undefined
  const gpuInfo = rec.gpu_info as Record<string, unknown> | undefined
  const spectral = rec.spectral_analysis as Record<string, unknown> | undefined
  const modelNotes = rec.model_notes as Record<string, unknown> | undefined

  if (!recommendations) return ''

  const lines: string[] = [
    '================================================================================',
    '                    ğŸ’¡ è¶…å‚æ•°æ¨èï¼ˆåŸºäºå®æµ‹æ˜¾å­˜ + æ•°æ®åˆ†æï¼‰',
    '================================================================================',
  ]

  // æ•°æ®é›† & GPU åŸºæœ¬ä¿¡æ¯
  if (datasetInfo || gpuInfo) {
    lines.push('\nã€åˆ†æåŸºç¡€ã€‘')
    if (datasetInfo) {
      lines.push(`- è®­ç»ƒé›†ï¼š${datasetInfo.n_train} ä¸ªæ ·æœ¬ï¼ŒHR ${(datasetInfo.hr_shape as number[])?.join(' Ã— ') ?? '?'}ï¼Œ${datasetInfo.n_vars} ä¸ªå˜é‡`)
    }
    if (gpuInfo && gpuInfo.name) {
      lines.push(`- GPUï¼š${gpuInfo.name}ï¼ˆ${gpuInfo.total_gb ?? '?'} GBï¼‰`)
    }
  }

  // æ¨èå‚æ•°
  lines.push('\nã€æ¨èå‚æ•°ã€‘')
  if (recommendations.batch_size !== undefined)
    lines.push(`- batch_size:        ${recommendations.batch_size}`)
  if (recommendations.eval_batch_size !== undefined)
    lines.push(`- eval_batch_size:   ${recommendations.eval_batch_size}`)
  if (recommendations.epochs !== undefined)
    lines.push(`- epochs:            ${recommendations.epochs}`)
  if (recommendations.lr !== undefined)
    lines.push(`- lr:                ${(recommendations.lr as number).toExponential(2)}`)
  if (recommendations.gradient_checkpointing !== undefined)
    lines.push(`- gradient_checkpointing: ${recommendations.gradient_checkpointing}`)

  // æ¨èç†ç”±
  if (reasoning && Object.keys(reasoning).length > 0) {
    lines.push('\nã€æ¨èç†ç”±ã€‘')
    for (const [key, val] of Object.entries(reasoning)) {
      lines.push(`- ${key}: ${val}`)
    }
  }

  // é¢‘è°±åˆ†æ
  if (spectral) {
    lines.push('\nã€æ•°æ®é¢‘è°±åˆ†æï¼ˆä»…ä¾›å‚è€ƒï¼Œä¸è‡ªåŠ¨ä¿®æ”¹æ¨¡å‹ç»“æ„ï¼‰ã€‘')
    lines.push(`- é¢‘ç‡ç‰¹å¾ï¼š${spectral.freq_desc}ï¼ˆk90 â‰ˆ ${spectral.k90_mean}ï¼Œmax_k = ${spectral.max_k}ï¼‰`)
  }

  // æ¨¡å‹ç‰¹å®šæç¤º
  if (modelNotes) {
    lines.push('\nã€æ¨¡å‹ç»“æ„å‚æ•°å‚è€ƒã€‘')
    for (const [, note] of Object.entries(modelNotes)) {
      lines.push(`- ${note}`)
    }
  }

  lines.push('\nâš ï¸ Agent æ³¨æ„ï¼šä»¥ä¸Šä¸ºç³»ç»Ÿæ¨èå€¼ï¼Œè¯·å‘ŠçŸ¥ç”¨æˆ·å¹¶è¯¢é—®æ˜¯å¦é‡‡ç”¨æˆ–è°ƒæ•´ï¼Œå†ç»§ç»­æ‰§è¡Œç¡®è®¤ã€‚')
  lines.push('================================================================================')

  return lines.join('\n')
}

export const oceanSrTrainTool = defineTool({
  name: 'ocean_sr_train',
  description: `æ‰§è¡Œæµ·æ´‹è¶…åˆ†è¾¨ç‡æ¨¡å‹è®­ç»ƒæˆ–æµ‹è¯•ã€‚

**åˆ†é˜¶æ®µç¡®è®¤æµç¨‹**ï¼ˆæ¯é˜¶æ®µå¿…é¡»ç­‰å¾…ç”¨æˆ·ç¡®è®¤ï¼‰ï¼š
1. ç¡®è®¤æ•°æ®ç›®å½•å’Œè¾“å‡ºç›®å½•ï¼ˆè‡ªåŠ¨æ£€æµ‹å˜é‡å’Œ scaleï¼‰
2. é€‰æ‹©è®­ç»ƒæ¨¡å‹
3. ç¡®è®¤è®­ç»ƒå‚æ•°ï¼ˆåŒ…æ‹¬ GPU é€‰æ‹©ï¼‰
4. æœ€ç»ˆç¡®è®¤æ‰§è¡Œ

**é¦–æ¬¡è°ƒç”¨**ï¼šåªä¼  dataset_root å’Œ log_dirï¼Œå·¥å…·ä¼šè‡ªåŠ¨æ£€æµ‹æ•°æ®å¹¶å±•ç¤ºä¿¡æ¯
**é€æ­¥è¡¥å……å‚æ•°**ï¼šæ¯æ¬¡è°ƒç”¨è¡¥å……è¯¥é˜¶æ®µéœ€è¦çš„å‚æ•°ï¼Œç›´åˆ°æ‰€æœ‰é˜¶æ®µé€šè¿‡
**æœ€ç»ˆæ‰§è¡Œ**ï¼šä¼ å…¥ user_confirmed=true å’Œ confirmation_token åå¯åŠ¨åå°è®­ç»ƒ

**åå°æ‰§è¡Œæ¨¡å¼**ï¼š
- è®­ç»ƒå¯åŠ¨åç«‹å³è¿”å› process_idï¼Œä¸ä¼šé˜»å¡ç­‰å¾…è®­ç»ƒå®Œæˆ
- ä½¿ç”¨ ocean_sr_train_status å·¥å…·æŸ¥è¯¢è®­ç»ƒçŠ¶æ€å’Œå®æ—¶æ—¥å¿—
- æœåŠ¡å™¨å…³é—­æ—¶ä¼šè‡ªåŠ¨ç»ˆæ­¢è®­ç»ƒè¿›ç¨‹

**è®­ç»ƒæ¨¡å¼ (mode=train)**ï¼šæ‰§è¡Œå®Œæ•´è®­ç»ƒæµç¨‹ï¼ŒåŒ…å«éªŒè¯å’Œæ—©åœ
**æµ‹è¯•æ¨¡å¼ (mode=test)**ï¼šåŠ è½½æœ€ä½³æ¨¡å‹ï¼Œåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
**é¢„æµ‹æ¨¡å¼ (mode=predict)**ï¼šåŠ è½½æ¨¡å‹å¯¹æµ‹è¯•é›†æ‰§è¡Œå…¨å›¾ SR æ¨ç†ï¼Œè¾“å‡º NPY æ–‡ä»¶ï¼ˆè·³è¿‡è®­ç»ƒå·¥ä½œæµï¼‰

**GPU æ¨¡å¼**ï¼š
- å•å¡ï¼šdevice_ids é•¿åº¦ä¸º 1
- å¤šå¡ DPï¼šdistribute=true, distribute_mode="DP"
- å¤šå¡ DDPï¼ˆæ¨èï¼‰ï¼šdistribute=true, distribute_mode="DDP"`,

  params: {
    dataset_root: {
      type: 'string',
      description: 'é¢„å¤„ç†æ•°æ®æ ¹ç›®å½•ï¼ˆocean-preprocess è¾“å‡ºç›®å½•ï¼‰',
      required: false
    },
    log_dir: {
      type: 'string',
      description: 'è®­ç»ƒæ—¥å¿—è¾“å‡ºç›®å½•',
      required: false
    },
    model_name: {
      type: 'string',
      description: 'æ¨¡å‹åç§°ï¼ˆå¦‚ SwinIR, FNO2d, DDPM ç­‰ï¼‰',
      required: false
    },
    dyn_vars: {
      type: 'array',
      items: { type: 'string' },
      description: 'åŠ¨æ€å˜é‡åˆ—è¡¨ï¼ˆå¦‚ ["temp", "salt"]ï¼‰ã€‚å¦‚ä¸æä¾›ï¼Œå°†ä»æ•°æ®ç›®å½•è‡ªåŠ¨æ£€æµ‹å¹¶è¦æ±‚ç¡®è®¤ã€‚',
      required: false
    },
    scale: {
      type: 'number',
      description: 'è¶…åˆ†è¾¨ç‡å€æ•°ã€‚å¦‚ä¸æä¾›ï¼Œå°†ä»æ•°æ®ç›®å½•è‡ªåŠ¨æ¨ç®—å¹¶è¦æ±‚ç¡®è®¤ã€‚',
      required: false
    },
    mode: {
      type: 'string',
      description: 'è¿è¡Œæ¨¡å¼: "train", "test" æˆ– "predict"ï¼ˆpredict è·³è¿‡è®­ç»ƒå·¥ä½œæµï¼Œç›´æ¥æ¨ç†ï¼‰',
      required: false,
      default: 'train'
    },
    epochs: {
      type: 'number',
      description: 'è®­ç»ƒè½®æ•°',
      required: false,
      default: 500
    },
    lr: {
      type: 'number',
      description: 'å­¦ä¹ ç‡',
      required: false,
      default: 0.001
    },
    batch_size: {
      type: 'number',
      description: 'è®­ç»ƒ batch size',
      required: false,
      default: 4
    },
    eval_batch_size: {
      type: 'number',
      description: 'è¯„ä¼° batch size',
      required: false,
      default: 4
    },
    device_ids: {
      type: 'array',
      items: { type: 'number' },
      description: 'ä½¿ç”¨çš„ GPU åˆ—è¡¨ï¼ˆå¦‚ [0, 1, 2, 3]ï¼‰ã€‚å¿…é¡»ç”±ç”¨æˆ·ç¡®è®¤ã€‚è‹¥å¯ç”¨å¤šå¡è®­ç»ƒï¼Œè‡³å°‘éœ€è¦ä¸¤ä¸ª GPUã€‚',
      required: false
    },
    distribute: {
      type: 'boolean',
      description: 'æ˜¯å¦å¯ç”¨å¤šå¡è®­ç»ƒ',
      required: false,
      default: false
    },
    distribute_mode: {
      type: 'string',
      description: 'å¤šå¡æ¨¡å¼: "DP" æˆ– "DDP"',
      required: false,
      default: 'DDP'
    },
    master_port: {
      type: 'number',
      description: 'DDP ä¸»ç«¯å£ï¼ˆå¯é€‰ï¼Œç«¯å£å†²çªæ—¶å¯æŒ‡å®šï¼‰',
      required: false
    },
    patience: {
      type: 'number',
      description: 'æ—©åœè€å¿ƒå€¼',
      required: false,
      default: 10
    },
    eval_freq: {
      type: 'number',
      description: 'è¯„ä¼°é¢‘ç‡ï¼ˆæ¯ N ä¸ª epochï¼‰',
      required: false,
      default: 5
    },
    normalize: {
      type: 'boolean',
      description: 'æ˜¯å¦å½’ä¸€åŒ–',
      required: false,
      default: true
    },
    normalizer_type: {
      type: 'string',
      description: 'å½’ä¸€åŒ–ç±»å‹: "PGN" æˆ– "GN"',
      required: false,
      default: 'PGN'
    },
    optimizer: {
      type: 'string',
      description: 'ä¼˜åŒ–å™¨: "AdamW", "Adam", "SGD"',
      required: false,
      default: 'AdamW'
    },
    weight_decay: {
      type: 'number',
      description: 'æƒé‡è¡°å‡',
      required: false,
      default: 0.001
    },
    scheduler: {
      type: 'string',
      description: 'å­¦ä¹ ç‡è°ƒåº¦å™¨: "StepLR", "MultiStepLR", "OneCycleLR"',
      required: false,
      default: 'StepLR'
    },
    scheduler_step_size: {
      type: 'number',
      description: 'è°ƒåº¦å™¨æ­¥é•¿',
      required: false,
      default: 300
    },
    scheduler_gamma: {
      type: 'number',
      description: 'è°ƒåº¦å™¨è¡°å‡ç‡',
      required: false,
      default: 0.5
    },
    seed: {
      type: 'number',
      description: 'éšæœºç§å­',
      required: false,
      default: 42
    },
    wandb: {
      type: 'boolean',
      description: 'æ˜¯å¦å¯ç”¨ WandB æ—¥å¿—',
      required: false,
      default: false
    },
    use_amp: {
      type: 'boolean',
      description: 'æ˜¯å¦å¯ç”¨ AMP æ··åˆç²¾åº¦è®­ç»ƒï¼ˆå‡å°‘çº¦ 40-50% æ˜¾å­˜ï¼›é»˜è®¤ï¼šé FFT å¼€å¯ / FFT é¢‘åŸŸæ¨¡å‹å…³é—­ï¼‰',
      required: false
    },
    gradient_checkpointing: {
      type: 'boolean',
      description: 'æ˜¯å¦å¯ç”¨ Gradient Checkpointingï¼ˆå‡å°‘çº¦ 60% æ¿€æ´»æ˜¾å­˜ï¼Œå¢åŠ çº¦ 30% è®¡ç®—æ—¶é—´ï¼Œé»˜è®¤å¼€å¯ï¼‰',
      required: false,
      default: true
    },
    patch_size: {
      type: 'number',
      description: 'HR Patch è£å‰ªå°ºå¯¸ï¼ˆå¦‚ 64, 128ï¼‰ï¼Œè®¾ç½®åè®­ç»ƒæ—¶éšæœºè£å‰ªå°åŒºåŸŸè€Œéå…¨å›¾è®­ç»ƒã€‚å¿…é¡»èƒ½è¢« scale æ•´é™¤ã€‚',
      required: false
    },
    ckpt_path: {
      type: 'string',
      description: 'æ¢å¤è®­ç»ƒçš„æ£€æŸ¥ç‚¹è·¯å¾„',
      required: false
    },
    user_confirmed: {
      type: 'boolean',
      description: 'ã€å¿…é¡»ã€‘ç”¨æˆ·ç¡®è®¤æ ‡å¿—ã€‚å¿…é¡»åœ¨å±•ç¤ºå‚æ•°æ±‡æ€»å¹¶è·å¾—ç”¨æˆ·æ˜ç¡®ç¡®è®¤åï¼Œæ‰èƒ½è®¾ç½®ä¸º trueã€‚ç¦æ­¢è‡ªåŠ¨è®¾ç½®ï¼',
      required: false,
      default: false
    },
    confirmation_token: {
      type: 'string',
      description: 'æ‰§è¡Œç¡®è®¤ Tokenã€‚å¿…é¡»ä» awaiting_execution é˜¶æ®µçš„è¿”å›å€¼ä¸­è·å–ã€‚',
      required: false
    }
  },

  async exec(args, ctx) {
    // è®­ç»ƒå·¥å…·éœ€è¦ torchï¼Œä¼˜å…ˆæŸ¥æ‰¾å®‰è£…äº† torch çš„ Python
    const pythonPath = findPythonWithModule('torch') || findFirstPythonPath()
    if (!pythonPath) {
      throw new Error('æœªæ‰¾åˆ°å¯ç”¨çš„ Python è§£é‡Šå™¨ï¼ˆéœ€è¦å®‰è£… torchï¼‰')
    }

    const trainingDir = path.resolve(process.cwd(), 'scripts/ocean_SR_training_masked')

    const userSpecifiedUseAmp = Object.prototype.hasOwnProperty.call(args, 'use_amp')
    const ampDefaultOff = isAmpDefaultOffModel(args.model_name as string | undefined)
    let autoDisabledAmp = false

    if (!userSpecifiedUseAmp && args.model_name) {
      if (ampDefaultOff) {
        args.use_amp = false
        autoDisabledAmp = true
      } else {
        args.use_amp = true
      }
    }

    // ===== 1. æ„å»ºå·¥ä½œæµå‚æ•°ï¼ˆåˆå¹¶ session ç¼“å­˜ï¼Œé˜²æ­¢å¯é€‰å‚æ•°è·¨è°ƒç”¨ä¸¢å¤±ï¼‰ =====
    // use_amp è‹¥éç”¨æˆ·æ˜¾å¼ä¼ å…¥ï¼Œåˆ™ä» args ä¸­ç§»é™¤ï¼Œé¿å…è‡ªåŠ¨è®¾ç½®å€¼è¦†ç›– session ä¸­ç”¨æˆ·çš„é€‰æ‹©
    const workflowArgs = { ...args }
    if (!userSpecifiedUseAmp) {
      delete workflowArgs.use_amp
    }
    const sessionParams = args.log_dir ? await loadSessionParams(args.log_dir, ctx) : null
    const workflow = new TrainingWorkflow(workflowArgs, sessionParams ?? undefined)
    const stateCheck = workflow.determineCurrentState()

    // ===== 2. å¦‚æœæœªåˆ° PASS é˜¶æ®µï¼Œæ”¶é›†ä¸Šä¸‹æ–‡ä¿¡æ¯å¹¶è¿”å›æç¤º =====
    if (stateCheck.currentState !== TrainingState.PASS) {
      const context: {
        datasetInfo?: DatasetValidationInfo
        gpuInfo?: GpuInfo
        modelList?: ModelInfo[]
      } = {}

      // å¦‚æœæœ‰ dataset_rootï¼ŒéªŒè¯æ•°æ®ç›®å½•
      if (args.dataset_root) {
        context.datasetInfo = await validateDataset(args.dataset_root, pythonPath, trainingDir, ctx)
      }

      // é˜¶æ®µ2+éœ€è¦æ¨¡å‹åˆ—è¡¨
      if (stateCheck.currentState === TrainingState.AWAITING_MODEL_SELECTION) {
        const listScript = path.join(trainingDir, 'list_models.py')
        const listResult = await ctx.sandbox.exec(
          `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(listScript)}"`,
          { timeoutMs: 30000 }
        )
        if (listResult.code === 0) {
          const parsed = JSON.parse(listResult.stdout)
          context.modelList = parsed.models
        }
      }

      // é˜¶æ®µ3+éœ€è¦ GPU ä¿¡æ¯
      if (
        stateCheck.currentState === TrainingState.AWAITING_PARAMETERS ||
        stateCheck.currentState === TrainingState.AWAITING_EXECUTION ||
        stateCheck.currentState === TrainingState.TOKEN_INVALID
      ) {
        const gpuScript = path.join(trainingDir, 'check_gpu.py')
        const gpuResult = await ctx.sandbox.exec(
          `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(gpuScript)}"`,
          { timeoutMs: 30000 }
        )
        if (gpuResult.code === 0) {
          context.gpuInfo = JSON.parse(gpuResult.stdout)
        }
      }

      const prompt = workflow.getStagePrompt(context)
      const fnoAmpWarning = buildFftAmpIncompatibility({
        model_name: args.model_name,
        use_amp: args.use_amp ?? true,
        datasetInfo: context.datasetInfo,
        scale: args.scale,
        patch_size: args.patch_size ?? null,
      })
      if (fnoAmpWarning) {
        prompt.message = `${prompt.message}\n\n${fnoAmpWarning.message}`
        prompt.data = {
          ...(prompt.data ?? {}),
          fft_amp_warning: fnoAmpWarning.details,
          fno_amp_warning: fnoAmpWarning.details,
        }
      }

      if (args.use_amp === true && isAmpDefaultOffModel(args.model_name) && !isFftSensitiveModel(args.model_name)) {
        prompt.message = `${prompt.message}\n\nâš ï¸ æ£€æµ‹åˆ°æ¨¡å‹ ${args.model_name} é»˜è®¤å…³é—­ AMPï¼Œä½†å½“å‰ use_amp=true å¯èƒ½å¯¼è‡´æ•°å€¼ä¸ç¨³å®šï¼ˆå¦‚ NaNï¼‰ã€‚å»ºè®® use_amp=falseï¼›å¦‚éœ€å¼ºè¡Œå¼€å¯è¯·è‡ªè¡Œæ‰¿æ‹…é£é™©ã€‚`
      }

      if (autoDisabledAmp) {
        prompt.message = `${prompt.message}\n\næ£€æµ‹åˆ°æ¨¡å‹ ${args.model_name} å±äº FFT/æ•°å€¼æ•æ„Ÿæ¨¡å‹ï¼Œå·²é»˜è®¤å…³é—­ AMPï¼ˆuse_amp=falseï¼‰ã€‚å¦‚éœ€å¼ºåˆ¶å¼€å¯ï¼Œè¯·æ˜ç¡®è®¾ç½® use_amp=trueã€‚`
        prompt.data = {
          ...(prompt.data ?? {}),
          amp_auto_disabled: { model: args.model_name },
        }
      }

      if (
        args.model_name &&
        FFT_AMP_SENSITIVE_MODELS.has(args.model_name as string) &&
        userSpecifiedUseAmp &&
        args.use_amp === true
      ) {
        prompt.message = `${prompt.message}\n\nä½ å·²æ‰‹åŠ¨å¯ç”¨ AMPï¼ˆå¼ºçƒˆä¸å»ºè®®ï¼‰ã€‚FFT ç±»æ¨¡å‹å¯èƒ½è§¦å‘ cuFFT å°ºå¯¸é™åˆ¶é”™è¯¯ï¼Œå¦‚ä»è¦ç»§ç»­è¯·ç¡®è®¤ã€‚`
        prompt.data = {
          ...(prompt.data ?? {}),
          amp_user_override: { model: args.model_name },
        }
      }

      const oomWarning = buildOomPreWarning({
        gpuInfo: context.gpuInfo,
        device_ids: args.device_ids,
      })
      if (oomWarning) {
        prompt.message = `${prompt.message}\n\n${oomWarning.message}`
        prompt.data = {
          ...(prompt.data ?? {}),
          oom_warning: oomWarning.details,
        }
      }
      // AWAITING_EXECUTION æ—¶æŒä¹…åŒ–å…¨é‡å‚æ•°ï¼Œä¾›åç»­æ‰§è¡Œè°ƒç”¨æ¢å¤å¯é€‰å‚æ•°ï¼ˆå¦‚ normalizer_typeï¼‰
      if (stateCheck.currentState === TrainingState.AWAITING_EXECUTION && args.log_dir) {
        await saveSessionParams(args.log_dir, workflow.getParams(), ctx)
      }
      // AWAITING_EXECUTION æ—¶è¿è¡Œè¶…å‚æ•°æ¨èï¼ˆå®æµ‹æ˜¾å­˜ + æ•°æ®é›†åˆ†æï¼‰
      if (stateCheck.currentState === TrainingState.AWAITING_EXECUTION) {
        const recResult = await runHyperparamRecommendation(args, pythonPath, trainingDir, ctx)
        if (recResult?.status === 'success') {
          const recMsg = formatRecommendationMessage(recResult)
          if (recMsg) {
            prompt.message = `${prompt.message}\n\n${recMsg}`
          }
          prompt.data = {
            ...(prompt.data ?? {}),
            hyperparameter_recommendations: recResult,
          }
        }
      }
      return {
        status: prompt.status,
        message: prompt.message,
        canExecute: prompt.canExecute,
        ...prompt.data
      }
    }

    // ===== 3. PASS é˜¶æ®µï¼šæ‰§è¡Œè®­ç»ƒ =====
    const {
      dataset_root,
      log_dir,
      model_name,
      dyn_vars,
      scale,
      mode = 'train',
      device_ids = [0],
      distribute = false,
      distribute_mode = 'DDP',
      ckpt_path,
    } = args

    if (!log_dir) {
      return {
        status: 'error',
        error: 'æœªæŒ‡å®šè®­ç»ƒæ—¥å¿—è¾“å‡ºç›®å½• (log_dir)',
        suggestion: 'è¯·åœ¨å‚æ•°ä¸­æä¾› log_dir'
      }
    }

    // ===== predict å¿«é€Ÿé€šé“ï¼šè·³è¿‡è®­ç»ƒä¸“å±æ­¥éª¤ï¼ˆOOM/shape/FFTï¼‰ï¼Œç›´æ¥å‡†å¤‡ + å¯åŠ¨ =====
    if (mode === 'predict') {
      if (!dataset_root) {
        return { status: 'error', error: 'éœ€è¦ dataset_root', suggestion: 'è¯·æä¾›é¢„å¤„ç†æ•°æ®æ ¹ç›®å½•' }
      }
      if (!model_name) {
        return { status: 'error', error: 'éœ€è¦ model_name', suggestion: 'è¯·æä¾›æ¨¡å‹åç§°' }
      }

      const normalizedDeviceIds = Array.isArray(device_ids) && device_ids.length > 0 ? device_ids : [0]

      // å‡†å¤‡å·¥ä½œç©ºé—´
      const workspaceDir = path.resolve(log_dir, '_ocean_sr_code')
      const prepareScript = path.join(trainingDir, 'prepare_workspace.py')
      const prepareResult = await ctx.sandbox.exec(
        `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(prepareScript)}" --source_dir "${shellEscapeDouble(trainingDir)}" --target_dir "${shellEscapeDouble(workspaceDir)}" --model_name "${shellEscapeDouble(model_name)}"`,
        { timeoutMs: 60000 }
      )
      if (prepareResult.code !== 0) {
        return {
          status: 'error',
          error: `å·¥ä½œç©ºé—´å‡†å¤‡å¤±è´¥: ${prepareResult.stderr}`,
          suggestion: `è¯·æ£€æŸ¥è¾“å‡ºç›®å½• ${log_dir} æ˜¯å¦å­˜åœ¨ä¸”æœ‰å†™å…¥æƒé™`
        }
      }
      const prepareInfo = JSON.parse(prepareResult.stdout)

      // ç”Ÿæˆé…ç½®ï¼ˆpredict æœ€å°å‚æ•°é›†ï¼Œnormalizer_type ä» mergedParams è·å–ä»¥ä¿ç•™ç”¨æˆ·é€‰æ‹©ï¼‰
      const predictMergedParams = workflow.getParams()
      const generateScript = path.join(workspaceDir, 'generate_config.py')
      const configParams: Record<string, unknown> = {
        model_name, dataset_root, dyn_vars, scale, log_dir,
        device: normalizedDeviceIds[0], device_ids: normalizedDeviceIds,
        distribute: false, distribute_mode: 'single',
        ckpt_path: ckpt_path || path.join(log_dir, 'best_model.pth'),
        epochs: 1, batch_size: 1, eval_batch_size: 1,
        use_amp: predictMergedParams.use_amp ?? (ampDefaultOff ? false : true),
        gradient_checkpointing: false,
        patch_size: predictMergedParams.patch_size,
        normalize: predictMergedParams.normalize, normalizer_type: predictMergedParams.normalizer_type,
      }
      const configPath = path.join(workspaceDir, `${model_name}_config.yaml`)
      const paramsJson = JSON.stringify(configParams)
      const genResult = await ctx.sandbox.exec(
        `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(generateScript)}" --params '${shellSafeJson(paramsJson)}' --output "${shellEscapeDouble(configPath)}"`,
        { timeoutMs: 60000 }
      )
      if (genResult.code !== 0) {
        return {
          status: 'error',
          error: `é…ç½®ç”Ÿæˆå¤±è´¥: ${genResult.stderr}`,
          suggestion: 'è¯·æ£€æŸ¥ dataset_root è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠ model_name æ˜¯å¦åœ¨æ”¯æŒåˆ—è¡¨ä¸­'
        }
      }
      const genInfo = JSON.parse(genResult.stdout)

      // æ„å»ºå‘½ä»¤ï¼ˆpredict å§‹ç»ˆå•å¡ï¼‰
      const cudaDevice = String(normalizedDeviceIds[0])
      const mainPy = path.join(workspaceDir, 'main.py')
      const cmdPath = pythonPath
      const cmdArgs = [mainPy, '--mode', 'predict', '--config', configPath]
      const cmdEnv = { CUDA_VISIBLE_DEVICES: cudaDevice }

      // å¯åŠ¨åå°è¿›ç¨‹
      const processInfo = trainingProcessManager.startProcess({
        cmd: cmdPath,
        args: cmdArgs,
        cwd: workspaceDir,
        logDir: log_dir,
        env: cmdEnv,
        metadata: {
          modelName: model_name,
          datasetRoot: dataset_root,
          logDir: log_dir,
          configPath: genInfo.config_path,
          workspaceDir: workspaceDir,
          deviceIds: normalizedDeviceIds,
          mode: 'predict',
        },
      })

      // ç­‰å¾… predict_start äº‹ä»¶
      const STARTUP_TIMEOUT_MS = 300000
      const startupResult = await trainingProcessManager.waitForEvent(
        processInfo.id, 'predict_start', STARTUP_TIMEOUT_MS
      )

      if (startupResult.processStatus === 'failed' || startupResult.processStatus === 'killed') {
        const failedInfo = trainingProcessManager.getProcess(processInfo.id)
        return {
          status: 'error',
          error: 'é¢„æµ‹æ¨ç†åœ¨å¯åŠ¨é˜¶æ®µå´©æºƒï¼ˆæ•°æ®åŠ è½½/æ¨¡å‹åŠ è½½å¤±è´¥ï¼‰',
          process_id: processInfo.id,
          error_summary: failedInfo?.errorSummary ?? null,
          error_log_tail: trainingProcessManager.readLogs(processInfo.id, { tail: 50 })?.content,
          suggestions: failedInfo?.errorSummary?.suggestions ?? [],
        }
      }

      const predictionsDir = path.join(log_dir, 'predictions')
      if (startupResult.found) {
        return {
          status: 'started',
          message: 'é¢„æµ‹æ¨ç†å·²å¯åŠ¨ã€‚ä½¿ç”¨ ocean_sr_train_status ç›‘æ§è¿›åº¦ã€‚',
          process_id: processInfo.id,
          pid: processInfo.pid,
          mode: 'predict',
          model: model_name,
          config_path: genInfo.config_path,
          log_dir,
          log_file: processInfo.logFile,
          predictions_dir: predictionsDir,
          workspace_dir: workspaceDir,
          workspace_info: prepareInfo,
          next_steps: [
            `è°ƒç”¨ ocean_sr_train_status({ action: "wait", process_id: "${processInfo.id}", timeout: 300 }) ç­‰å¾…æ¨ç†å®Œæˆ`,
            `è°ƒç”¨ ocean_sr_train_status({ process_id: "${processInfo.id}" }) æŸ¥çœ‹æ¨ç†çŠ¶æ€`,
            `è°ƒç”¨ ocean_sr_train_status({ action: "logs", process_id: "${processInfo.id}", tail: 50 }) æŸ¥çœ‹æœ€æ–°æ—¥å¿—`,
            `æ¨ç†å®Œæˆåè°ƒç”¨ ocean_sr_visualize({ log_dir: "${log_dir}", mode: "predict" }) ç”Ÿæˆå¯è§†åŒ–`,
          ],
        }
      }

      return {
        status: 'started',
        message: 'é¢„æµ‹è¿›ç¨‹å·²å¯åŠ¨ï¼Œä»åœ¨åˆå§‹åŒ–ä¸­ï¼ˆå¯èƒ½æ•°æ®é‡è¾ƒå¤§ï¼‰ã€‚ä½¿ç”¨ ocean_sr_train_status ç›‘æ§ã€‚',
        process_id: processInfo.id,
        pid: processInfo.pid,
        mode: 'predict',
        model: model_name,
        config_path: genInfo.config_path,
        log_dir,
        log_file: processInfo.logFile,
        predictions_dir: predictionsDir,
        workspace_dir: workspaceDir,
        workspace_info: prepareInfo,
        next_steps: [
          `è°ƒç”¨ ocean_sr_train_status({ action: "wait", process_id: "${processInfo.id}", timeout: 300 }) ç­‰å¾…æ¨ç†å®Œæˆ`,
          `è°ƒç”¨ ocean_sr_train_status({ process_id: "${processInfo.id}" }) æŸ¥çœ‹æ¨ç†çŠ¶æ€`,
        ],
      }
    }

    // ===== 3.0 æ¨¡å‹æ”¯æŒæ€§æ£€æŸ¥ï¼ˆè‹¥æ¨¡å‹æœªæ¥å…¥ï¼Œæå‰é˜»æ–­ï¼‰ =====
    let modelSupportInfo: ModelInfo | undefined
    const listScript = path.join(trainingDir, 'list_models.py')
    const listResult = await ctx.sandbox.exec(
      `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(listScript)}"`,
      { timeoutMs: 30000 }
    )
    if (listResult.code === 0) {
      try {
        const parsed = JSON.parse(listResult.stdout)
        if (Array.isArray(parsed.models)) {
          modelSupportInfo = parsed.models.find((m: ModelInfo) => m.name === model_name)
        }
      } catch {
        modelSupportInfo = undefined
      }
    }
    if (modelSupportInfo && modelSupportInfo.supported === false) {
      return {
        status: 'error',
        error: 'æ¨¡å‹ ' + model_name + ' æœªæ¥å…¥è®­ç»ƒæµç¨‹',
        reason: modelSupportInfo.notes ?? modelSupportInfo.description,
        suggestion: 'è¯·æ”¹ç”¨å·²æ¥å…¥çš„æ¨¡å‹ï¼Œæˆ–è¡¥é½æ¨¡å‹æ³¨å†Œ / trainer / é…ç½®æ¨¡æ¿åå†è¯•'
      }
    }
    if (listResult.code === 0 && !modelSupportInfo) {
      return {
        status: 'error',
        error: 'æœªçŸ¥æ¨¡å‹: ' + model_name,
        suggestion: 'è¯·ä»æ¨¡å‹åˆ—è¡¨ä¸­é€‰æ‹©ï¼Œæˆ–ç¡®è®¤æ¨¡å‹åç§°æ˜¯å¦æ‹¼å†™æ­£ç¡®'
      }
    }

    // ===== 3.1 FFT + AMP å…¼å®¹æ€§é¢„æ£€ï¼ˆæç¤ºï¼Œä¸æ‹¦æˆªï¼‰ =====
    let fftAmpWarningAtStart: ReturnType<typeof buildFftAmpIncompatibility> | null = null
    if (isFftSensitiveModel(model_name) && (args.use_amp ?? true)) {
      const datasetInfo = await validateDataset(dataset_root, pythonPath, trainingDir, ctx)
      fftAmpWarningAtStart = buildFftAmpIncompatibility({
        model_name,
        use_amp: args.use_amp ?? true,
        datasetInfo,
        scale,
        patch_size: args.patch_size ?? null,
      })
    }
    const execWarnings: string[] = []
    if (fftAmpWarningAtStart) {
      execWarnings.push(
        `FFT + AMP å¯èƒ½ä¸å…¼å®¹ï¼šLR ${fftAmpWarningAtStart.details.lr_height}Ã—${fftAmpWarningAtStart.details.lr_width} ä¸æ˜¯ 2 çš„å¹‚ï¼Œå»ºè®® use_amp=false æˆ–è°ƒæ•´å°ºå¯¸ã€‚`
      )
    }

    const normalizedDeviceIds = Array.isArray(device_ids) && device_ids.length > 0 ? device_ids : [0]
    const effectiveDistribute = distribute && normalizedDeviceIds.length > 1
    const effectiveDistributeMode = effectiveDistribute ? distribute_mode : 'single'

    let masterPort: number | null = null
    if (effectiveDistribute && distribute_mode === 'DDP') {
      const requestedPort = typeof args.master_port === 'number' ? Math.trunc(args.master_port) : null
      if (requestedPort && requestedPort > 0 && requestedPort <= 65535) {
        if (await isPortFree(requestedPort)) {
          masterPort = requestedPort
        } else {
          const fallbackPort = await findFreePort(29500, 29600)
          masterPort = fallbackPort ?? requestedPort
          execWarnings.push(`DDP master_port ${requestedPort} å·²è¢«å ç”¨ï¼Œå·²åˆ‡æ¢ä¸º ${masterPort}ã€‚`)
        }
      } else {
        const fallbackPort = await findFreePort(29500, 29600)
        masterPort = fallbackPort ?? 29500
        if (masterPort !== 29500) {
          execWarnings.push(`DDP master_port è‡ªåŠ¨é€‰æ‹©ä¸º ${masterPort}ã€‚`)
        }
      }
    }

    if (distribute && normalizedDeviceIds.length <= 1) {
      execWarnings.push(
        'å·²è¯·æ±‚å¤šå¡/DP/DDP ä½† device_ids åªæœ‰ 1 å¼  GPUï¼Œå·²è‡ªåŠ¨é™çº§ä¸ºå•å¡è®­ç»ƒä»¥é¿å… DDP åˆå§‹åŒ–å¤±è´¥ã€‚'
      )
    }

    // ===== 3a. å‡†å¤‡è®­ç»ƒå·¥ä½œç©ºé—´ï¼ˆåªå¤åˆ¶æ‰€é€‰æ¨¡å‹ç›¸å…³ä»£ç ï¼‰ =====
    // è®­ç»ƒåœ¨å‰¯æœ¬ä¸Šæ‰§è¡Œï¼Œä¿æŒ Agent SDK æºç ä¸è¢«ä¿®æ”¹ï¼›
    // Agent è¿è¡Œæ—¶å¦‚éœ€è°ƒæ•´ä»£ç ï¼Œå¯ç›´æ¥ä¿®æ”¹å‰¯æœ¬è€Œä¸å½±å“ SDKï¼›
    // åˆ‡æ¢æ¨¡å‹æ—¶ä¼šè‡ªåŠ¨æ¸…ç†æ—§æ¨¡å‹ä»£ç å¹¶æ›¿æ¢ä¸ºæ–°æ¨¡å‹ä»£ç 
    const workspaceDir = path.resolve(log_dir, '_ocean_sr_code')
    const prepareScript = path.join(trainingDir, 'prepare_workspace.py')
    const prepareResult = await ctx.sandbox.exec(
      `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(prepareScript)}" --source_dir "${shellEscapeDouble(trainingDir)}" --target_dir "${shellEscapeDouble(workspaceDir)}" --model_name "${shellEscapeDouble(model_name)}"`,
      { timeoutMs: 60000 }
    )
    if (prepareResult.code !== 0) {
      return {
        status: 'error',
        error: `å·¥ä½œç©ºé—´å‡†å¤‡å¤±è´¥: ${prepareResult.stderr}`,
        reason: 'æ— æ³•å°†è®­ç»ƒä»£ç å¤åˆ¶åˆ°è¾“å‡ºç›®å½•',
        suggestion: `è¯·æ£€æŸ¥è¾“å‡ºç›®å½• ${log_dir} æ˜¯å¦å­˜åœ¨ä¸”æœ‰å†™å…¥æƒé™`
      }
    }
    const prepareInfo = JSON.parse(prepareResult.stdout)

    const generateScript = path.join(workspaceDir, 'generate_config.py')

    // ===== 3b. ç”Ÿæˆé…ç½®æ–‡ä»¶ =====
    // ä½¿ç”¨ workflow.getParams() å–åˆå¹¶åå‚æ•°ï¼ˆç”¨æˆ·ä¼ å…¥å€¼ > é»˜è®¤å€¼ï¼‰ï¼Œ
    // é¿å…å›  Agent åç»­è°ƒç”¨æœªæºå¸¦æŸå­—æ®µè€Œä¸¢å¤±ç”¨æˆ·ç¡®è®¤è¿‡çš„å‚æ•°
    const mergedParams = workflow.getParams()
    // use_amp å›è½ï¼šè‹¥ session å’Œå½“å‰è°ƒç”¨å‡æœªæ˜ç¡®æŒ‡å®šï¼Œåˆ™ä½¿ç”¨æ¨¡å‹è‡ªåŠ¨è®¡ç®—å€¼
    const effectiveUseAmp = mergedParams.use_amp ?? (ampDefaultOff ? false : true)
    const configParams: Record<string, unknown> = {
      model_name,
      dataset_root,
      dyn_vars,
      scale,
      log_dir,
      device: normalizedDeviceIds[0],
      device_ids: normalizedDeviceIds,
      distribute: effectiveDistribute,
      distribute_mode: effectiveDistributeMode,
      master_port: masterPort ?? undefined,
      ckpt_path,
      epochs: mergedParams.epochs,
      lr: mergedParams.lr,
      batch_size: mergedParams.batch_size,
      eval_batch_size: mergedParams.eval_batch_size,
      patience: mergedParams.patience,
      eval_freq: mergedParams.eval_freq,
      normalize: mergedParams.normalize,
      normalizer_type: mergedParams.normalizer_type,
      optimizer: mergedParams.optimizer,
      weight_decay: mergedParams.weight_decay,
      scheduler: mergedParams.scheduler,
      scheduler_step_size: mergedParams.scheduler_step_size,
      scheduler_gamma: mergedParams.scheduler_gamma,
      seed: mergedParams.seed,
      wandb: mergedParams.wandb,
      use_amp: effectiveUseAmp,
      gradient_checkpointing: mergedParams.gradient_checkpointing,
      patch_size: mergedParams.patch_size,
    }

    const configPath = path.join(workspaceDir, `${model_name}_config.yaml`)

    const paramsJson = JSON.stringify(configParams)
    const genResult = await ctx.sandbox.exec(
      `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(generateScript)}" --params '${shellSafeJson(paramsJson)}' --output "${shellEscapeDouble(configPath)}"`,
      { timeoutMs: 60000 }
    )

    if (genResult.code !== 0) {
      return {
        status: 'error',
        error: `é…ç½®ç”Ÿæˆå¤±è´¥: ${genResult.stderr}`,
        reason: 'å‚æ•°å¯èƒ½ä¸å…¼å®¹æ‰€é€‰æ¨¡å‹ï¼Œæˆ–æ•°æ®ç›®å½•ä¸å¯è®¿é—®',
        suggestion: 'è¯·æ£€æŸ¥ dataset_root è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œä»¥åŠ model_name æ˜¯å¦åœ¨æ”¯æŒåˆ—è¡¨ä¸­'
      }
    }

    const genInfo = JSON.parse(genResult.stdout)
    if (genInfo?.eval_batchsize_clamped) {
      const requested = genInfo.eval_batchsize_requested ?? args.eval_batch_size
      const applied = genInfo.eval_batchsize ?? 4
      execWarnings.push(
        `æ‰©æ•£æ¨¡å‹è¯„ä¼°æ˜¾å­˜å¼€é”€å¤§ï¼Œeval_batch_size å·²ä» ${requested} é™åˆ¶ä¸º ${applied}ï¼ˆä¸Šé™ 4ï¼‰`
      )
    }

    // ===== 3b.1 è®­ç»ƒå‰æ¨¡å‹è¾“å‡ºå°ºå¯¸é¢„æ£€ =====
    if (mode === 'train') {
      const shapeCheckScript = path.join(workspaceDir, 'check_output_shape.py')
      const deviceId = normalizedDeviceIds[0] ?? 0
      const shapeResult = await ctx.sandbox.exec(
        `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(shapeCheckScript)}" --config "${shellEscapeDouble(configPath)}" --device ${Number(deviceId) || 0}`,
        { timeoutMs: 120000 }
      )

      if (shapeResult.code !== 0) {
        // ä¼˜å…ˆä» stdout æå– tagged JSONï¼ˆstderr å¯èƒ½åªå« FutureWarning ç­‰æ— å…³è­¦å‘Šï¼‰
        const shapeInfoOnError = extractTaggedJson(shapeResult.stdout, 'shape_check')
        if (shapeInfoOnError) {
          return {
            status: 'error',
            error: shapeInfoOnError.error ?? `è¾“å‡ºå°ºå¯¸é¢„æ£€å¤±è´¥ (exit code ${shapeResult.code})`,
            reason: shapeInfoOnError.reason ?? 'æ— æ³•å®Œæˆæ¨¡å‹è¾“å‡ºå°ºå¯¸æ£€æŸ¥',
            details: shapeInfoOnError.details,
            suggestion: 'è¯·æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–æ•°æ®ç›®å½•æ˜¯å¦å¯ç”¨'
          }
        }
        // stdout æ— ç»“æ„åŒ–è¾“å‡ºæ—¶æ‰å›é€€åˆ° stderr
        return {
          status: 'error',
          error: `è¾“å‡ºå°ºå¯¸é¢„æ£€å¤±è´¥: ${shapeResult.stderr || shapeResult.stdout}`,
          reason: 'æ— æ³•å®Œæˆæ¨¡å‹è¾“å‡ºå°ºå¯¸æ£€æŸ¥',
          suggestion: 'è¯·æ£€æŸ¥æ¨¡å‹é…ç½®æˆ–æ•°æ®ç›®å½•æ˜¯å¦å¯ç”¨'
        }
      }

      const shapeInfo = extractTaggedJson(shapeResult.stdout, 'shape_check')
      if (shapeInfo && shapeInfo.status === 'error') {
        return {
          status: 'error',
          error: shapeInfo.error ?? 'æ¨¡å‹è¾“å‡ºå°ºå¯¸ä¸ HR ä¸åŒ¹é…',
          reason: shapeInfo.reason ?? 'æ¨¡å‹è¾“å‡ºå°ºå¯¸ä¸ç›®æ ‡å°ºå¯¸ä¸ä¸€è‡´',
          details: shapeInfo.details,
          suggestion:
            'è¯·æ£€æŸ¥ scale/upsample_factor é…ç½®ï¼Œæˆ–è°ƒæ•´ patch_size/æ¨¡å‹å‚æ•°ä½¿è¾“å‡ºä¸ HR å¯¹é½'
        }
      }
    }

    // ===== 3c. è‡ªåŠ¨æ˜¾å­˜é¢„ä¼° + è‡ªåŠ¨è°ƒå‚ï¼ˆä¸å¯è·³è¿‡ï¼‰ =====
    if (mode === 'train') {
      const estimateScript = path.join(workspaceDir, 'estimate_memory.py')
      const cudaDevice = normalizedDeviceIds[0]
      let currentBatchSize = (configParams.batch_size as number) ?? 4
      let currentAmp = (configParams.use_amp as boolean) ?? true
      const allowAutoEnableAmp = !ampDefaultOff || args.use_amp === true
      const MAX_ATTEMPTS = 5

      for (let attempt = 0; attempt < MAX_ATTEMPTS; attempt++) {
        // æ¯æ¬¡è°ƒå‚åé‡æ–°ç”Ÿæˆé…ç½®
        if (attempt > 0) {
          configParams.batch_size = currentBatchSize
          configParams.use_amp = currentAmp
          const regenJson = JSON.stringify(configParams)
          const regenResult = await ctx.sandbox.exec(
            `"${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(generateScript)}" --params '${shellSafeJson(regenJson)}' --output "${shellEscapeDouble(configPath)}"`,
            { timeoutMs: 60000 }
          )
          if (regenResult.code !== 0) {
            execWarnings.push(`æ˜¾å­˜é¢„ä¼°å‰é‡å»ºé…ç½®å¤±è´¥ï¼Œå·²è·³è¿‡è‡ªåŠ¨è°ƒå‚ï¼š${regenResult.stderr || regenResult.stdout}`)
            break
          }
        }

        const estimateResult = await ctx.sandbox.exec(
          `cd "${shellEscapeDouble(workspaceDir)}" && CUDA_VISIBLE_DEVICES=${Number(cudaDevice) || 0} "${shellEscapeDouble(pythonPath)}" "${shellEscapeDouble(estimateScript)}" --config "${shellEscapeDouble(configPath)}" --device 0`,
          { timeoutMs: 120000 }
        )
        if (estimateResult.code !== 0) {
          execWarnings.push(`æ˜¾å­˜é¢„ä¼°å¤±è´¥ï¼Œå·²è·³è¿‡è‡ªåŠ¨è°ƒå‚å¹¶ç»§ç»­è®­ç»ƒï¼š${estimateResult.stderr || estimateResult.stdout}`)
          break
        }

        try {
          const mem = JSON.parse(estimateResult.stdout)
          if (mem.status === 'success' && mem.utilization_pct <= 85) {
            // é€šè¿‡ â†’ è·³å‡ºå¾ªç¯
            break
          }

          // OOM æˆ– >85%ï¼šä¾æ¬¡é™çº§
          if (!currentAmp) {
            if (allowAutoEnableAmp) {
              currentAmp = true
            } else if (currentBatchSize > 1) {
              currentBatchSize = Math.max(1, Math.floor(currentBatchSize / 2))
            } else {
              // æ‰€æœ‰æ‰‹æ®µè€—å°½
              return {
                status: 'error',
                error: 'GPU æ˜¾å­˜ä¸è¶³ï¼Œå·²å°è¯•æ‰€æœ‰è‡ªåŠ¨ä¼˜åŒ–æ‰‹æ®µä»æ— æ³•é€‚é…',
                memory_estimate: mem,
                applied_optimizations: { use_amp: currentAmp, batch_size: currentBatchSize },
                recommendations: mem.recommendations,
                suggestion: 'è¯·ä½¿ç”¨æ›´å¤§æ˜¾å­˜çš„ GPUï¼Œæˆ–æ‰‹åŠ¨è®¾ç½®æ›´å°çš„ patch_size'
              }
            }
          } else if (currentBatchSize > 1) {
            currentBatchSize = Math.max(1, Math.floor(currentBatchSize / 2))
          } else {
            // æ‰€æœ‰æ‰‹æ®µè€—å°½
            return {
              status: 'error',
              error: 'GPU æ˜¾å­˜ä¸è¶³ï¼Œå·²å°è¯•æ‰€æœ‰è‡ªåŠ¨ä¼˜åŒ–æ‰‹æ®µä»æ— æ³•é€‚é…',
              memory_estimate: mem,
              applied_optimizations: { use_amp: currentAmp, batch_size: currentBatchSize },
              recommendations: mem.recommendations,
              suggestion: 'è¯·ä½¿ç”¨æ›´å¤§æ˜¾å­˜çš„ GPUï¼Œæˆ–æ‰‹åŠ¨è®¾ç½®æ›´å°çš„ patch_size'
            }
          }
        } catch {
          // è§£æå¤±è´¥ä¸é˜»æ­¢è®­ç»ƒ
          execWarnings.push('æ˜¾å­˜é¢„ä¼°è¾“å‡ºè§£æå¤±è´¥ï¼Œå·²è·³è¿‡è‡ªåŠ¨è°ƒå‚å¹¶ç»§ç»­è®­ç»ƒ')
          break
        }
      }
    }

    // ===== 3d. æ„å»ºè¿è¡Œå‘½ä»¤ =====
    // æ³¨ï¼šä»£ç å¿«ç…§ç”± Python çš„ main.py / main_ddp.py åœ¨è®­ç»ƒå¼€å§‹å‰è‡ªåŠ¨ä¿å­˜åˆ° saving_path/code/
    let cmdPath: string
    let cmdArgs: string[]
    let cmdEnv: Record<string, string> = {}

    if (effectiveDistribute && distribute_mode === 'DDP') {
      const nproc = normalizedDeviceIds.length
      const cudaDevices = normalizedDeviceIds.join(',')
      const mainDdp = path.join(workspaceDir, 'main_ddp.py')
      cmdPath = pythonPath
      cmdArgs = ['-m', 'torch.distributed.run', `--nproc_per_node=${nproc}`, `--master_port=${masterPort ?? 29500}`, mainDdp, '--mode', mode, '--config', configPath]
      cmdEnv = { CUDA_VISIBLE_DEVICES: cudaDevices, MASTER_PORT: String(masterPort ?? 29500) }
    } else if (effectiveDistribute && distribute_mode === 'DP') {
      const mainPy = path.join(workspaceDir, 'main.py')
      cmdPath = pythonPath
      cmdArgs = [mainPy, '--mode', mode, '--config', configPath]
      // DP ç›´æ¥ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„ç‰©ç† GPU ç¼–å·ï¼Œé¿å…è¢«å•å¡ CUDA_VISIBLE_DEVICES é™åˆ¶
      cmdEnv = {}
    } else {
      const cudaDevice = String(normalizedDeviceIds[0])
      const mainPy = path.join(workspaceDir, 'main.py')
      cmdPath = pythonPath
      cmdArgs = [mainPy, '--mode', mode, '--config', configPath]
      cmdEnv = { CUDA_VISIBLE_DEVICES: cudaDevice }
    }

    // ===== 3e. å¯åŠ¨åå°è®­ç»ƒè¿›ç¨‹ =====
    const processInfo = trainingProcessManager.startProcess({
      cmd: cmdPath,
      args: cmdArgs,
      cwd: workspaceDir,
      logDir: log_dir,
      env: cmdEnv,
      metadata: {
        modelName: model_name,
        datasetRoot: dataset_root,
        logDir: log_dir,
        configPath: genInfo.config_path,
        workspaceDir: workspaceDir,
        deviceIds: normalizedDeviceIds,
      },
    })

    // ===== 3f. ç­‰å¾…è®­ç»ƒå¯åŠ¨æˆåŠŸï¼ˆäº‹ä»¶é©±åŠ¨ï¼‰ =====
    const STARTUP_TIMEOUT_MS = 300000  // 5 åˆ†é’Ÿï¼ˆæ•°æ®åŠ è½½å¯èƒ½å¾ˆä¹…ï¼‰
    const startupResult = await trainingProcessManager.waitForEvent(
      processInfo.id, 'training_start', STARTUP_TIMEOUT_MS
    )

    if (startupResult.processStatus === 'failed' || startupResult.processStatus === 'killed') {
      // å¯åŠ¨é˜¶æ®µå´©æºƒ â†’ ç›´æ¥è¿”å›é”™è¯¯
      const failedInfo = trainingProcessManager.getProcess(processInfo.id)
      return {
        status: 'error',
        error: 'è®­ç»ƒåœ¨å¯åŠ¨é˜¶æ®µå´©æºƒï¼ˆæ•°æ®åŠ è½½/æ¨¡å‹æ„å»ºå¤±è´¥ï¼‰',
        process_id: processInfo.id,
        error_summary: failedInfo?.errorSummary ?? null,
        error_log_tail: trainingProcessManager.readLogs(processInfo.id, { tail: 50 })?.content,
        suggestions: failedInfo?.errorSummary?.suggestions ?? [],
      }
    }

    // ===== 3g. ç”Ÿæˆ Jupyter Notebookï¼ˆè®­ç»ƒæˆåŠŸå¯åŠ¨åï¼‰ =====
    const metadataNotebookPath = (ctx.agent as any)?.config?.metadata?.notebookPath as string | undefined
    const notebookPath = metadataNotebookPath
      ? path.resolve(metadataNotebookPath)
      : path.resolve(ctx.sandbox.workDir, `${path.basename(ctx.sandbox.workDir)}.ipynb`)
    try {
      const cells = generateTrainCells({
        logDir: log_dir,
        datasetRoot: dataset_root ?? '',
        modelName: model_name ?? '',
        configPath: genInfo.config_path ?? configPath,
        workspaceDir,
        pythonPath,
        deviceIds: normalizedDeviceIds,
        distribute: effectiveDistribute,
        distributeMode: effectiveDistributeMode,
        masterPort: masterPort ?? undefined,
        mode,
        scale: mergedParams.scale,
        dynVars: mergedParams.dyn_vars,
        epochs: mergedParams.epochs,
        lr: mergedParams.lr,
        batchSize: mergedParams.batch_size,
        evalBatchSize: mergedParams.eval_batch_size,
        patience: mergedParams.patience,
        evalFreq: mergedParams.eval_freq,
        normalize: mergedParams.normalize,
        normalizerType: mergedParams.normalizer_type,
        optimizer: mergedParams.optimizer,
        weightDecay: mergedParams.weight_decay,
        scheduler: mergedParams.scheduler,
        schedulerStepSize: mergedParams.scheduler_step_size,
        schedulerGamma: mergedParams.scheduler_gamma,
        seed: mergedParams.seed,
        useAmp: effectiveUseAmp,
        gradientCheckpointing: mergedParams.gradient_checkpointing,
        patchSize: mergedParams.patch_size,
        ckptPath: ckpt_path,
        wandb: mergedParams.wandb,
      })
      await saveOrAppendNotebook(ctx, notebookPath, cells)
    } catch (e) {
      console.warn('Notebook ç”Ÿæˆå¤±è´¥:', e)
    }

    // å…¬å…±åŸºç¡€å“åº”
    const baseResponse = {
      status: 'started',
      process_id: processInfo.id,
      pid: processInfo.pid,
      mode,
      model: model_name,
      config_path: genInfo.config_path,
      log_dir,
      log_file: processInfo.logFile,
      notebook_path: notebookPath,
      distribute: effectiveDistribute,
      distribute_mode: effectiveDistributeMode,
      device_ids: normalizedDeviceIds,
      master_port: masterPort ?? undefined,
      workspace_dir: workspaceDir,
      workspace_info: prepareInfo,
      amp_auto_disabled: autoDisabledAmp ? { model: args.model_name } : undefined,
      warnings: execWarnings.length > 0 ? execWarnings : undefined,
      fft_amp_warning: fftAmpWarningAtStart?.details,
    };

    if (startupResult.found) {
      return {
        ...baseResponse,
        message: 'è®­ç»ƒå·²å¯åŠ¨å¹¶æ­£å¸¸è¿è¡Œä¸­ã€‚ä½¿ç”¨ ocean_sr_train_status å·¥å…·ç›‘æ§è¿›åº¦ã€‚',
        next_steps: [
          `è°ƒç”¨ ocean_sr_train_status({ action: "wait", process_id: "${processInfo.id}", timeout: 120 }) ç­‰å¾…è®­ç»ƒçŠ¶æ€å˜åŒ–`,
          `è°ƒç”¨ ocean_sr_train_status({ action: "watch", process_id: "${processInfo.id}", timeout: 300 }) ç­‰å¾…å…³é”®æ¨é€äº‹ä»¶`,
          `è°ƒç”¨ ocean_sr_train_status({ process_id: "${processInfo.id}" }) æŸ¥çœ‹è®­ç»ƒçŠ¶æ€`,
          `è°ƒç”¨ ocean_sr_train_status({ action: "logs", process_id: "${processInfo.id}", tail: 50 }) æŸ¥çœ‹æœ€æ–°æ—¥å¿—`,
          `è°ƒç”¨ ocean_sr_train_status({ action: "kill", process_id: "${processInfo.id}" }) ç»ˆæ­¢è®­ç»ƒ`,
        ],
      };
    }

    return {
      ...baseResponse,
      message: 'è®­ç»ƒè¿›ç¨‹å·²å¯åŠ¨ï¼Œä»åœ¨åˆå§‹åŒ–ä¸­ï¼ˆå¯èƒ½æ•°æ®é‡è¾ƒå¤§ï¼‰ã€‚ä½¿ç”¨ ocean_sr_train_status ç›‘æ§ã€‚',
      next_steps: [
        `è°ƒç”¨ ocean_sr_train_status({ action: "wait", process_id: "${processInfo.id}", timeout: 120 }) ç­‰å¾…è®­ç»ƒçŠ¶æ€å˜åŒ–`,
        `è°ƒç”¨ ocean_sr_train_status({ action: "watch", process_id: "${processInfo.id}", timeout: 300 }) ç­‰å¾…å…³é”®æ¨é€äº‹ä»¶`,
        `è°ƒç”¨ ocean_sr_train_status({ process_id: "${processInfo.id}" }) æŸ¥çœ‹è®­ç»ƒçŠ¶æ€`,
        `è°ƒç”¨ ocean_sr_train_status({ action: "logs", process_id: "${processInfo.id}", tail: 50 }) æŸ¥çœ‹æœ€æ–°æ—¥å¿—`,
      ],
    };
  }
})
